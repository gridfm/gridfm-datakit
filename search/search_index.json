{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#gridfm-datakit","title":"GridFM DataKit","text":"<p>GridFM DataKit (<code>gridfm-datakit</code>) is a Python library for generating realistic, diverse, and scalable synthetic datasets for power flow (PF) and optimal power flow (OPF) machine learning solvers. It unifies state-of-the-art methods for perturbing loads, generator dispatches, network topologies, and branch parameters, addressing limitations of existing data generation libraries.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Scalable: Supports grids with up to 30,000 buses for PF and 10,000 buses for OPF. Compatible with MATPOWER (<code>.m</code>) files and the PGLib dataset.</li> <li>Realistic load scenarios: Combines global scaling from real-world aggregated profiles with localized per-bus noise, preserving temporal and spatial correlations.</li> <li>Flexible topology perturbations: Handles arbitrary (N-k) outages for lines, transformers, and generators, ensuring feasible network states.</li> <li>Generator cost diversity: Permutes or randomly scales generator cost functions when solving OPF to produce diverse dispatches and improve generalization across different cost conditions.</li> <li>Out-of-operating-limits scenarios for PF: PF datasets include realistic violations of operating limits (e.g., voltage or branch overloads) resulting from topology and load perturbations without re-optimizing generator dispatch.</li> <li>Admittance perturbations: Randomly scales branch resistances and reactances to enhance diversity.</li> <li>Structured outputs for ML: Per-bus, per-branch, and per-generator data ready for training neural PF/OPF solvers, with pre-computed DC-PF and DC-OPF baselines and runtime.</li> <li>Data validation and benchmarking: Includes CLI tools for consistency checks, statistics, and constraint validation.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Please cite the library when using it in your work:</p> <pre><code>@misc{puech2025gridfmdatakitv1pythonlibraryscalable,\n      title={gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation},\n      author={Alban Puech and Matteo Mazzonelli and Celia Cintas and Tamara R. Govindasamy and Mangaliso Mngomezulu and Jonas Weiss and Matteo Ba\u00f9 and Anna Varbella and Fran\u00e7ois Mirall\u00e8s and Kibaek Kim and Le Xie and Hendrik F. Hamann and Etienne Vos and Thomas Brunschwiler},\n      year={2025},\n      eprint={2512.14658},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG},\n      url={https://arxiv.org/abs/2512.14658},\n}\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<ol> <li> <p>\u2b50 Star the repository on GitHub to support the project!</p> </li> <li> <p>Make sure you have Python 3.10, 3.11, or 3.12 installed. \u26a0\ufe0f Windows users: Python 3.12 is not supported. Use Python 3.10.11 or 3.11.9.</p> </li> <li> <p>Install gridfm-datakit</p> </li> </ol> <pre><code>python -m pip install --upgrade pip  # Upgrade pip\npip install gridfm-datakit\n</code></pre> <ol> <li>Install Julia with PowerModels and Ipopt</li> </ol> <pre><code>gridfm_datakit setup_pm\n</code></pre>"},{"location":"installation/#for-developers","title":"For Developers","text":"<p>To install the latest development version from GitHub, follow these steps instead of step 3.</p> <pre><code>git clone https://github.com/gridfm/gridfm-datakit.git\ncd \"gridfm-datakit\"\npython3 -m venv venv\nsource venv/bin/activate\npython -m pip install --upgrade pip  # Upgrade pip to ensure compatibility with pyproject.toml\npip3 install -e '.[test,dev]'\n</code></pre>"},{"location":"components/admittance_perturbation/","title":"Admittance Perturbations","text":""},{"location":"components/admittance_perturbation/#base-classes","title":"Base Classes","text":""},{"location":"components/admittance_perturbation/#admittancegenerator","title":"<code>AdmittanceGenerator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for applying perturbations to line admittances.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>class AdmittanceGenerator(ABC):\n    \"\"\"Abstract base class for applying perturbations to line admittances.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the admittance generator.\"\"\"\n        pass\n\n    @abstractmethod\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Union[Generator[Network, None, None], List[Network]]:\n        \"\"\"Generate admittance perturbations.\n\n        Args:\n            example_generator: A generator producing example (load/topology/generation)\n                scenarios to which line admittance perturbations are added.\n\n        Yields:\n            An admittance-perturbed scenario.\n        \"\"\"\n        pass\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the admittance generator.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the admittance generator.\"\"\"\n    pass\n</code></pre> <code>generate(example_generator)</code> <code>abstractmethod</code> \u00b6 <p>Generate admittance perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which line admittance perturbations are added.</p> required <p>Yields:</p> Type Description <code>Union[Generator[Network, None, None], List[Network]]</code> <p>An admittance-perturbed scenario.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>@abstractmethod\ndef generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Union[Generator[Network, None, None], List[Network]]:\n    \"\"\"Generate admittance perturbations.\n\n    Args:\n        example_generator: A generator producing example (load/topology/generation)\n            scenarios to which line admittance perturbations are added.\n\n    Yields:\n        An admittance-perturbed scenario.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"components/admittance_perturbation/#concrete-implementations","title":"Concrete Implementations","text":""},{"location":"components/admittance_perturbation/#noadmittanceperturbationgenerator","title":"<code>NoAdmittancePerturbationGenerator</code>","text":"<p>               Bases: <code>AdmittanceGenerator</code></p> <p>Generator that yields the original example generator without any perturbations.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>class NoAdmittancePerturbationGenerator(AdmittanceGenerator):\n    \"\"\"Generator that yields the original example generator without any perturbations.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the no-perturbation generator\"\"\"\n        pass\n\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Yield the original examples without any perturbations.\n\n        Args:\n            example_generator: A generator producing example (load/topology/generation)\n                scenarios to which line admittance perturbations are added.\n\n        Yields:\n            The original example produced by the example_generator.\n        \"\"\"\n        for example in example_generator:\n            yield example\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the no-perturbation generator</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the no-perturbation generator\"\"\"\n    pass\n</code></pre> <code>generate(example_generator)</code> \u00b6 <p>Yield the original examples without any perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which line admittance perturbations are added.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>The original example produced by the example_generator.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>def generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Yield the original examples without any perturbations.\n\n    Args:\n        example_generator: A generator producing example (load/topology/generation)\n            scenarios to which line admittance perturbations are added.\n\n    Yields:\n        The original example produced by the example_generator.\n    \"\"\"\n    for example in example_generator:\n        yield example\n</code></pre>"},{"location":"components/admittance_perturbation/#perturbadmittancegenerator","title":"<code>PerturbAdmittanceGenerator</code>","text":"<p>               Bases: <code>AdmittanceGenerator</code></p> <p>Class for applying perturbations to line admittances.</p> <p>This class is for generating different line admittance scenarios by applying perturbations to the resistance (R) and reactance (X) values of the lines.  Perturbations are applied as a scaling factor sampled from a uniform distribution with a given lower and upper bound.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>class PerturbAdmittanceGenerator(AdmittanceGenerator):\n    \"\"\"Class for applying perturbations to line admittances.\n\n    This class is for generating different line admittance scenarios\n    by applying perturbations to the resistance (R) and reactance (X)\n    values of the lines.  Perturbations are applied as a scaling factor\n    sampled from a uniform distribution with a given lower and upper\n    bound.\n    \"\"\"\n\n    def __init__(self, base_net: Network, sigma: float) -&gt; None:\n        \"\"\"\n        Initialize the line admittance perturbation generator.\n        TODO: add BR_B\n\n        Args:\n            base_net: The base power network.\n            sigma: A constant that specifies the range from which to draw\n                samples from a uniform distribution to be used as a scaling\n                factor for resistance and reactance. The range is\n                set as [max([0, 1-sigma]), 1+sigma).\n        \"\"\"\n        self.base_net = base_net\n        self.r_original = self.base_net.branches[:, BR_R]\n        self.x_original = self.base_net.branches[:, BR_X]\n        self.lower = np.max([0.0, 1.0 - sigma])\n        self.upper = 1.0 + sigma\n        self.sample_size = self.base_net.branches.shape[0]\n\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Generate a network with perturbed line admittance values.\n\n        Args:\n            example_generator: A generator producing example (load/topology/generation)\n                scenarios to which line admittance perturbations are added.\n\n        Yields:\n            An example scenario with random perturbations applied to line\n            admittances.\n        \"\"\"\n        for example in example_generator:\n            example.branches[:, BR_R] = np.random.uniform(\n                self.lower * self.r_original,\n                self.upper * self.r_original,\n                self.r_original.shape[0],\n            )\n\n            example.branches[:, BR_X] = np.random.uniform(\n                self.lower * self.x_original,\n                self.upper * self.x_original,\n                self.x_original.shape[0],\n            )\n\n            yield example\n</code></pre> <code>__init__(base_net, sigma)</code> \u00b6 <p>Initialize the line admittance perturbation generator. TODO: add BR_B</p> <p>Parameters:</p> Name Type Description Default <code>base_net</code> <code>Network</code> <p>The base power network.</p> required <code>sigma</code> <code>float</code> <p>A constant that specifies the range from which to draw samples from a uniform distribution to be used as a scaling factor for resistance and reactance. The range is set as [max([0, 1-sigma]), 1+sigma).</p> required Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>def __init__(self, base_net: Network, sigma: float) -&gt; None:\n    \"\"\"\n    Initialize the line admittance perturbation generator.\n    TODO: add BR_B\n\n    Args:\n        base_net: The base power network.\n        sigma: A constant that specifies the range from which to draw\n            samples from a uniform distribution to be used as a scaling\n            factor for resistance and reactance. The range is\n            set as [max([0, 1-sigma]), 1+sigma).\n    \"\"\"\n    self.base_net = base_net\n    self.r_original = self.base_net.branches[:, BR_R]\n    self.x_original = self.base_net.branches[:, BR_X]\n    self.lower = np.max([0.0, 1.0 - sigma])\n    self.upper = 1.0 + sigma\n    self.sample_size = self.base_net.branches.shape[0]\n</code></pre> <code>generate(example_generator)</code> \u00b6 <p>Generate a network with perturbed line admittance values.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which line admittance perturbations are added.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>An example scenario with random perturbations applied to line</p> <code>Network</code> <p>admittances.</p> Source code in <code>gridfm_datakit/perturbations/admittance_perturbation.py</code> <pre><code>def generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Generate a network with perturbed line admittance values.\n\n    Args:\n        example_generator: A generator producing example (load/topology/generation)\n            scenarios to which line admittance perturbations are added.\n\n    Yields:\n        An example scenario with random perturbations applied to line\n        admittances.\n    \"\"\"\n    for example in example_generator:\n        example.branches[:, BR_R] = np.random.uniform(\n            self.lower * self.r_original,\n            self.upper * self.r_original,\n            self.r_original.shape[0],\n        )\n\n        example.branches[:, BR_X] = np.random.uniform(\n            self.lower * self.x_original,\n            self.upper * self.x_original,\n            self.x_original.shape[0],\n        )\n\n        yield example\n</code></pre>"},{"location":"components/cli/","title":"CLI","text":"<p>This module provides a command-line interface for generating and validating power flow data.</p>"},{"location":"components/cli/#commands","title":"Commands","text":""},{"location":"components/cli/#generate-data","title":"Generate Data","text":"<p>Generate power flow data from a configuration file:</p> <pre><code>gridfm-datakit generate path/to/config.yaml\n</code></pre> <p>Arguments: - <code>config</code>: Path to the YAML configuration file</p> <p>Example:</p> <pre><code>gridfm-datakit generate scripts/config/default.yaml\n</code></pre>"},{"location":"components/cli/#validate-data","title":"Validate Data","text":"<p>Validate previously generated power flow data. Runs comprehensive validation checks for data integrity and physical consistency:</p> <pre><code>gridfm-datakit validate path/to/data/directory [--n-partitions N] [--sn-mva 100]\n</code></pre> <p>Arguments: - <code>data_path</code>: Path to directory containing generated CSV files - <code>--n-partitions N</code>: Number of partitions (of 200 scenarios) to sample for validation (default: 100). Use 0 to validate all partitions. - <code>--sn-mva</code>: Base MVA used to scale power quantities (default: 100).</p> <p>Examples:</p> <pre><code># Validate with default sampling (100 partitions)\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw\n\n# Validate custom number of partitions\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw --n-partitions 50\n\n# Validate all partitions (slower but complete)\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw --n-partitions 0\n</code></pre> <p>The validation command performs the following checks:</p>"},{"location":"components/cli/#y-bus-consistency","title":"Y-Bus Consistency","text":"<ul> <li>Consistency of bus admittance matrix with branch admittance data</li> <li>Y-bus matrix structure validation</li> </ul>"},{"location":"components/cli/#branch-constraints","title":"Branch Constraints","text":"<ul> <li>Deactivated lines have zero power flows and admittances</li> <li>Computed vs stored power flow consistency</li> <li>Branch loading limits (OPF mode only)</li> </ul>"},{"location":"components/cli/#generator-constraints","title":"Generator Constraints","text":"<ul> <li>Deactivated generators have zero power output</li> <li>Generator power limits validation</li> <li>Reactive power limits (OPF mode only)</li> </ul>"},{"location":"components/cli/#power-balance","title":"Power Balance","text":"<ul> <li>Bus generation consistency between bus_data and gen_data</li> <li>Power Balance</li> </ul>"},{"location":"components/cli/#data-integrity","title":"Data Integrity","text":"<ul> <li>Scenario indexing consistency across all files</li> <li>Bus indexing consistency</li> <li>Data completeness and missing value checks</li> </ul>"},{"location":"components/cli/#stats","title":"Stats","text":"<p>Compute and display statistics from generated power flow data:</p> <pre><code>gridfm-datakit stats path/to/data/directory [--sn-mva 100]\n</code></pre> <p>Arguments: - <code>data_path</code>: Path to directory containing generated parquet files (<code>bus_data.parquet</code>, <code>branch_data.parquet</code>, <code>gen_data.parquet</code>) - <code>--sn-mva</code>: Base MVA used to scale power quantities (default: 100).</p> <p>Example:</p> <pre><code>gridfm-datakit stats ./data_out/case24_ieee_rts/raw\n</code></pre> <p>This command: 1. Computes aggregated statistics across sampled partitions:    - Number of active generators and branches per scenario    - Branch loading metrics (overloads, maximum loading, all branch loadings)    - Power balance errors (active and reactive, normalized by number of buses) 2. Generates and saves <code>stats_plot.png</code> containing histogram distributions of these metrics</p> <p>The statistics help assess dataset quality, identify constraint violations (overloads), and verify power balance consistency. See the stats module documentation for details.</p>"},{"location":"components/cli/#plots","title":"Plots","text":"<p>Generate violin plots for all bus features and save them to disk:</p> <pre><code>gridfm-datakit plots path/to/data/directory [--output-dir DIR] [--sn-mva 100]\n</code></pre> <p>Arguments: - <code>data_path</code>: Path containing <code>bus_data.parquet</code> - <code>--output-dir DIR</code> (optional): Directory where plots are saved (default: <code>data_path/feature_plots</code>) - <code>--sn-mva</code> (optional): Base MVA used to normalize Pd/Qd/Pg/Qg (default: 100)</p> <p>Example:</p> <pre><code>gridfm-datakit plots ./data_out/case24_ieee_rts/raw --sn-mva 100\n</code></pre> <p>This command reads <code>bus_data.parquet</code>, normalizes power columns by <code>sn_mva</code>, and writes violin plots named <code>distribution_{feature_name}.png</code> to the output directory for quick visualization of feature distributions.</p>"},{"location":"components/generate/","title":"Generate","text":"<p>This module provides functions for generating power flow data.</p>"},{"location":"components/generate/#_setup_environment","title":"<code>_setup_environment</code>","text":"<p>Setup the environment for data generation.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict[str, Any], NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace)</p> required <p>Returns:</p> Type Description <code>Tuple[NestedNamespace, str, Dict[str, str], int]</code> <p>Tuple of (args, base_path, file_paths, seed)</p> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _setup_environment(\n    config: Union[str, Dict[str, Any], NestedNamespace],\n) -&gt; Tuple[NestedNamespace, str, Dict[str, str], int]:\n    \"\"\"Setup the environment for data generation.\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n\n    Returns:\n        Tuple of (args, base_path, file_paths, seed)\n    \"\"\"\n    # Load config from file if a path is provided\n    if isinstance(config, str):\n        with open(config, \"r\") as f:\n            config = yaml.safe_load(f)\n\n    # Convert dict to NestedNamespace if needed\n    if isinstance(config, dict):\n        args = NestedNamespace(**config)\n    else:\n        args = config\n\n        # Set global seed if provided, otherwise generate a unique seed for this generation\n    if (\n        hasattr(args.settings, \"seed\")\n        and args.settings.seed is not None\n        and args.settings.seed != \"\"\n    ):\n        seed = args.settings.seed\n        print(f\"Global random seed set to: {seed}\")\n\n    else:\n        # Generate a unique seed for non-reproducible but independent scenarios\n        # This ensures scenarios are i.i.d. within a run, but different across runs\n        import secrets\n\n        seed = secrets.randbelow(50_000)\n        # chunk_seed = seed * 20000 + start_idx + 1 &lt; 2^31 - 1\n        # seed &lt; (2,147,483,647 - n_scenarios) / 20,000 ~= 100_000 so taking 50_000 to be safe\n        print(f\"No seed provided. Using seed={seed}\")\n\n    # Setup output directory\n    base_path = os.path.join(args.settings.data_dir, args.network.name, \"raw\")\n    if os.path.exists(base_path) and args.settings.overwrite:\n        shutil.rmtree(base_path)\n    os.makedirs(base_path, exist_ok=True)\n\n    # Setup solver logs directory under data_dir/solver_log\n    solver_log_dir = (\n        os.path.join(base_path, \"solver_log\")\n        if args.settings.enable_solver_logs\n        else None\n    )\n    os.makedirs(solver_log_dir, exist_ok=True) if solver_log_dir is not None else None\n\n    # Setup file paths\n    file_paths = {\n        \"tqdm_log\": os.path.join(base_path, \"tqdm.log\"),\n        \"error_log\": os.path.join(base_path, \"error.log\"),\n        \"args_log\": os.path.join(base_path, \"args.log\"),\n        \"solver_log_dir\": solver_log_dir,\n        \"bus_data\": os.path.join(base_path, \"bus_data.parquet\"),\n        \"branch_data\": os.path.join(base_path, \"branch_data.parquet\"),\n        \"gen_data\": os.path.join(base_path, \"gen_data.parquet\"),\n        \"y_bus_data\": os.path.join(base_path, \"y_bus_data.parquet\"),\n        \"runtime_data\": os.path.join(base_path, \"runtime_data.parquet\"),\n        \"scenarios\": os.path.join(\n            base_path,\n            f\"scenarios_{args.load.generator}.parquet\",\n        ),\n        \"scenarios_plot\": os.path.join(\n            base_path,\n            f\"scenarios_{args.load.generator}.html\",\n        ),\n        \"scenarios_log\": os.path.join(\n            base_path,\n            f\"scenarios_{args.load.generator}.log\",\n        ),\n    }\n\n    # Initialize logs\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    for log_file in [\n        file_paths[\"tqdm_log\"],\n        file_paths[\"error_log\"],\n        file_paths[\"scenarios_log\"],\n        file_paths[\"args_log\"],\n    ]:\n        with open(log_file, \"a\") as f:\n            f.write(f\"\\nNew generation started at {timestamp}\\n\")\n            if log_file == file_paths[\"args_log\"]:\n                yaml.safe_dump(args.to_dict(), f)\n\n    return args, base_path, file_paths, seed\n</code></pre>"},{"location":"components/generate/#_prepare_network_and_scenarios","title":"<code>_prepare_network_and_scenarios</code>","text":"<p>Prepare the network and generate load scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration object</p> required <code>file_paths</code> <code>Dict[str, str]</code> <p>Dictionary of file paths</p> required <code>seed</code> <code>int</code> <p>Global random seed for reproducibility.</p> required <p>Returns:</p> Type Description <code>Tuple[Network, ndarray]</code> <p>Tuple of (network, scenarios)</p> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _prepare_network_and_scenarios(\n    args: NestedNamespace,\n    file_paths: Dict[str, str],\n    seed: int,\n) -&gt; Tuple[Network, np.ndarray]:\n    \"\"\"Prepare the network and generate load scenarios.\n\n    Args:\n        args: Configuration object\n        file_paths: Dictionary of file paths\n        seed: Global random seed for reproducibility.\n\n    Returns:\n        Tuple of (network, scenarios)\n    \"\"\"\n    if args.network.source == \"pglib\":\n        net = load_net_from_pglib(args.network.name)\n    elif args.network.source == \"file\":\n        net = load_net_from_file(\n            os.path.join(args.network.network_dir, args.network.name) + \".m\",\n        )\n    else:\n        raise ValueError(\"Invalid grid source!\")\n\n    # Generate load scenarios\n    load_scenario_generator = get_load_scenario_generator(args.load)\n    scenarios = load_scenario_generator(\n        net,\n        args.load.scenarios,\n        file_paths[\"scenarios_log\"],\n        max_iter=args.settings.max_iter,\n        seed=seed,\n    )\n    scenarios_df = load_scenarios_to_df(scenarios)\n    scenarios_df.to_parquet(file_paths[\"scenarios\"], index=False, engine=\"pyarrow\")\n    if net.buses.shape[0] &lt;= 100:\n        plot_load_scenarios_combined(scenarios_df, file_paths[\"scenarios_plot\"])\n    else:\n        print(\"Skipping plot of scenarios for large networks (number of buses &gt; 100)\")\n\n    return net, scenarios\n</code></pre>"},{"location":"components/generate/#_save_generated_data","title":"<code>_save_generated_data</code>","text":"<p>Save the generated data to files.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>Network object</p> required <code>processed_data</code> <code>List</code> <p>List of processed data arrays</p> required <code>file_paths</code> <code>Dict[str, str]</code> <p>Dictionary of file paths</p> required <code>base_path</code> <code>str</code> <p>Base output directory</p> required <code>args</code> <code>NestedNamespace</code> <p>Configuration object</p> required Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _save_generated_data(\n    net: Network,\n    processed_data: List,\n    file_paths: Dict[str, str],\n    base_path: str,\n    args: NestedNamespace,\n) -&gt; None:\n    \"\"\"Save the generated data to files.\n\n    Args:\n        net: Network object\n        processed_data: List of processed data arrays\n        file_paths: Dictionary of file paths\n        base_path: Base output directory\n        args: Configuration object\n    \"\"\"\n    if len(processed_data) &gt; 0:\n        save_node_edge_data(\n            net,\n            file_paths[\"bus_data\"],\n            file_paths[\"branch_data\"],\n            file_paths[\"gen_data\"],\n            file_paths[\"y_bus_data\"],\n            file_paths[\"runtime_data\"],\n            processed_data,\n            include_dc_res=args.settings.include_dc_res,\n        )\n</code></pre>"},{"location":"components/generate/#generate_power_flow_data","title":"<code>generate_power_flow_data</code>","text":"<p>Generate power flow data based on the provided configuration using sequential processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict[str, Any], NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace) The config must include settings, network, load, and perturbation configurations.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary with paths to generated artifacts:</p> <code>Dict[str, str]</code> <p>{ 'tqdm_log': progress log file, 'error_log': error log file, 'args_log': configuration dump file, 'bus_data': bus-level features CSV (BUS_COLUMNS), 'branch_data': branch-level features CSV (BRANCH_COLUMNS), 'gen_data': generator features CSV (GEN_COLUMNS), 'y_bus_data': Y-bus nonzero entries CSV, 'scenarios': load scenarios Parquet, 'scenarios_plot': load scenarios plot HTML, 'scenarios_log': load scenario generation log</p> <code>Dict[str, str]</code> <p>}</p> Note <p>The function creates output files under {settings.data_dir}/{network.name}/raw/:</p> <ul> <li>tqdm.log: Progress tracking</li> <li>error.log: Error messages</li> <li>args.log: Configuration parameters (YAML dump)</li> <li>bus_data.parquet: Bus-level features for each scenario</li> <li>branch_data.parquet: Branch-level features for each scenario</li> <li>gen_data.parquet: Generator features for each scenario</li> <li>y_bus_data.parquet: Nonzero Y-bus entries for each scenario</li> <li>scenarios_{generator}.parquet: Load scenarios (per-element time series)</li> <li>scenarios_{generator}.html: Load scenario plots</li> <li>scenarios_{generator}.log: Load scenario generation notes</li> </ul> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def generate_power_flow_data(\n    config: Union[str, Dict[str, Any], NestedNamespace],\n) -&gt; Dict[str, str]:\n    \"\"\"Generate power flow data based on the provided configuration using sequential processing.\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n            The config must include settings, network, load, and perturbation configurations.\n\n    Returns:\n        Dictionary with paths to generated artifacts:\n        {\n            'tqdm_log': progress log file,\n            'error_log': error log file,\n            'args_log': configuration dump file,\n            'bus_data': bus-level features CSV (BUS_COLUMNS),\n            'branch_data': branch-level features CSV (BRANCH_COLUMNS),\n            'gen_data': generator features CSV (GEN_COLUMNS),\n            'y_bus_data': Y-bus nonzero entries CSV,\n            'scenarios': load scenarios Parquet,\n            'scenarios_plot': load scenarios plot HTML,\n            'scenarios_log': load scenario generation log\n        }\n\n    Note:\n        The function creates output files under {settings.data_dir}/{network.name}/raw/:\n\n        - tqdm.log: Progress tracking\n        - error.log: Error messages\n        - args.log: Configuration parameters (YAML dump)\n        - bus_data.parquet: Bus-level features for each scenario\n        - branch_data.parquet: Branch-level features for each scenario\n        - gen_data.parquet: Generator features for each scenario\n        - y_bus_data.parquet: Nonzero Y-bus entries for each scenario\n        - scenarios_{generator}.parquet: Load scenarios (per-element time series)\n        - scenarios_{generator}.html: Load scenario plots\n        - scenarios_{generator}.log: Load scenario generation notes\n    \"\"\"\n\n    # Setup environment\n    args, base_path, file_paths, seed = _setup_environment(config)\n\n    # Prepare network and scenarios\n    net, scenarios = _prepare_network_and_scenarios(args, file_paths, seed)\n\n    # Initialize topology generator\n    topology_generator = initialize_topology_generator(args.topology_perturbation, net)\n\n    # Initialize generation generator\n    generation_generator = initialize_generation_generator(\n        args.generation_perturbation,\n        net,\n    )\n\n    # Initialize admittance generator\n    admittance_generator = initialize_admittance_generator(\n        args.admittance_perturbation,\n        net,\n    )\n\n    jl = init_julia(args.settings.max_iter, file_paths[\"solver_log_dir\"])\n\n    processed_data = []\n\n    # Process scenarios sequentially with deterministic seed\n    # Use custom_seed to control randomness for reproducibility\n    with custom_seed(seed + 1):\n        with open(file_paths[\"tqdm_log\"], \"a\") as f:\n            with tqdm(\n                total=args.load.scenarios,\n                desc=\"Processing scenarios\",\n                file=Tee(sys.stdout, f),\n                miniters=5,\n            ) as pbar:\n                for scenario_index in range(args.load.scenarios):\n                    # Process the scenario\n                    if args.settings.mode == \"opf\":\n                        processed_data = process_scenario_opf_mode(\n                            net,\n                            scenarios,\n                            scenario_index,\n                            topology_generator,\n                            generation_generator,\n                            admittance_generator,\n                            processed_data,\n                            file_paths[\"error_log\"],\n                            args.settings.include_dc_res,\n                            jl,\n                        )\n                    elif args.settings.mode == \"pf\":\n                        processed_data = process_scenario_pf_mode(\n                            net,\n                            scenarios,\n                            scenario_index,\n                            topology_generator,\n                            generation_generator,\n                            admittance_generator,\n                            processed_data,\n                            file_paths[\"error_log\"],\n                            args.settings.include_dc_res,\n                            args.settings.pf_fast,\n                            args.settings.dcpf_fast,\n                            jl,\n                        )\n                    else:\n                        raise ValueError(\"Invalid mode!\")\n\n                    pbar.update(1)\n\n    # Save final data\n    _save_generated_data(\n        net,\n        processed_data,\n        file_paths,\n        base_path,\n        args,\n    )\n\n    return file_paths\n</code></pre>"},{"location":"components/generate/#generate_power_flow_data_distributed","title":"<code>generate_power_flow_data_distributed</code>","text":"<p>Generate power flow data based on the provided configuration using distributed processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict[str, Any], NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace) The config must include settings, network, load, and perturbation configurations.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary with paths to generated artifacts (same as generate_power_flow_data)</p> Note <p>The function creates output files under {settings.data_dir}/{network.name}/raw/:</p> <ul> <li>tqdm.log: Progress tracking</li> <li>error.log: Error messages</li> <li>args.log: Configuration parameters (YAML dump)</li> <li>bus_data.parquet: Bus-level features for each scenario</li> <li>branch_data.parquet: Branch-level features for each scenario</li> <li>gen_data.parquet: Generator features for each scenario</li> <li>y_bus_data.parquet: Nonzero Y-bus entries for each scenario</li> <li>scenarios_{generator}.parquet: Load scenarios (per-element time series)</li> <li>scenarios_{generator}.html: Load scenario plots</li> <li>scenarios_{generator}.log: Load scenario generation notes</li> </ul> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def generate_power_flow_data_distributed(\n    config: Union[str, Dict[str, Any], NestedNamespace],\n) -&gt; Dict[str, str]:\n    \"\"\"Generate power flow data based on the provided configuration using distributed processing.\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n            The config must include settings, network, load, and perturbation configurations.\n\n    Returns:\n        Dictionary with paths to generated artifacts (same as generate_power_flow_data)\n\n    Note:\n        The function creates output files under {settings.data_dir}/{network.name}/raw/:\n\n        - tqdm.log: Progress tracking\n        - error.log: Error messages\n        - args.log: Configuration parameters (YAML dump)\n        - bus_data.parquet: Bus-level features for each scenario\n        - branch_data.parquet: Branch-level features for each scenario\n        - gen_data.parquet: Generator features for each scenario\n        - y_bus_data.parquet: Nonzero Y-bus entries for each scenario\n        - scenarios_{generator}.parquet: Load scenarios (per-element time series)\n        - scenarios_{generator}.html: Load scenario plots\n        - scenarios_{generator}.log: Load scenario generation notes\n    \"\"\"\n    # Setup environment\n    args, base_path, file_paths, seed = _setup_environment(config)\n\n    # check if mode is valid\n    if args.settings.mode not in [\"opf\", \"pf\"]:\n        raise ValueError(\"Invalid mode!\")\n\n    # Prepare network and scenarios\n    net, scenarios = _prepare_network_and_scenarios(args, file_paths, seed)\n\n    # Initialize topology generator\n    topology_generator = initialize_topology_generator(args.topology_perturbation, net)\n\n    # Initialize generation generator\n    generation_generator = initialize_generation_generator(\n        args.generation_perturbation,\n        net,\n    )\n\n    # Initialize admittance generator\n    admittance_generator = initialize_admittance_generator(\n        args.admittance_perturbation,\n        net,\n    )\n\n    # Setup multiprocessing\n    manager = Manager()\n    progress_queue = manager.Queue()\n\n    # Process scenarios in chunks\n    large_chunks = np.array_split(\n        range(args.load.scenarios),\n        np.ceil(args.load.scenarios / args.settings.large_chunk_size).astype(int),\n    )\n\n    with open(file_paths[\"tqdm_log\"], \"a\") as f:\n        with tqdm(\n            total=args.load.scenarios,\n            desc=\"Processing scenarios\",\n            file=Tee(sys.stdout, f),\n            miniters=5,\n        ) as pbar:\n            for large_chunk_index, large_chunk in enumerate(large_chunks):\n                write_ram_usage_distributed(f)\n                chunk_size = len(large_chunk)\n                scenario_chunks = np.array_split(\n                    large_chunk,\n                    min(args.settings.num_processes, chunk_size),\n                )\n\n                tasks = [\n                    (\n                        args.settings.mode,\n                        chunk[0],\n                        chunk[-1] + 1,\n                        scenarios,\n                        net,\n                        progress_queue,\n                        topology_generator,\n                        generation_generator,\n                        admittance_generator,\n                        file_paths[\"error_log\"],\n                        args.settings.include_dc_res,\n                        args.settings.pf_fast,\n                        args.settings.dcpf_fast,\n                        file_paths[\"solver_log_dir\"],\n                        args.settings.max_iter,\n                        seed,\n                    )\n                    for chunk in scenario_chunks\n                ]\n\n                # Run parallel processing\n                with Pool(processes=args.settings.num_processes) as pool:\n                    results = [\n                        pool.apply_async(process_scenario_chunk, task) for task in tasks\n                    ]\n\n                    # Update progress\n                    completed = 0\n                    while completed &lt; chunk_size:\n                        progress_queue.get()\n                        pbar.update(1)\n                        completed += 1\n\n                    # Gather results\n                    processed_data = []\n\n                    for result in results:\n                        (\n                            e,\n                            traceback,\n                            local_processed_data,\n                        ) = result.get()\n                        if isinstance(e, Exception):\n                            print(f\"Error in process_scenario_chunk: {e}\")\n                            print(traceback)\n                            sys.exit(e)\n                        processed_data.extend(local_processed_data)\n\n                    pool.close()\n                    pool.join()\n\n                # Save processed data\n                _save_generated_data(\n                    net,\n                    processed_data,\n                    file_paths,\n                    base_path,\n                    args,\n                )\n\n                del processed_data\n                gc.collect()\n\n    return file_paths\n</code></pre>"},{"location":"components/generator_perturbation/","title":"Generator Perturbations","text":""},{"location":"components/generator_perturbation/#base-classes","title":"Base Classes","text":""},{"location":"components/generator_perturbation/#generationgenerator","title":"<code>GenerationGenerator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for applying perturbations to generator elements in a network.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>class GenerationGenerator(ABC):\n    \"\"\"Abstract base class for applying perturbations to generator elements\n    in a network.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the generation generator.\"\"\"\n        pass\n\n    @abstractmethod\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Union[Generator[Network, None, None], List[Network]]:\n        \"\"\"Generate generation perturbations.\n\n        Args:\n            example_generator: A generator producing example (load/topology/generation)\n                scenarios to which generator cost perturbations are added.\n\n        Yields:\n            A generation-perturbed scenario.\n        \"\"\"\n        pass\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the generation generator.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the generation generator.\"\"\"\n    pass\n</code></pre> <code>generate(example_generator)</code> <code>abstractmethod</code> \u00b6 <p>Generate generation perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which generator cost perturbations are added.</p> required <p>Yields:</p> Type Description <code>Union[Generator[Network, None, None], List[Network]]</code> <p>A generation-perturbed scenario.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>@abstractmethod\ndef generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Union[Generator[Network, None, None], List[Network]]:\n    \"\"\"Generate generation perturbations.\n\n    Args:\n        example_generator: A generator producing example (load/topology/generation)\n            scenarios to which generator cost perturbations are added.\n\n    Yields:\n        A generation-perturbed scenario.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"components/generator_perturbation/#concrete-implementations","title":"Concrete Implementations","text":""},{"location":"components/generator_perturbation/#nogenperturbationgenerator","title":"<code>NoGenPerturbationGenerator</code>","text":"<p>               Bases: <code>GenerationGenerator</code></p> <p>Generator that yields the original network generator without any perturbations.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>class NoGenPerturbationGenerator(GenerationGenerator):\n    \"\"\"Generator that yields the original network generator without any perturbations.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the no-perturbation generator\"\"\"\n        pass\n\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Yield the original examples without any perturbations.\n\n        Args:\n            example_generator: A generator producing example (load/topology/generation)\n                scenarios to which generator cost perturbations should be applied.\n\n        Yields:\n            The original example produced by the example_generator.\n        \"\"\"\n        for example in example_generator:\n            yield example\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the no-perturbation generator</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the no-perturbation generator\"\"\"\n    pass\n</code></pre> <code>generate(example_generator)</code> \u00b6 <p>Yield the original examples without any perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which generator cost perturbations should be applied.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>The original example produced by the example_generator.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Yield the original examples without any perturbations.\n\n    Args:\n        example_generator: A generator producing example (load/topology/generation)\n            scenarios to which generator cost perturbations should be applied.\n\n    Yields:\n        The original example produced by the example_generator.\n    \"\"\"\n    for example in example_generator:\n        yield example\n</code></pre>"},{"location":"components/generator_perturbation/#permutegencostgenerator","title":"<code>PermuteGenCostGenerator</code>","text":"<p>               Bases: <code>GenerationGenerator</code></p> <p>Class for permuting generator costs.</p> <p>This class is for generating different generation scenarios by permuting cost coefficients between and among generators of power grid networks. Only generators with non-zero linear (c1) or quadratic (c2) cost coefficients are permuted, preserving zero-cost and constant-only generators.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>class PermuteGenCostGenerator(GenerationGenerator):\n    \"\"\"Class for permuting generator costs.\n\n    This class is for generating different generation scenarios\n    by permuting cost coefficients between and among generators\n    of power grid networks. Only generators with non-zero linear (c1)\n    or quadratic (c2) cost coefficients are permuted, preserving\n    zero-cost and constant-only generators.\n    \"\"\"\n\n    def __init__(self, base_net: Network) -&gt; None:\n        \"\"\"\n        Initialize the gen-cost permuation generator.\n\n        Args:\n            base_net: The base power network.\n        \"\"\"\n        self.base_net = base_net\n        self.num_gens = base_net.gens.shape[0]  # acount for deactivated generators\n        assert np.all(base_net.gencosts[:, NCOST] == base_net.gencosts[:, NCOST][0]), (\n            \"All generators must have the same number of cost coefficients\"\n        )\n\n        # Identify generators to permute (skip zero-cost and constant-only cost)\n        costs = base_net.gencosts[\n            :,\n            COST:,\n        ]  # all cost coefficients [c2, c1, c0] for NCOST=3\n        # Keep only generators with non-constant terms (c1, c2, ...) non-zero\n        # costs[:, :-1] excludes the last coefficient (c0, the constant term)\n        self.permutable_mask = np.any(costs[:, :-1] != 0, axis=1)\n        self.permutable_indices = np.where(self.permutable_mask)[0]\n\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Generate a network with permuted generator cost coefficients.\n\n        Args:\n            example_generator: A generator producing example\n                (load/topology/generation) scenarios to which generator\n                cost coefficient permutations should be applied.\n\n        Yields:\n            An example scenario with cost coeffiecients in the\n            poly_cost table permuted (only for dispatchable generators)\n        \"\"\"\n        for scenario in example_generator:\n            # Only permute the selected generators\n            new_idx = np.random.permutation(self.permutable_indices)\n            # Permute the rows (generators) of the cost coefficients (and NCOST, although we assume it is the same for all generators)\n            scenario.gencosts[self.permutable_indices, NCOST:] = scenario.gencosts[\n                new_idx,\n                NCOST:,\n            ]\n            yield scenario\n</code></pre> <code>__init__(base_net)</code> \u00b6 <p>Initialize the gen-cost permuation generator.</p> <p>Parameters:</p> Name Type Description Default <code>base_net</code> <code>Network</code> <p>The base power network.</p> required Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def __init__(self, base_net: Network) -&gt; None:\n    \"\"\"\n    Initialize the gen-cost permuation generator.\n\n    Args:\n        base_net: The base power network.\n    \"\"\"\n    self.base_net = base_net\n    self.num_gens = base_net.gens.shape[0]  # acount for deactivated generators\n    assert np.all(base_net.gencosts[:, NCOST] == base_net.gencosts[:, NCOST][0]), (\n        \"All generators must have the same number of cost coefficients\"\n    )\n\n    # Identify generators to permute (skip zero-cost and constant-only cost)\n    costs = base_net.gencosts[\n        :,\n        COST:,\n    ]  # all cost coefficients [c2, c1, c0] for NCOST=3\n    # Keep only generators with non-constant terms (c1, c2, ...) non-zero\n    # costs[:, :-1] excludes the last coefficient (c0, the constant term)\n    self.permutable_mask = np.any(costs[:, :-1] != 0, axis=1)\n    self.permutable_indices = np.where(self.permutable_mask)[0]\n</code></pre> <code>generate(example_generator)</code> \u00b6 <p>Generate a network with permuted generator cost coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology/generation) scenarios to which generator cost coefficient permutations should be applied.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>An example scenario with cost coeffiecients in the</p> <code>Network</code> <p>poly_cost table permuted (only for dispatchable generators)</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Generate a network with permuted generator cost coefficients.\n\n    Args:\n        example_generator: A generator producing example\n            (load/topology/generation) scenarios to which generator\n            cost coefficient permutations should be applied.\n\n    Yields:\n        An example scenario with cost coeffiecients in the\n        poly_cost table permuted (only for dispatchable generators)\n    \"\"\"\n    for scenario in example_generator:\n        # Only permute the selected generators\n        new_idx = np.random.permutation(self.permutable_indices)\n        # Permute the rows (generators) of the cost coefficients (and NCOST, although we assume it is the same for all generators)\n        scenario.gencosts[self.permutable_indices, NCOST:] = scenario.gencosts[\n            new_idx,\n            NCOST:,\n        ]\n        yield scenario\n</code></pre>"},{"location":"components/generator_perturbation/#perturbgencostgenerator","title":"<code>PerturbGenCostGenerator</code>","text":"<p>               Bases: <code>GenerationGenerator</code></p> <p>Class for perturbing generator cost.</p> <p>This class is for generating different generation scenarios by randomly perturbing cost coefficients of generators in a power network by multiplying with a scaling factor sampled from a uniform distribution. Only generators with non-zero linear (c1) or quadratic (c2) cost coefficients are perturbed, preserving zero-cost and constant-only generators.</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>class PerturbGenCostGenerator(GenerationGenerator):\n    \"\"\"Class for perturbing generator cost.\n\n    This class is for generating different generation scenarios\n    by randomly perturbing cost coefficients of generators in a\n    power network by multiplying with a scaling factor sampled\n    from a uniform distribution. Only generators with non-zero\n    linear (c1) or quadratic (c2) cost coefficients are perturbed,\n    preserving zero-cost and constant-only generators.\n    \"\"\"\n\n    def __init__(self, base_net: Network, sigma: float) -&gt; None:\n        \"\"\"\n        Initialize the gen-cost perturbation generator.\n\n        Args:\n            base_net: The base power network.\n            sigma: A constant that specifies the range from which to draw\n                samples from a uniform distribution to be used as a scaling\n                factor for cost coefficient perturbations. The range is\n                set as [max([0, 1-sigma]), 1+sigma).\n        \"\"\"\n        self.base_net = base_net\n        self.num_gens = base_net.gens.shape[0]  # acount for deactivated generators\n        # assert all generators have the same number of cost coefficients\n        assert np.all(base_net.gencosts[:, NCOST] == base_net.gencosts[:, NCOST][0]), (\n            \"All generators must have the same number of cost coefficients\"\n        )\n        n_costs = int(base_net.gencosts[:, NCOST][0])\n        self.lower = np.max([0.0, 1.0 - sigma])\n        self.upper = 1.0 + sigma\n\n        # Mask generators to perturb (skip zero-cost or constant-only)\n        costs = base_net.gencosts[\n            :,\n            COST:,\n        ]  # all cost coefficients [c2, c1, c0] for NCOST=3\n        # Keep only generators with non-constant terms (c1, c2, ...) non-zero\n        # costs[:, :-1] excludes the last coefficient (c0, the constant term)\n        self.perturb_mask = np.any(costs[:, :-1] != 0, axis=1)\n        self.n_perturbable = np.sum(self.perturb_mask)\n\n        # Sample size for only the perturbable generators\n        self.sample_size = [self.n_perturbable, n_costs]\n\n    def generate(\n        self,\n        example_generator: Generator[Network, None, None],\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Generate a network with perturbed generator cost coefficients.\n\n        Args:\n            example_generator: A generator producing example (load/topology) scenarios\n                to which generator cost coefficient perturbations should be added.\n\n        Yields:\n            An example scenario with cost coeffiecients in the poly_cost\n            table perturbed by multiplying with a scaling factor (only for dispatchable generators).\n        \"\"\"\n        for example in example_generator:\n            # Generate scaling factors only for generators that can be perturbed\n            scale_fact = np.random.uniform(\n                low=self.lower,\n                high=self.upper,\n                size=self.sample_size,\n            )\n            # Apply scaling only to selected generators\n            example.gencosts[self.perturb_mask, COST:] = (\n                example.gencosts[self.perturb_mask, COST:] * scale_fact\n            )\n            yield example\n</code></pre> <code>__init__(base_net, sigma)</code> \u00b6 <p>Initialize the gen-cost perturbation generator.</p> <p>Parameters:</p> Name Type Description Default <code>base_net</code> <code>Network</code> <p>The base power network.</p> required <code>sigma</code> <code>float</code> <p>A constant that specifies the range from which to draw samples from a uniform distribution to be used as a scaling factor for cost coefficient perturbations. The range is set as [max([0, 1-sigma]), 1+sigma).</p> required Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def __init__(self, base_net: Network, sigma: float) -&gt; None:\n    \"\"\"\n    Initialize the gen-cost perturbation generator.\n\n    Args:\n        base_net: The base power network.\n        sigma: A constant that specifies the range from which to draw\n            samples from a uniform distribution to be used as a scaling\n            factor for cost coefficient perturbations. The range is\n            set as [max([0, 1-sigma]), 1+sigma).\n    \"\"\"\n    self.base_net = base_net\n    self.num_gens = base_net.gens.shape[0]  # acount for deactivated generators\n    # assert all generators have the same number of cost coefficients\n    assert np.all(base_net.gencosts[:, NCOST] == base_net.gencosts[:, NCOST][0]), (\n        \"All generators must have the same number of cost coefficients\"\n    )\n    n_costs = int(base_net.gencosts[:, NCOST][0])\n    self.lower = np.max([0.0, 1.0 - sigma])\n    self.upper = 1.0 + sigma\n\n    # Mask generators to perturb (skip zero-cost or constant-only)\n    costs = base_net.gencosts[\n        :,\n        COST:,\n    ]  # all cost coefficients [c2, c1, c0] for NCOST=3\n    # Keep only generators with non-constant terms (c1, c2, ...) non-zero\n    # costs[:, :-1] excludes the last coefficient (c0, the constant term)\n    self.perturb_mask = np.any(costs[:, :-1] != 0, axis=1)\n    self.n_perturbable = np.sum(self.perturb_mask)\n\n    # Sample size for only the perturbable generators\n    self.sample_size = [self.n_perturbable, n_costs]\n</code></pre> <code>generate(example_generator)</code> \u00b6 <p>Generate a network with perturbed generator cost coefficients.</p> <p>Parameters:</p> Name Type Description Default <code>example_generator</code> <code>Generator[Network, None, None]</code> <p>A generator producing example (load/topology) scenarios to which generator cost coefficient perturbations should be added.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>An example scenario with cost coeffiecients in the poly_cost</p> <code>Network</code> <p>table perturbed by multiplying with a scaling factor (only for dispatchable generators).</p> Source code in <code>gridfm_datakit/perturbations/generator_perturbation.py</code> <pre><code>def generate(\n    self,\n    example_generator: Generator[Network, None, None],\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Generate a network with perturbed generator cost coefficients.\n\n    Args:\n        example_generator: A generator producing example (load/topology) scenarios\n            to which generator cost coefficient perturbations should be added.\n\n    Yields:\n        An example scenario with cost coeffiecients in the poly_cost\n        table perturbed by multiplying with a scaling factor (only for dispatchable generators).\n    \"\"\"\n    for example in example_generator:\n        # Generate scaling factors only for generators that can be perturbed\n        scale_fact = np.random.uniform(\n            low=self.lower,\n            high=self.upper,\n            size=self.sample_size,\n        )\n        # Apply scaling only to selected generators\n        example.gencosts[self.perturb_mask, COST:] = (\n            example.gencosts[self.perturb_mask, COST:] * scale_fact\n        )\n        yield example\n</code></pre>"},{"location":"components/load/","title":"Load Perturbations","text":"<p>This module provides functions and classes for generating load scenarios.</p>"},{"location":"components/load/#classes","title":"Classes","text":""},{"location":"components/load/#loadscenariogeneratorbase","title":"<code>LoadScenarioGeneratorBase</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for load scenario generators.</p> <p>This class defines the interface and common functionality for generating load scenarios for power grid networks.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class LoadScenarioGeneratorBase(ABC):\n    \"\"\"Abstract base class for load scenario generators.\n\n    This class defines the interface and common functionality for generating\n    load scenarios for power grid networks.\n    \"\"\"\n\n    @abstractmethod\n    def __call__(\n        self,\n        net: Network,\n        n_scenarios: int,\n        scenario_log: str,\n        max_iter: int,\n        seed: int,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load scenarios for a power network.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenario_log: Path to log file for scenario generation details.\n            max_iter: Maximum iterations for the OPF solver.\n            seed: Global random seed for reproducibility.\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def interpolate_row(row: np.ndarray, data_points: int) -&gt; np.ndarray:\n        \"\"\"Interpolates a row of data to match the desired number of data points.\n\n        Args:\n            row: Input data array to interpolate.\n            data_points: Number of points in the output array.\n\n        Returns:\n            numpy.ndarray: Interpolated data array of length data_points.\n        \"\"\"\n        if np.all(row == 0):\n            return np.zeros(data_points)\n        x_original = np.linspace(1, len(row), len(row))\n        x_target = np.linspace(1, len(row), data_points)\n        return interp1d(x_original, row, kind=\"linear\")(x_target)\n\n    @staticmethod\n    def find_largest_scaling_factor(\n        net: Network,\n        max_scaling: float,\n        step_size: float,\n        start: float,\n        change_reactive_power: bool,\n        max_iter: int,\n    ) -&gt; Tuple[Pool, Any]:\n        \"\"\"Finds the largest load scaling factor that maintains OPF convergence.\n\n        Args:\n            net: The power network.\n            max_scaling: Maximum scaling factor to try.\n            step_size: Increment for scaling factor search.\n            start: Starting scaling factor.\n            change_reactive_power: Whether to scale reactive power.\n            max_iter: Maximum iterations for the OPF solver.\n\n        Returns:\n            float: Largest scaling factor that maintains OPF convergence.\n\n        Raises:\n            RuntimeError: If OPF does not converge for the starting value.\n        \"\"\"\n        pool = Pool(processes=1)\n        result = pool.apply_async(\n            _find_largest_scaling_factor_worker,\n            ((net, max_scaling, step_size, start, change_reactive_power, max_iter),),\n        )\n        return pool, result\n\n    @staticmethod\n    def min_max_scale(series: np.ndarray, new_min: float, new_max: float) -&gt; np.ndarray:\n        \"\"\"Scales a series of values to a new range using min-max normalization.\n\n        Args:\n            series: Input data array to scale.\n            new_min: Minimum value of the output range.\n            new_max: Maximum value of the output range.\n\n        Returns:\n            numpy.ndarray: Scaled data array.\n        \"\"\"\n        old_min, old_max = np.min(series), np.max(series)\n        if old_max == old_min:\n            return np.ones_like(series) * new_min\n        else:\n            return new_min + (series - old_min) * (new_max - new_min) / (\n                old_max - old_min\n            )\n</code></pre> <code>__call__(net, n_scenarios, scenario_log, max_iter, seed)</code> <code>abstractmethod</code> \u00b6 <p>Generates load scenarios for a power network.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenario_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <code>max_iter</code> <code>int</code> <p>Maximum iterations for the OPF solver.</p> required <code>seed</code> <code>int</code> <p>Global random seed for reproducibility.</p> required <p>Returns:     numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@abstractmethod\ndef __call__(\n    self,\n    net: Network,\n    n_scenarios: int,\n    scenario_log: str,\n    max_iter: int,\n    seed: int,\n) -&gt; np.ndarray:\n    \"\"\"Generates load scenarios for a power network.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenario_log: Path to log file for scenario generation details.\n        max_iter: Maximum iterations for the OPF solver.\n        seed: Global random seed for reproducibility.\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n    \"\"\"\n    pass\n</code></pre> <code>find_largest_scaling_factor(net, max_scaling, step_size, start, change_reactive_power, max_iter)</code> <code>staticmethod</code> \u00b6 <p>Finds the largest load scaling factor that maintains OPF convergence.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>max_scaling</code> <code>float</code> <p>Maximum scaling factor to try.</p> required <code>step_size</code> <code>float</code> <p>Increment for scaling factor search.</p> required <code>start</code> <code>float</code> <p>Starting scaling factor.</p> required <code>change_reactive_power</code> <code>bool</code> <p>Whether to scale reactive power.</p> required <code>max_iter</code> <code>int</code> <p>Maximum iterations for the OPF solver.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>Tuple[Pool, Any]</code> <p>Largest scaling factor that maintains OPF convergence.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If OPF does not converge for the starting value.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef find_largest_scaling_factor(\n    net: Network,\n    max_scaling: float,\n    step_size: float,\n    start: float,\n    change_reactive_power: bool,\n    max_iter: int,\n) -&gt; Tuple[Pool, Any]:\n    \"\"\"Finds the largest load scaling factor that maintains OPF convergence.\n\n    Args:\n        net: The power network.\n        max_scaling: Maximum scaling factor to try.\n        step_size: Increment for scaling factor search.\n        start: Starting scaling factor.\n        change_reactive_power: Whether to scale reactive power.\n        max_iter: Maximum iterations for the OPF solver.\n\n    Returns:\n        float: Largest scaling factor that maintains OPF convergence.\n\n    Raises:\n        RuntimeError: If OPF does not converge for the starting value.\n    \"\"\"\n    pool = Pool(processes=1)\n    result = pool.apply_async(\n        _find_largest_scaling_factor_worker,\n        ((net, max_scaling, step_size, start, change_reactive_power, max_iter),),\n    )\n    return pool, result\n</code></pre> <code>interpolate_row(row, data_points)</code> <code>staticmethod</code> \u00b6 <p>Interpolates a row of data to match the desired number of data points.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>ndarray</code> <p>Input data array to interpolate.</p> required <code>data_points</code> <code>int</code> <p>Number of points in the output array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Interpolated data array of length data_points.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef interpolate_row(row: np.ndarray, data_points: int) -&gt; np.ndarray:\n    \"\"\"Interpolates a row of data to match the desired number of data points.\n\n    Args:\n        row: Input data array to interpolate.\n        data_points: Number of points in the output array.\n\n    Returns:\n        numpy.ndarray: Interpolated data array of length data_points.\n    \"\"\"\n    if np.all(row == 0):\n        return np.zeros(data_points)\n    x_original = np.linspace(1, len(row), len(row))\n    x_target = np.linspace(1, len(row), data_points)\n    return interp1d(x_original, row, kind=\"linear\")(x_target)\n</code></pre> <code>min_max_scale(series, new_min, new_max)</code> <code>staticmethod</code> \u00b6 <p>Scales a series of values to a new range using min-max normalization.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>ndarray</code> <p>Input data array to scale.</p> required <code>new_min</code> <code>float</code> <p>Minimum value of the output range.</p> required <code>new_max</code> <code>float</code> <p>Maximum value of the output range.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Scaled data array.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef min_max_scale(series: np.ndarray, new_min: float, new_max: float) -&gt; np.ndarray:\n    \"\"\"Scales a series of values to a new range using min-max normalization.\n\n    Args:\n        series: Input data array to scale.\n        new_min: Minimum value of the output range.\n        new_max: Maximum value of the output range.\n\n    Returns:\n        numpy.ndarray: Scaled data array.\n    \"\"\"\n    old_min, old_max = np.min(series), np.max(series)\n    if old_max == old_min:\n        return np.ones_like(series) * new_min\n    else:\n        return new_min + (series - old_min) * (new_max - new_min) / (\n            old_max - old_min\n        )\n</code></pre>"},{"location":"components/load/#loadscenariosfromaggprofile","title":"<code>LoadScenariosFromAggProfile</code>","text":"<p>               Bases: <code>LoadScenarioGeneratorBase</code></p> <p>Generates load scenarios by scaling an aggregated load profile and adding local noise.</p> <p>Overview</p> <p>This generator uses an aggregated load profile (a time series of normalized demand values) to simulate realistic variations in load over time. The process includes:</p> <ol> <li>Determining an upper bound <code>u</code> for load scaling such that the network still    supports a feasible optimal power flow (OPF) solution.</li> <li>Setting the lower bound \\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\).</li> <li>Min-max scaling the aggregate profile to the interval \\([l, u]\\).</li> <li>Applying this global scaling factor to each load's nominal value with additive uniform noise.</li> </ol> <p>Mathematical Model</p> <p>Let:</p> <ul> <li> <p>\\(n\\): Number of loads (\\(i \\in \\{1, \\dots, n\\}\\))</p> </li> <li> <p>\\(K\\): Number of scenarios (\\(k \\in \\{1, \\dots, K\\}\\))</p> </li> <li> <p>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active/reactive loads</p> </li> <li> <p>\\(\\text{agg}^k\\): Aggregated load profile value at time step \\(k\\)</p> </li> <li> <p>\\(u\\): Maximum feasible global scaling factor (from OPF)</p> </li> <li> <p>\\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\): Minimum global scaling factor</p> </li> <li> <p>\\(\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])\\): Scaled aggregate profile</p> </li> <li> <p>\\(\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Active power noise</p> </li> <li> <p>\\(\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Reactive power noise (if enabled)</p> </li> </ul> <p>Then for each load \\(i\\) and scenario \\(k\\):</p> <p>For each load \\(i\\) and scenario \\(k\\): $$ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k $$</p> \\[ \\tilde{q}_i^k = \\begin{cases} q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\ q_i &amp; \\text{otherwise} \\end{cases} \\] <p>Notes</p> <ul> <li> <p>The upper bound <code>u</code> is automatically determined by gradually increasing the base load and solving the OPF until it fails.</p> </li> <li> <p>The lower bound <code>l</code> is computed as a relative percentage (1-<code>global_range</code>) of <code>u</code>.</p> </li> <li> <p>Noise helps simulate local variability across loads within a global trend.</p> </li> </ul> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class LoadScenariosFromAggProfile(LoadScenarioGeneratorBase):\n    r\"\"\"\n    Generates load scenarios by scaling an aggregated load profile and adding local noise.\n\n    **Overview**\n\n    This generator uses an aggregated load profile (a time series of normalized demand values)\n    to simulate realistic variations in load over time. The process includes:\n\n    1. Determining an upper bound `u` for load scaling such that the network still\n       supports a feasible optimal power flow (OPF) solution.\n    2. Setting the lower bound $l = (1 - \\text{global\\textunderscore range}) \\cdot u$.\n    3. Min-max scaling the aggregate profile to the interval \\([l, u]\\).\n    4. Applying this global scaling factor to each load's nominal value with additive uniform noise.\n\n    **Mathematical Model**\n\n    Let:\n\n    - $n$: Number of loads ($i \\in \\{1, \\dots, n\\}$)\n\n    - $K$: Number of scenarios ($k \\in \\{1, \\dots, K\\}$)\n\n    - $(p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2$: Nominal active/reactive loads\n\n    - $\\text{agg}^k$: Aggregated load profile value at time step $k$\n\n    - $u$: Maximum feasible global scaling factor (from OPF)\n\n    - $l = (1 - \\text{global\\textunderscore range}) \\cdot u$: Minimum global scaling factor\n\n    - $\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])$: Scaled aggregate profile\n\n    - $\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)$: Active power noise\n\n    - $\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)$: Reactive power noise (if enabled)\n\n    Then for each load $i$ and scenario $k$:\n\n    For each load $i$ and scenario $k$:\n    $$\n    \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k\n    $$\n\n    $$\n    \\tilde{q}_i^k =\n    \\begin{cases}\n    q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\\n    q_i &amp; \\text{otherwise}\n    \\end{cases}\n    $$\n\n    **Notes**\n\n    - The upper bound `u` is automatically determined by gradually increasing the base load and solving the OPF until it fails.\n\n    - The lower bound `l` is computed as a relative percentage (1-`global_range`) of `u`.\n\n    - Noise helps simulate local variability across loads within a global trend.\n    \"\"\"\n\n    def __init__(\n        self,\n        agg_load_name: str,\n        sigma: float,\n        change_reactive_power: bool,\n        global_range: float,\n        max_scaling_factor: float,\n        step_size: float,\n        start_scaling_factor: float,\n    ):\n        \"\"\"Initializes the load scenario generator.\n\n        Args:\n            agg_load_name: Name of the aggregated load profile file.\n            sigma: Standard deviation for noise addition.\n            change_reactive_power: Whether to scale reactive power.\n            global_range: Range for scaling factor.\n            max_scaling_factor: Maximum scaling factor to try.\n            step_size: Increment for scaling factor search.\n            start_scaling_factor: Starting scaling factor.\n        \"\"\"\n        self.agg_load_name = agg_load_name\n        self.sigma = sigma\n        self.change_reactive_power = change_reactive_power\n        self.global_range = global_range\n        self.max_scaling_factor = max_scaling_factor\n        self.step_size = step_size\n        self.start_scaling_factor = start_scaling_factor\n\n    def __call__(\n        self,\n        net: Network,\n        n_scenarios: int,\n        scenarios_log: str,\n        max_iter: int,\n        seed: int,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load profiles based on aggregated load data.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenarios_log: Path to log file for scenario generation details.\n            max_iter: Maximum iterations for the OPF solver.\n            seed: Global random seed for reproducibility.\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n        Raises:\n            ValueError: If start_scaling_factor is less than global_range.\n        \"\"\"\n        if (\n            self.start_scaling_factor - self.global_range * self.start_scaling_factor\n            &lt; 0\n        ):\n            raise ValueError(\n                \"The start scaling factor must be larger than the global range.\",\n            )\n\n        pool, async_result = self.find_largest_scaling_factor(\n            net,\n            max_scaling=self.max_scaling_factor,\n            step_size=self.step_size,\n            start=self.start_scaling_factor,\n            change_reactive_power=self.change_reactive_power,\n            max_iter=max_iter,\n        )\n\n        try:\n            # wait for the worker to finish and fetch numeric result\n            u = async_result.get(timeout=None)\n        finally:\n            pool.close()\n            pool.join()\n\n        lower = (\n            u - self.global_range * u\n        )  # The lower bound used to be set as e.g. u - 40%, while now it is set as u - 40% of u\n\n        with open(scenarios_log, \"a\") as f:\n            f.write(\"u=\" + str(u) + \"\\n\")\n            f.write(\"l=\" + str(lower) + \"\\n\")\n\n        agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n            f\"{self.agg_load_name}.csv\",\n        )\n        agg_load = pd.read_csv(agg_load_path).to_numpy()\n        agg_load = agg_load.reshape(agg_load.shape[0])\n        ref_curve = self.min_max_scale(agg_load, lower, u)\n        print(\"min, max of ref_curve: {}, {}\".format(ref_curve.min(), ref_curve.max()))\n        print(\"l, u: {}, {}\".format(lower, u))\n\n        p_mw_array = net.Pd.copy()  # note that we do use buses that have 0 load, but since we only perturb the load by multiplying it by a factor, it will still be 0\n        q_mvar_array = net.Qd.copy()\n\n        # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n        if n_scenarios &lt;= ref_curve.shape[0]:\n            print(\n                \"cutting the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = ref_curve[:n_scenarios]\n        # if it is larger, we interpolate it\n        else:\n            print(\n                \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n        # Use custom_seed context manager to temporarily set seed for noise generation\n        with custom_seed(seed):\n            load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n            noise = np.random.uniform(\n                1 - self.sigma,\n                1 + self.sigma,\n                size=load_profile_pmw.shape,\n            )  # Add uniform noise\n            load_profile_pmw *= noise\n\n            if self.change_reactive_power:\n                load_profile_qmvar = q_mvar_array[:, np.newaxis] * ref_curve\n                noise = np.random.uniform(\n                    1 - self.sigma,\n                    1 + self.sigma,\n                    size=load_profile_qmvar.shape,\n                )  # Add uniform noise\n                load_profile_qmvar *= noise\n            else:\n                load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(\n                    ref_curve,\n                )\n                print(\"No change in reactive power across scenarios\")\n\n        # Stack profiles along the last dimension\n        load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n        return load_profiles\n</code></pre> <code>__call__(net, n_scenarios, scenarios_log, max_iter, seed)</code> \u00b6 <p>Generates load profiles based on aggregated load data.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenarios_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <code>max_iter</code> <code>int</code> <p>Maximum iterations for the OPF solver.</p> required <code>seed</code> <code>int</code> <p>Global random seed for reproducibility.</p> required <p>Returns:     numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If start_scaling_factor is less than global_range.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __call__(\n    self,\n    net: Network,\n    n_scenarios: int,\n    scenarios_log: str,\n    max_iter: int,\n    seed: int,\n) -&gt; np.ndarray:\n    \"\"\"Generates load profiles based on aggregated load data.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenarios_log: Path to log file for scenario generation details.\n        max_iter: Maximum iterations for the OPF solver.\n        seed: Global random seed for reproducibility.\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n    Raises:\n        ValueError: If start_scaling_factor is less than global_range.\n    \"\"\"\n    if (\n        self.start_scaling_factor - self.global_range * self.start_scaling_factor\n        &lt; 0\n    ):\n        raise ValueError(\n            \"The start scaling factor must be larger than the global range.\",\n        )\n\n    pool, async_result = self.find_largest_scaling_factor(\n        net,\n        max_scaling=self.max_scaling_factor,\n        step_size=self.step_size,\n        start=self.start_scaling_factor,\n        change_reactive_power=self.change_reactive_power,\n        max_iter=max_iter,\n    )\n\n    try:\n        # wait for the worker to finish and fetch numeric result\n        u = async_result.get(timeout=None)\n    finally:\n        pool.close()\n        pool.join()\n\n    lower = (\n        u - self.global_range * u\n    )  # The lower bound used to be set as e.g. u - 40%, while now it is set as u - 40% of u\n\n    with open(scenarios_log, \"a\") as f:\n        f.write(\"u=\" + str(u) + \"\\n\")\n        f.write(\"l=\" + str(lower) + \"\\n\")\n\n    agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n        f\"{self.agg_load_name}.csv\",\n    )\n    agg_load = pd.read_csv(agg_load_path).to_numpy()\n    agg_load = agg_load.reshape(agg_load.shape[0])\n    ref_curve = self.min_max_scale(agg_load, lower, u)\n    print(\"min, max of ref_curve: {}, {}\".format(ref_curve.min(), ref_curve.max()))\n    print(\"l, u: {}, {}\".format(lower, u))\n\n    p_mw_array = net.Pd.copy()  # note that we do use buses that have 0 load, but since we only perturb the load by multiplying it by a factor, it will still be 0\n    q_mvar_array = net.Qd.copy()\n\n    # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n    if n_scenarios &lt;= ref_curve.shape[0]:\n        print(\n            \"cutting the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = ref_curve[:n_scenarios]\n    # if it is larger, we interpolate it\n    else:\n        print(\n            \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n    # Use custom_seed context manager to temporarily set seed for noise generation\n    with custom_seed(seed):\n        load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n        noise = np.random.uniform(\n            1 - self.sigma,\n            1 + self.sigma,\n            size=load_profile_pmw.shape,\n        )  # Add uniform noise\n        load_profile_pmw *= noise\n\n        if self.change_reactive_power:\n            load_profile_qmvar = q_mvar_array[:, np.newaxis] * ref_curve\n            noise = np.random.uniform(\n                1 - self.sigma,\n                1 + self.sigma,\n                size=load_profile_qmvar.shape,\n            )  # Add uniform noise\n            load_profile_qmvar *= noise\n        else:\n            load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(\n                ref_curve,\n            )\n            print(\"No change in reactive power across scenarios\")\n\n    # Stack profiles along the last dimension\n    load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n    return load_profiles\n</code></pre> <code>__init__(agg_load_name, sigma, change_reactive_power, global_range, max_scaling_factor, step_size, start_scaling_factor)</code> \u00b6 <p>Initializes the load scenario generator.</p> <p>Parameters:</p> Name Type Description Default <code>agg_load_name</code> <code>str</code> <p>Name of the aggregated load profile file.</p> required <code>sigma</code> <code>float</code> <p>Standard deviation for noise addition.</p> required <code>change_reactive_power</code> <code>bool</code> <p>Whether to scale reactive power.</p> required <code>global_range</code> <code>float</code> <p>Range for scaling factor.</p> required <code>max_scaling_factor</code> <code>float</code> <p>Maximum scaling factor to try.</p> required <code>step_size</code> <code>float</code> <p>Increment for scaling factor search.</p> required <code>start_scaling_factor</code> <code>float</code> <p>Starting scaling factor.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __init__(\n    self,\n    agg_load_name: str,\n    sigma: float,\n    change_reactive_power: bool,\n    global_range: float,\n    max_scaling_factor: float,\n    step_size: float,\n    start_scaling_factor: float,\n):\n    \"\"\"Initializes the load scenario generator.\n\n    Args:\n        agg_load_name: Name of the aggregated load profile file.\n        sigma: Standard deviation for noise addition.\n        change_reactive_power: Whether to scale reactive power.\n        global_range: Range for scaling factor.\n        max_scaling_factor: Maximum scaling factor to try.\n        step_size: Increment for scaling factor search.\n        start_scaling_factor: Starting scaling factor.\n    \"\"\"\n    self.agg_load_name = agg_load_name\n    self.sigma = sigma\n    self.change_reactive_power = change_reactive_power\n    self.global_range = global_range\n    self.max_scaling_factor = max_scaling_factor\n    self.step_size = step_size\n    self.start_scaling_factor = start_scaling_factor\n</code></pre>"},{"location":"components/load/#powergraph","title":"<code>Powergraph</code>","text":"<p>               Bases: <code>LoadScenarioGeneratorBase</code></p> <p>Load scenario generator using the PowerGraph method.</p> <p>Generates load scenarios by scaling the nominal active power profile with a normalized reference curve while keeping reactive power fixed.</p> <p>Mathematical Model</p> <p>Let:</p> <ul> <li>\\(n\\): Number of loads (indexed by \\(i \\in \\{1, \\dots, n\\}\\))</li> <li>\\(K\\): Number of scenarios (indexed by \\(k \\in \\{1, \\dots, K\\}\\))</li> <li>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active and reactive load vectors</li> <li>\\(\\text{ref}^k \\in [0, 1]\\): Normalized aggregate reference profile at scenario \\(k\\)</li> <li>\\((\\tilde{p}_i^k, \\tilde{q}_i^k) \\in \\mathbb{R}_{\\geq 0}^2\\): Active/reactive load at bus \\(i\\) in scenario \\(k\\)</li> </ul> <p>The reference profile is computed by normalizing an aggregated profile:</p> \\[ \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k} \\] <p>Then, for each bus \\(i\\) and scenario \\(k\\):</p> \\[ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\] <p>and reactive power is kept constant:</p> \\[ \\tilde{q}_i^k = q_i \\] Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class Powergraph(LoadScenarioGeneratorBase):\n    r\"\"\"\n    Load scenario generator using the PowerGraph method.\n\n    Generates load scenarios by scaling the nominal active power profile\n    with a normalized reference curve while keeping reactive power fixed.\n\n    **Mathematical Model**\n\n    Let:\n\n    - $n$: Number of loads (indexed by $i \\in \\{1, \\dots, n\\}$)\n    - $K$: Number of scenarios (indexed by $k \\in \\{1, \\dots, K\\}$)\n    - $(p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2$: Nominal active and reactive load vectors\n    - $\\text{ref}^k \\in [0, 1]$: Normalized aggregate reference profile at scenario $k$\n    - $(\\tilde{p}_i^k, \\tilde{q}_i^k) \\in \\mathbb{R}_{\\geq 0}^2$: Active/reactive load at bus $i$ in scenario $k$\n\n    The reference profile is computed by normalizing an aggregated profile:\n\n    $$\n    \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k}\n    $$\n\n    Then, for each bus $i$ and scenario $k$:\n\n    $$\n    \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k\n    $$\n\n    and reactive power is kept constant:\n\n    $$\n    \\tilde{q}_i^k = q_i\n    $$\"\"\"\n\n    def __init__(\n        self,\n        agg_load_name: str,\n    ):\n        \"\"\"Initializes the powergraph load scenario generator.\n\n        Args:\n            agg_load_name: Name of the aggregated load profile file.\n        \"\"\"\n        self.agg_load_name = agg_load_name\n\n    def __call__(\n        self,\n        net: Network,\n        n_scenarios: int,\n        scenario_log: str,\n        max_iter: int,\n        seed: int,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load profiles based on aggregated load data.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenario_log: Path to log file for scenario generation details.\n            max_iter: Maximum iterations for the OPF solver (unused for Powergraph).\n            seed: Global random seed for reproducibility.\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n        \"\"\"\n        agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n            f\"{self.agg_load_name}.csv\",\n        )\n        agg_load = pd.read_csv(agg_load_path).to_numpy()\n        agg_load = agg_load.reshape(agg_load.shape[0])\n        ref_curve = agg_load / agg_load.max()\n        print(\"u={}, l={}\".format(ref_curve.max(), ref_curve.min()))\n\n        p_mw_array = net.Pd.copy()\n        q_mvar_array = net.Qd.copy()\n\n        # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n        if n_scenarios &lt;= ref_curve.shape[0]:\n            print(\n                \"cutting the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = ref_curve[:n_scenarios]\n        # if it is larger, we interpolate it\n        else:\n            print(\n                \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n        load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n        load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n        print(\"No change in reactive power across scenarios\")\n\n        # Stack profiles along the last dimension\n        load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n        return load_profiles\n</code></pre> <code>__call__(net, n_scenarios, scenario_log, max_iter, seed)</code> \u00b6 <p>Generates load profiles based on aggregated load data.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenario_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <code>max_iter</code> <code>int</code> <p>Maximum iterations for the OPF solver (unused for Powergraph).</p> required <code>seed</code> <code>int</code> <p>Global random seed for reproducibility.</p> required <p>Returns:     numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __call__(\n    self,\n    net: Network,\n    n_scenarios: int,\n    scenario_log: str,\n    max_iter: int,\n    seed: int,\n) -&gt; np.ndarray:\n    \"\"\"Generates load profiles based on aggregated load data.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenario_log: Path to log file for scenario generation details.\n        max_iter: Maximum iterations for the OPF solver (unused for Powergraph).\n        seed: Global random seed for reproducibility.\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n    \"\"\"\n    agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n        f\"{self.agg_load_name}.csv\",\n    )\n    agg_load = pd.read_csv(agg_load_path).to_numpy()\n    agg_load = agg_load.reshape(agg_load.shape[0])\n    ref_curve = agg_load / agg_load.max()\n    print(\"u={}, l={}\".format(ref_curve.max(), ref_curve.min()))\n\n    p_mw_array = net.Pd.copy()\n    q_mvar_array = net.Qd.copy()\n\n    # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n    if n_scenarios &lt;= ref_curve.shape[0]:\n        print(\n            \"cutting the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = ref_curve[:n_scenarios]\n    # if it is larger, we interpolate it\n    else:\n        print(\n            \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n    load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n    load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n    print(\"No change in reactive power across scenarios\")\n\n    # Stack profiles along the last dimension\n    load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n    return load_profiles\n</code></pre> <code>__init__(agg_load_name)</code> \u00b6 <p>Initializes the powergraph load scenario generator.</p> <p>Parameters:</p> Name Type Description Default <code>agg_load_name</code> <code>str</code> <p>Name of the aggregated load profile file.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __init__(\n    self,\n    agg_load_name: str,\n):\n    \"\"\"Initializes the powergraph load scenario generator.\n\n    Args:\n        agg_load_name: Name of the aggregated load profile file.\n    \"\"\"\n    self.agg_load_name = agg_load_name\n</code></pre>"},{"location":"components/load/#load_scenarios_to_df","title":"<code>load_scenarios_to_df</code>","text":"<p>Converts load scenarios array to a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>scenarios</code> <code>ndarray</code> <p>3D numpy array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns: load_scenario, load, p_mw, q_mvar.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def load_scenarios_to_df(scenarios: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"Converts load scenarios array to a DataFrame.\n\n    Args:\n        scenarios: 3D numpy array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n    Returns:\n        DataFrame with columns: load_scenario, load, p_mw, q_mvar.\n    \"\"\"\n    n_loads = scenarios.shape[0]\n    n_scenarios = scenarios.shape[1]\n\n    # Flatten the array\n    reshaped_array = scenarios.reshape((-1, 2), order=\"F\")\n\n    # Create a DataFrame\n    df = pd.DataFrame(reshaped_array, columns=[\"p_mw\", \"q_mvar\"])\n\n    # Create load_scenario and bus columns\n    load_idx = np.tile(np.arange(n_loads), n_scenarios)\n    scenarios_idx = np.repeat(np.arange(n_scenarios), n_loads)\n\n    df.insert(0, \"load_scenario\", scenarios_idx)\n    df.insert(1, \"load\", load_idx)\n\n    return df\n</code></pre>"},{"location":"components/load/#plot_load_scenarios_combined","title":"<code>plot_load_scenarios_combined</code>","text":"<p>Generates a combined plot of active and reactive power load scenarios.</p> <p>Creates a two-subplot figure with p_mw and q_mvar plots, one line per bus.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing load scenarios with columns: load_scenario, load, p_mw, q_mvar.</p> required <code>output_file</code> <code>str</code> <p>Path where the HTML plot file should be saved.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def plot_load_scenarios_combined(df: pd.DataFrame, output_file: str) -&gt; None:\n    \"\"\"Generates a combined plot of active and reactive power load scenarios.\n\n    Creates a two-subplot figure with p_mw and q_mvar plots, one line per bus.\n\n    Args:\n        df: DataFrame containing load scenarios with columns: load_scenario, load, p_mw, q_mvar.\n        output_file: Path where the HTML plot file should be saved.\n    \"\"\"\n    # Create subplots\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        shared_xaxes=True,\n        vertical_spacing=0.1,\n        subplot_titles=(\"p_mw\", \"q_mvar\"),\n    )\n\n    # Add p_mw plot\n    for load in df[\"load\"].unique():\n        df_load = df[df[\"load\"] == load]\n        fig.add_trace(\n            go.Scatter(\n                x=df_load[\"load_scenario\"],\n                y=df_load[\"p_mw\"],\n                mode=\"lines\",\n                name=f\"Load {load} p_mw\",\n            ),\n            row=1,\n            col=1,\n        )\n\n    # Add q_mvar plot\n    for load in df[\"load\"].unique():\n        df_load = df[df[\"load\"] == load]\n        fig.add_trace(\n            go.Scatter(\n                x=df_load[\"load_scenario\"],\n                y=df_load[\"q_mvar\"],\n                mode=\"lines\",\n                name=f\"Load {load} q_mvar\",\n            ),\n            row=2,\n            col=1,\n        )\n\n    # Update layout\n    fig.update_layout(height=800, width=1500, title_text=\"Load Scenarios\")\n\n    # Save the combined plot to an HTML file\n    fig.write_html(output_file)\n</code></pre>"},{"location":"components/network/","title":"Network","text":"<p>This module provides functionality for loading, processing, and saving power system networks in MATPOWER format.</p>"},{"location":"components/network/#network_1","title":"<code>Network</code>","text":"<p>Power system network representation with MATPOWER compatibility.</p> <p>This class handles power system networks loaded from MATPOWER case files, providing functionality for bus index mapping, power flow calculations, and data export. It automatically handles non-continuous bus indexing by mapping to continuous indices for internal processing.</p> <p>Attributes:</p> Name Type Description <code>mpc</code> <p>Original MATPOWER case dictionary.</p> <code>baseMVA</code> <p>Base MVA for the power system.</p> <code>buses</code> <p>Bus data array with continuous indexing.</p> <code>gens</code> <p>Generator data array with continuous indexing.</p> <code>branches</code> <p>Branch data array with continuous indexing.</p> <code>gencosts</code> <p>Generator cost data array.</p> <code>original_bus_indices</code> <p>Original bus indices from MATPOWER file.</p> <code>bus_index_mapping</code> <p>Mapping from original to continuous bus indices.</p> <code>reverse_bus_index_mapping</code> <p>Mapping from continuous to original bus indices.</p> <code>ref_bus_idx</code> <p>Index of the reference bus.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>class Network:\n    \"\"\"Power system network representation with MATPOWER compatibility.\n\n    This class handles power system networks loaded from MATPOWER case files,\n    providing functionality for bus index mapping, power flow calculations,\n    and data export. It automatically handles non-continuous bus indexing\n    by mapping to continuous indices for internal processing.\n\n    Attributes:\n        mpc: Original MATPOWER case dictionary.\n        baseMVA: Base MVA for the power system.\n        buses: Bus data array with continuous indexing.\n        gens: Generator data array with continuous indexing.\n        branches: Branch data array with continuous indexing.\n        gencosts: Generator cost data array.\n        original_bus_indices: Original bus indices from MATPOWER file.\n        bus_index_mapping: Mapping from original to continuous bus indices.\n        reverse_bus_index_mapping: Mapping from continuous to original bus indices.\n        ref_bus_idx: Index of the reference bus.\n    \"\"\"\n\n    def __init__(self, mpc: Dict[str, Any]) -&gt; None:\n        \"\"\"Initialize Network from MATPOWER case dictionary.\n\n        Args:\n            mpc: MATPOWER case dictionary containing bus, gen, branch, and gencost data.\n\n        Raises:\n            AssertionError: If generator buses are not in bus IDs or if there's not exactly one reference bus.\n        \"\"\"\n        self.mpc = mpc\n        self.baseMVA = self.mpc.get(\"baseMVA\", 100)\n\n        self.buses = self.mpc[\"bus\"].copy()\n        self.gens = self.mpc[\"gen\"].copy()\n        self.branches = self.mpc[\"branch\"].copy()\n        self.gencosts = self.mpc[\"gencost\"].copy()\n\n        # Store original bus indices before conversion (these are 1-based from MATPOWER)\n        self.original_bus_indices = self.buses[:, BUS_I].astype(int).copy()\n\n        # Create mapping from original bus indices to continuous indices (0, 1, 2, ..., n_bus-1)\n        unique_bus_indices = np.unique(self.original_bus_indices)\n        self.bus_index_mapping = {\n            int(orig_idx): new_idx\n            for new_idx, orig_idx in enumerate(unique_bus_indices)\n        }\n        self.reverse_bus_index_mapping = {\n            new_idx: int(orig_idx)\n            for orig_idx, new_idx in self.bus_index_mapping.items()\n        }\n\n        # Convert bus indices to continuous (0-based) for internal processing\n        self.buses[:, BUS_I] = np.array(\n            [self.bus_index_mapping[int(idx)] for idx in self.buses[:, BUS_I]],\n        )\n        self.gens[:, GEN_BUS] = np.array(\n            [self.bus_index_mapping[int(idx)] for idx in self.gens[:, GEN_BUS]],\n        )\n        self.branches[:, F_BUS] = np.array(\n            [self.bus_index_mapping[int(idx)] for idx in self.branches[:, F_BUS]],\n        )\n        self.branches[:, T_BUS] = np.array(\n            [self.bus_index_mapping[int(idx)] for idx in self.branches[:, T_BUS]],\n        )\n\n        # assert all generator buses are in bus IDs\n        assert np.all(np.isin(self.gens[:, GEN_BUS], self.buses[:, BUS_I])), (\n            \"All generator buses should be in bus IDs\"\n        )\n\n        assert np.all(self.gencosts[:, MODEL] == POLYNOMIAL), (\n            \"MODEL should be POLYNOMIAL\"\n        )\n\n        # assert all generators have the same number of cost coefficients\n        assert np.all(self.gencosts[:, NCOST] == self.gencosts[:, NCOST][0]), (\n            \"All generators must have the same number of cost coefficients\"\n        )\n\n        # assert only one reference bus\n        assert np.sum(self.buses[:, BUS_TYPE] == REF) == 1, (\n            \"There should be exactly one reference bus\"\n        )\n        self.ref_bus_idx = np.where(self.buses[:, BUS_TYPE] == REF)[0][0]\n\n        self.check_single_connected_component()\n\n    @property\n    def idx_gens_in_service(self) -&gt; np.ndarray:\n        \"\"\"Get indices of generators that are in service.\n\n        Returns:\n            Array of generator indices that are currently in service (status = 1).\n        \"\"\"\n        return (np.where(self.gens[:, GEN_STATUS] == 1)[0]).astype(int)\n\n    @property\n    def idx_branches_in_service(self) -&gt; np.ndarray:\n        \"\"\"Get indices of branches that are in service.\n\n        Returns:\n            Array of branch indices that are currently in service (status = 1).\n        \"\"\"\n        return (np.where(self.branches[:, BR_STATUS] == 1)[0]).astype(int)\n\n    @property\n    def Pd(self) -&gt; np.ndarray:\n        \"\"\"Get active power demand at all buses.\n\n        Returns:\n            Array of active power demand values for all buses.\n        \"\"\"\n        return self.buses[:, PD]\n\n    @Pd.setter\n    def Pd(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set active power demand at all buses.\n\n        Args:\n            value: Array of active power demand values.\n        \"\"\"\n        self.buses[:, PD] = value\n\n    @property\n    def Qd(self) -&gt; np.ndarray:\n        \"\"\"Get reactive power demand at all buses.\n\n        Returns:\n            Array of reactive power demand values for all buses.\n        \"\"\"\n        return self.buses[:, QD]\n\n    @Qd.setter\n    def Qd(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set reactive power demand at all buses.\n\n        Args:\n            value: Array of reactive power demand values.\n        \"\"\"\n        self.buses[:, QD] = value\n\n    @property\n    def Pg_gen(self) -&gt; np.ndarray:\n        \"\"\"Get active power generation at all generators.\n\n        Returns:\n            Array of active power generation values for all generators.\n        \"\"\"\n        return self.gens[:, PG]\n\n    @Pg_gen.setter\n    def Pg_gen(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set active power generation at generators in service.\n\n        Args:\n            value: Array of active power generation values.\n        \"\"\"\n        self.gens[self.idx_gens_in_service, PG] = value\n\n    @property\n    def Qg_gen(self) -&gt; np.ndarray:\n        \"\"\"Get reactive power generation at all generators.\n\n        Returns:\n            Array of reactive power generation values for all generators.\n        \"\"\"\n        return self.gens[:, QG]\n\n    @Qg_gen.setter\n    def Qg_gen(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set reactive power generation at generators in service.\n\n        Args:\n            value: Array of reactive power generation values.\n        \"\"\"\n        self.gens[self.idx_gens_in_service, QG] = value\n\n    @property\n    def Vm(self) -&gt; np.ndarray:\n        \"\"\"Get voltage magnitude at all buses.\n\n        Returns:\n            Array of voltage magnitude values for all buses.\n        \"\"\"\n        return self.buses[:, VM]\n\n    @Vm.setter\n    def Vm(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set voltage magnitude at all buses.\n\n        Args:\n            value: Array of voltage magnitude values.\n        \"\"\"\n        self.buses[:, VM] = value\n\n    @property\n    def Va(self) -&gt; np.ndarray:\n        \"\"\"Get voltage angle at all buses.\n\n        Returns:\n            Array of voltage angle values for all buses.\n        \"\"\"\n        return self.buses[:, VA]\n\n    @Va.setter\n    def Va(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set voltage angle at all buses.\n\n        Args:\n            value: Array of voltage angle values.\n        \"\"\"\n        self.buses[:, VA] = value\n\n    @property\n    def Pg_bus(self) -&gt; np.ndarray:\n        \"\"\"Get active power generation at all buses.\n\n        Returns:\n            Array of active power generation values for all buses.\n        \"\"\"\n        return self.buses[:, PG]\n\n    @Pg_bus.setter\n    def Pg_bus(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set active power generation at buses (not allowed).\n\n        Args:\n            value: Array of active power generation values.\n\n        Raises:\n            ValueError: Power generation should be set at the generator level.\n        \"\"\"\n        raise ValueError(\"Power generation should be set at the generator level\")\n\n    @property\n    def Qg_bus(self) -&gt; np.ndarray:\n        \"\"\"Get reactive power generation at all buses.\n\n        Returns:\n            Array of reactive power generation values for all buses.\n        \"\"\"\n        return self.buses[:, QG]\n\n    @Qg_bus.setter\n    def Qg_bus(self, value: np.ndarray) -&gt; None:\n        \"\"\"Set reactive power generation at buses (not allowed).\n\n        Args:\n            value: Array of reactive power generation values.\n\n        Raises:\n            ValueError: Power generation should be set at the generator level.\n        \"\"\"\n        raise ValueError(\"Power generation should be set at the generator level\")\n\n    def deactivate_branches(self, idx_branches: np.ndarray) -&gt; None:\n        \"\"\"Deactivate specified branches by setting their status to 0.\n\n        Args:\n            idx_branches: Array of branch indices to deactivate.\n\n        Warns:\n            UserWarning: If trying to deactivate branches that are already deactivated.\n        \"\"\"\n        # throw warning if try deactivating branches that are already deactivated\n        if not np.all(self.branches[idx_branches, BR_STATUS] == 1):\n            warnings.warn(\n                f\"Trying to deactivate branches that are already deactivated: {idx_branches}\",\n            )\n        self.branches[idx_branches, BR_STATUS] = 0\n\n    def deactivate_gens(self, idx_gens: np.ndarray) -&gt; None:\n        \"\"\"Deactivate specified generators by setting their status to 0.\n\n        Args:\n            idx_gens: Array of generator indices to deactivate.\n\n        Warns:\n            UserWarning: If trying to deactivate generators that are already deactivated.\n        \"\"\"\n        # throw warning if try deactivate gens that are already deactivated\n        if not np.all(self.gens[idx_gens, GEN_STATUS] == 1):\n            warnings.warn(\n                f\"Trying to deactivate gens that are already deactivated: {idx_gens}\",\n            )\n        self.gens[idx_gens, GEN_STATUS] = 0\n\n        # -----------------------------\n        # Update PV buses that lost all generators \u2192 PQ\n        # -----------------------------\n        n_buses = self.buses.shape[0]\n\n        # Count in-service generators per bus\n        gens_on = self.gens[self.idx_gens_in_service]\n        gen_count = np.bincount(gens_on[:, GEN_BUS].astype(int), minlength=n_buses)\n\n        # Boolean mask: PV buses with no in-service generator\n        pv_no_gen = (self.buses[:, BUS_TYPE] == PV) &amp; (gen_count == 0)\n\n        # Set them to PQ\n        self.buses[pv_no_gen, BUS_TYPE] = PQ\n\n    def check_single_connected_component(self) -&gt; bool:\n        \"\"\"\n        Check that the network forms a single connected component.\n\n        Creates a NetworkX graph with buses as nodes and in-service branches as edges,\n        then checks if there is exactly one connected component.\n\n        Returns:\n            bool: True if there is exactly one connected component, False otherwise\n        \"\"\"\n        # Create NetworkX graph\n        G = nx.Graph()\n\n        # Add all buses as nodes\n        n_buses = self.buses.shape[0]\n        G.add_nodes_from(range(n_buses))\n\n        # Add in-service branches as edges\n        in_service_branches = self.idx_branches_in_service\n        for branch_idx in in_service_branches:\n            from_bus = int(self.branches[branch_idx, F_BUS])\n            to_bus = int(self.branches[branch_idx, T_BUS])\n            G.add_edge(from_bus, to_bus)\n\n        # Find connected components\n        connected_components = list(nx.connected_components(G))\n\n        # Check if there is exactly one connected component\n        if len(connected_components) == 1:\n            return True\n        else:\n            return False\n\n    def version(self) -&gt; str:\n        \"\"\"Get the MATPOWER version from the MPC dictionary.\n\n        Returns:\n            MATPOWER version string, defaults to '2' if not specified.\n        \"\"\"\n        return self.mpc.get(\"version\", \"2\")\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"Structural equality: compare core fields and matrices with tolerance.\n\n        Two Network objects are considered equal if their scalar attributes and\n        all core matrices are numerically equal (within a small tolerance), and\n        their bus index mappings agree.\n        \"\"\"\n        if not isinstance(other, Network):\n            return False\n\n        # Compare simple scalars\n        try:\n            if self.version() != other.version():\n                return False\n            if not np.isclose(self.baseMVA, other.baseMVA, atol=1e-12, rtol=0):\n                return False\n            if int(self.ref_bus_idx) != int(other.ref_bus_idx):\n                return False\n\n            # Compare arrays with tolerance\n            def arrays_close(a: np.ndarray, b: np.ndarray) -&gt; bool:\n                if a is None and b is None:\n                    return True\n                if (a is None) != (b is None):\n                    return False\n                if a.shape != b.shape:\n                    return False\n                # Use allclose for numeric matrices\n                return np.allclose(a, b, atol=1e-12, rtol=0)\n\n            if not arrays_close(self.buses, other.buses):\n                return False\n            if not arrays_close(self.gens, other.gens):\n                return False\n            if not arrays_close(self.branches, other.branches):\n                return False\n            if not arrays_close(self.gencosts, other.gencosts):\n                return False\n            if not arrays_close(self.original_bus_indices, other.original_bus_indices):\n                return False\n\n            # Compare mappings\n            if self.bus_index_mapping != other.bus_index_mapping:\n                return False\n            if self.reverse_bus_index_mapping != other.reverse_bus_index_mapping:\n                return False\n\n            return True\n        except Exception:\n            return False\n\n    def to_mpc(self, filename: str) -&gt; None:\n        \"\"\"Convert network data to MATPOWER .m case file format.\n\n        This method saves the network data to a MATPOWER case file, restoring\n        the original bus indices for MATPOWER compatibility.\n\n        Args:\n            filename: Path where the MATPOWER case file should be saved.\n\n        Raises:\n            AssertionError: If bus, gen, or branch matrices don't have the required number of columns.\n        \"\"\"\n\n        to_save = copy.deepcopy(self)\n        # Restore original bus indices (1-based for MATPOWER)\n        to_save.buses[:, BUS_I] = np.array(\n            [self.reverse_bus_index_mapping[idx] for idx in to_save.buses[:, BUS_I]],\n            dtype=int,\n        )\n        to_save.gens[:, GEN_BUS] = np.array(\n            [self.reverse_bus_index_mapping[idx] for idx in to_save.gens[:, GEN_BUS]],\n            dtype=int,\n        )\n        to_save.branches[:, F_BUS] = np.array(\n            [self.reverse_bus_index_mapping[idx] for idx in to_save.branches[:, F_BUS]],\n            dtype=int,\n        )\n        to_save.branches[:, T_BUS] = np.array(\n            [self.reverse_bus_index_mapping[idx] for idx in to_save.branches[:, T_BUS]],\n            dtype=int,\n        )\n\n        with open(filename, \"w\") as f:\n            f.write(\"function mpc = case_from_dict\\n\")\n            f.write(\"% Automatically generated MATPOWER case file\\n\\n\")\n\n            # version and baseMVA\n            f.write(f\"mpc.version = '{to_save.version()}';\\n\")\n            f.write(f\"mpc.baseMVA = {to_save.baseMVA};\\n\\n\")\n\n            # -------------------------\n            # BUS matrix\n            # -------------------------\n            assert to_save.buses.ndim == 2, \"mpc['bus'] must be a 2D array\"\n            assert to_save.buses.shape[1] &gt;= 13, (\n                f\"mpc['bus'] has {to_save.buses.shape[1]} columns, expected \u226513\"\n            )\n            f.write(\n                \"% Columns: BUS_I  BUS_TYPE  PD  QD  GS  BS  BUS_AREA  VM  VA  BASE_KV  ZONE  VMAX  VMIN\\n\",\n            )\n            f.write(numpy_to_matlab_matrix(to_save.buses, \"bus\"))\n\n            # -------------------------\n            # GEN matrix\n            # -------------------------\n            assert to_save.gens.ndim == 2, \"mpc['gen'] must be a 2D array\"\n            assert to_save.gens.shape[1] &gt;= 10, (\n                f\"mpc['gen'] has {to_save.gens.shape[1]} columns, expected minimum \u226510\"\n            )\n            f.write(\n                \"% Columns: GEN_BUS  PG  QG  QMAX  QMIN  VG  MBASE  GEN_STATUS  PMAX  PMIN  \"\n                \"PC1  PC2  QC1MIN  QC1MAX  QC2MIN  QC2MAX  RAMP_AGC  RAMP_10  RAMP_30  RAMP_Q  APF\\n\",\n            )\n            f.write(numpy_to_matlab_matrix(to_save.gens, \"gen\"))\n\n            # -------------------------\n            # BRANCH matrix (always 13 columns)\n            # -------------------------\n            assert to_save.branches.ndim == 2, \"mpc['branch'] must be a 2D array\"\n            assert to_save.branches.shape[1] &gt;= 13, (\n                f\"mpc['branch'] has {to_save.branches.shape[1]} columns, expected \u226513\"\n            )\n            f.write(\n                \"% Columns: F_BUS  T_BUS  BR_R  BR_X  BR_B  RATE_A  RATE_B  RATE_C  TAP  SHIFT  BR_STATUS  ANGMIN  ANGMAX\\n\",\n            )\n            f.write(numpy_to_matlab_matrix(to_save.branches, \"branch\"))\n\n            # -------------------------\n            # GENCOST matrix\n            # -------------------------\n            if to_save.gencosts is not None:\n                assert to_save.gencosts.ndim == 2, \"mpc['gencost'] must be a 2D array\"\n                f.write(\n                    \"% Columns: MODEL  STARTUP  SHUTDOWN  NCOST  COST (coefficients or x-y pairs)\\n\",\n                )\n                f.write(numpy_to_matlab_matrix(to_save.gencosts, \"gencost\"))\n</code></pre> <code>Pd</code> <code>property</code> <code>writable</code> \u00b6 <p>Get active power demand at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of active power demand values for all buses.</p> <code>Pg_bus</code> <code>property</code> <code>writable</code> \u00b6 <p>Get active power generation at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of active power generation values for all buses.</p> <code>Pg_gen</code> <code>property</code> <code>writable</code> \u00b6 <p>Get active power generation at all generators.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of active power generation values for all generators.</p> <code>Qd</code> <code>property</code> <code>writable</code> \u00b6 <p>Get reactive power demand at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of reactive power demand values for all buses.</p> <code>Qg_bus</code> <code>property</code> <code>writable</code> \u00b6 <p>Get reactive power generation at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of reactive power generation values for all buses.</p> <code>Qg_gen</code> <code>property</code> <code>writable</code> \u00b6 <p>Get reactive power generation at all generators.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of reactive power generation values for all generators.</p> <code>Va</code> <code>property</code> <code>writable</code> \u00b6 <p>Get voltage angle at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of voltage angle values for all buses.</p> <code>Vm</code> <code>property</code> <code>writable</code> \u00b6 <p>Get voltage magnitude at all buses.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of voltage magnitude values for all buses.</p> <code>idx_branches_in_service</code> <code>property</code> \u00b6 <p>Get indices of branches that are in service.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of branch indices that are currently in service (status = 1).</p> <code>idx_gens_in_service</code> <code>property</code> \u00b6 <p>Get indices of generators that are in service.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of generator indices that are currently in service (status = 1).</p> <code>__eq__(other)</code> \u00b6 <p>Structural equality: compare core fields and matrices with tolerance.</p> <p>Two Network objects are considered equal if their scalar attributes and all core matrices are numerically equal (within a small tolerance), and their bus index mappings agree.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Structural equality: compare core fields and matrices with tolerance.\n\n    Two Network objects are considered equal if their scalar attributes and\n    all core matrices are numerically equal (within a small tolerance), and\n    their bus index mappings agree.\n    \"\"\"\n    if not isinstance(other, Network):\n        return False\n\n    # Compare simple scalars\n    try:\n        if self.version() != other.version():\n            return False\n        if not np.isclose(self.baseMVA, other.baseMVA, atol=1e-12, rtol=0):\n            return False\n        if int(self.ref_bus_idx) != int(other.ref_bus_idx):\n            return False\n\n        # Compare arrays with tolerance\n        def arrays_close(a: np.ndarray, b: np.ndarray) -&gt; bool:\n            if a is None and b is None:\n                return True\n            if (a is None) != (b is None):\n                return False\n            if a.shape != b.shape:\n                return False\n            # Use allclose for numeric matrices\n            return np.allclose(a, b, atol=1e-12, rtol=0)\n\n        if not arrays_close(self.buses, other.buses):\n            return False\n        if not arrays_close(self.gens, other.gens):\n            return False\n        if not arrays_close(self.branches, other.branches):\n            return False\n        if not arrays_close(self.gencosts, other.gencosts):\n            return False\n        if not arrays_close(self.original_bus_indices, other.original_bus_indices):\n            return False\n\n        # Compare mappings\n        if self.bus_index_mapping != other.bus_index_mapping:\n            return False\n        if self.reverse_bus_index_mapping != other.reverse_bus_index_mapping:\n            return False\n\n        return True\n    except Exception:\n        return False\n</code></pre> <code>__init__(mpc)</code> \u00b6 <p>Initialize Network from MATPOWER case dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>mpc</code> <code>Dict[str, Any]</code> <p>MATPOWER case dictionary containing bus, gen, branch, and gencost data.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If generator buses are not in bus IDs or if there's not exactly one reference bus.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def __init__(self, mpc: Dict[str, Any]) -&gt; None:\n    \"\"\"Initialize Network from MATPOWER case dictionary.\n\n    Args:\n        mpc: MATPOWER case dictionary containing bus, gen, branch, and gencost data.\n\n    Raises:\n        AssertionError: If generator buses are not in bus IDs or if there's not exactly one reference bus.\n    \"\"\"\n    self.mpc = mpc\n    self.baseMVA = self.mpc.get(\"baseMVA\", 100)\n\n    self.buses = self.mpc[\"bus\"].copy()\n    self.gens = self.mpc[\"gen\"].copy()\n    self.branches = self.mpc[\"branch\"].copy()\n    self.gencosts = self.mpc[\"gencost\"].copy()\n\n    # Store original bus indices before conversion (these are 1-based from MATPOWER)\n    self.original_bus_indices = self.buses[:, BUS_I].astype(int).copy()\n\n    # Create mapping from original bus indices to continuous indices (0, 1, 2, ..., n_bus-1)\n    unique_bus_indices = np.unique(self.original_bus_indices)\n    self.bus_index_mapping = {\n        int(orig_idx): new_idx\n        for new_idx, orig_idx in enumerate(unique_bus_indices)\n    }\n    self.reverse_bus_index_mapping = {\n        new_idx: int(orig_idx)\n        for orig_idx, new_idx in self.bus_index_mapping.items()\n    }\n\n    # Convert bus indices to continuous (0-based) for internal processing\n    self.buses[:, BUS_I] = np.array(\n        [self.bus_index_mapping[int(idx)] for idx in self.buses[:, BUS_I]],\n    )\n    self.gens[:, GEN_BUS] = np.array(\n        [self.bus_index_mapping[int(idx)] for idx in self.gens[:, GEN_BUS]],\n    )\n    self.branches[:, F_BUS] = np.array(\n        [self.bus_index_mapping[int(idx)] for idx in self.branches[:, F_BUS]],\n    )\n    self.branches[:, T_BUS] = np.array(\n        [self.bus_index_mapping[int(idx)] for idx in self.branches[:, T_BUS]],\n    )\n\n    # assert all generator buses are in bus IDs\n    assert np.all(np.isin(self.gens[:, GEN_BUS], self.buses[:, BUS_I])), (\n        \"All generator buses should be in bus IDs\"\n    )\n\n    assert np.all(self.gencosts[:, MODEL] == POLYNOMIAL), (\n        \"MODEL should be POLYNOMIAL\"\n    )\n\n    # assert all generators have the same number of cost coefficients\n    assert np.all(self.gencosts[:, NCOST] == self.gencosts[:, NCOST][0]), (\n        \"All generators must have the same number of cost coefficients\"\n    )\n\n    # assert only one reference bus\n    assert np.sum(self.buses[:, BUS_TYPE] == REF) == 1, (\n        \"There should be exactly one reference bus\"\n    )\n    self.ref_bus_idx = np.where(self.buses[:, BUS_TYPE] == REF)[0][0]\n\n    self.check_single_connected_component()\n</code></pre> <code>check_single_connected_component()</code> \u00b6 <p>Check that the network forms a single connected component.</p> <p>Creates a NetworkX graph with buses as nodes and in-service branches as edges, then checks if there is exactly one connected component.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if there is exactly one connected component, False otherwise</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def check_single_connected_component(self) -&gt; bool:\n    \"\"\"\n    Check that the network forms a single connected component.\n\n    Creates a NetworkX graph with buses as nodes and in-service branches as edges,\n    then checks if there is exactly one connected component.\n\n    Returns:\n        bool: True if there is exactly one connected component, False otherwise\n    \"\"\"\n    # Create NetworkX graph\n    G = nx.Graph()\n\n    # Add all buses as nodes\n    n_buses = self.buses.shape[0]\n    G.add_nodes_from(range(n_buses))\n\n    # Add in-service branches as edges\n    in_service_branches = self.idx_branches_in_service\n    for branch_idx in in_service_branches:\n        from_bus = int(self.branches[branch_idx, F_BUS])\n        to_bus = int(self.branches[branch_idx, T_BUS])\n        G.add_edge(from_bus, to_bus)\n\n    # Find connected components\n    connected_components = list(nx.connected_components(G))\n\n    # Check if there is exactly one connected component\n    if len(connected_components) == 1:\n        return True\n    else:\n        return False\n</code></pre> <code>deactivate_branches(idx_branches)</code> \u00b6 <p>Deactivate specified branches by setting their status to 0.</p> <p>Parameters:</p> Name Type Description Default <code>idx_branches</code> <code>ndarray</code> <p>Array of branch indices to deactivate.</p> required <p>Warns:</p> Type Description <code>UserWarning</code> <p>If trying to deactivate branches that are already deactivated.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def deactivate_branches(self, idx_branches: np.ndarray) -&gt; None:\n    \"\"\"Deactivate specified branches by setting their status to 0.\n\n    Args:\n        idx_branches: Array of branch indices to deactivate.\n\n    Warns:\n        UserWarning: If trying to deactivate branches that are already deactivated.\n    \"\"\"\n    # throw warning if try deactivating branches that are already deactivated\n    if not np.all(self.branches[idx_branches, BR_STATUS] == 1):\n        warnings.warn(\n            f\"Trying to deactivate branches that are already deactivated: {idx_branches}\",\n        )\n    self.branches[idx_branches, BR_STATUS] = 0\n</code></pre> <code>deactivate_gens(idx_gens)</code> \u00b6 <p>Deactivate specified generators by setting their status to 0.</p> <p>Parameters:</p> Name Type Description Default <code>idx_gens</code> <code>ndarray</code> <p>Array of generator indices to deactivate.</p> required <p>Warns:</p> Type Description <code>UserWarning</code> <p>If trying to deactivate generators that are already deactivated.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def deactivate_gens(self, idx_gens: np.ndarray) -&gt; None:\n    \"\"\"Deactivate specified generators by setting their status to 0.\n\n    Args:\n        idx_gens: Array of generator indices to deactivate.\n\n    Warns:\n        UserWarning: If trying to deactivate generators that are already deactivated.\n    \"\"\"\n    # throw warning if try deactivate gens that are already deactivated\n    if not np.all(self.gens[idx_gens, GEN_STATUS] == 1):\n        warnings.warn(\n            f\"Trying to deactivate gens that are already deactivated: {idx_gens}\",\n        )\n    self.gens[idx_gens, GEN_STATUS] = 0\n\n    # -----------------------------\n    # Update PV buses that lost all generators \u2192 PQ\n    # -----------------------------\n    n_buses = self.buses.shape[0]\n\n    # Count in-service generators per bus\n    gens_on = self.gens[self.idx_gens_in_service]\n    gen_count = np.bincount(gens_on[:, GEN_BUS].astype(int), minlength=n_buses)\n\n    # Boolean mask: PV buses with no in-service generator\n    pv_no_gen = (self.buses[:, BUS_TYPE] == PV) &amp; (gen_count == 0)\n\n    # Set them to PQ\n    self.buses[pv_no_gen, BUS_TYPE] = PQ\n</code></pre> <code>to_mpc(filename)</code> \u00b6 <p>Convert network data to MATPOWER .m case file format.</p> <p>This method saves the network data to a MATPOWER case file, restoring the original bus indices for MATPOWER compatibility.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path where the MATPOWER case file should be saved.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If bus, gen, or branch matrices don't have the required number of columns.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def to_mpc(self, filename: str) -&gt; None:\n    \"\"\"Convert network data to MATPOWER .m case file format.\n\n    This method saves the network data to a MATPOWER case file, restoring\n    the original bus indices for MATPOWER compatibility.\n\n    Args:\n        filename: Path where the MATPOWER case file should be saved.\n\n    Raises:\n        AssertionError: If bus, gen, or branch matrices don't have the required number of columns.\n    \"\"\"\n\n    to_save = copy.deepcopy(self)\n    # Restore original bus indices (1-based for MATPOWER)\n    to_save.buses[:, BUS_I] = np.array(\n        [self.reverse_bus_index_mapping[idx] for idx in to_save.buses[:, BUS_I]],\n        dtype=int,\n    )\n    to_save.gens[:, GEN_BUS] = np.array(\n        [self.reverse_bus_index_mapping[idx] for idx in to_save.gens[:, GEN_BUS]],\n        dtype=int,\n    )\n    to_save.branches[:, F_BUS] = np.array(\n        [self.reverse_bus_index_mapping[idx] for idx in to_save.branches[:, F_BUS]],\n        dtype=int,\n    )\n    to_save.branches[:, T_BUS] = np.array(\n        [self.reverse_bus_index_mapping[idx] for idx in to_save.branches[:, T_BUS]],\n        dtype=int,\n    )\n\n    with open(filename, \"w\") as f:\n        f.write(\"function mpc = case_from_dict\\n\")\n        f.write(\"% Automatically generated MATPOWER case file\\n\\n\")\n\n        # version and baseMVA\n        f.write(f\"mpc.version = '{to_save.version()}';\\n\")\n        f.write(f\"mpc.baseMVA = {to_save.baseMVA};\\n\\n\")\n\n        # -------------------------\n        # BUS matrix\n        # -------------------------\n        assert to_save.buses.ndim == 2, \"mpc['bus'] must be a 2D array\"\n        assert to_save.buses.shape[1] &gt;= 13, (\n            f\"mpc['bus'] has {to_save.buses.shape[1]} columns, expected \u226513\"\n        )\n        f.write(\n            \"% Columns: BUS_I  BUS_TYPE  PD  QD  GS  BS  BUS_AREA  VM  VA  BASE_KV  ZONE  VMAX  VMIN\\n\",\n        )\n        f.write(numpy_to_matlab_matrix(to_save.buses, \"bus\"))\n\n        # -------------------------\n        # GEN matrix\n        # -------------------------\n        assert to_save.gens.ndim == 2, \"mpc['gen'] must be a 2D array\"\n        assert to_save.gens.shape[1] &gt;= 10, (\n            f\"mpc['gen'] has {to_save.gens.shape[1]} columns, expected minimum \u226510\"\n        )\n        f.write(\n            \"% Columns: GEN_BUS  PG  QG  QMAX  QMIN  VG  MBASE  GEN_STATUS  PMAX  PMIN  \"\n            \"PC1  PC2  QC1MIN  QC1MAX  QC2MIN  QC2MAX  RAMP_AGC  RAMP_10  RAMP_30  RAMP_Q  APF\\n\",\n        )\n        f.write(numpy_to_matlab_matrix(to_save.gens, \"gen\"))\n\n        # -------------------------\n        # BRANCH matrix (always 13 columns)\n        # -------------------------\n        assert to_save.branches.ndim == 2, \"mpc['branch'] must be a 2D array\"\n        assert to_save.branches.shape[1] &gt;= 13, (\n            f\"mpc['branch'] has {to_save.branches.shape[1]} columns, expected \u226513\"\n        )\n        f.write(\n            \"% Columns: F_BUS  T_BUS  BR_R  BR_X  BR_B  RATE_A  RATE_B  RATE_C  TAP  SHIFT  BR_STATUS  ANGMIN  ANGMAX\\n\",\n        )\n        f.write(numpy_to_matlab_matrix(to_save.branches, \"branch\"))\n\n        # -------------------------\n        # GENCOST matrix\n        # -------------------------\n        if to_save.gencosts is not None:\n            assert to_save.gencosts.ndim == 2, \"mpc['gencost'] must be a 2D array\"\n            f.write(\n                \"% Columns: MODEL  STARTUP  SHUTDOWN  NCOST  COST (coefficients or x-y pairs)\\n\",\n            )\n            f.write(numpy_to_matlab_matrix(to_save.gencosts, \"gencost\"))\n</code></pre> <code>version()</code> \u00b6 <p>Get the MATPOWER version from the MPC dictionary.</p> <p>Returns:</p> Type Description <code>str</code> <p>MATPOWER version string, defaults to '2' if not specified.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def version(self) -&gt; str:\n    \"\"\"Get the MATPOWER version from the MPC dictionary.\n\n    Returns:\n        MATPOWER version string, defaults to '2' if not specified.\n    \"\"\"\n    return self.mpc.get(\"version\", \"2\")\n</code></pre>"},{"location":"components/network/#load_net_from_file","title":"<code>load_net_from_file</code>","text":"<p>Load a network from a MATPOWER file.</p> <p>Parameters:</p> Name Type Description Default <code>network_path</code> <code>str</code> <p>Path to the MATPOWER file (without extension).</p> required <p>Returns:</p> Type Description <code>Network</code> <p>Network object containing the power network configuration.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the network file doesn't exist.</p> <code>ValueError</code> <p>If the file format is invalid.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def load_net_from_file(network_path: str) -&gt; Network:\n    \"\"\"Load a network from a MATPOWER file.\n\n    Args:\n        network_path: Path to the MATPOWER file (without extension).\n\n    Returns:\n        Network object containing the power network configuration.\n\n    Raises:\n        FileNotFoundError: If the network file doesn't exist.\n        ValueError: If the file format is invalid.\n    \"\"\"\n    # Load network using matpowercaseframes\n    network_path = correct_network(network_path)\n    mpc_frames = CaseFrames(network_path)\n    mpc = {\n        key: mpc_frames.__getattribute__(key)\n        if not isinstance(mpc_frames.__getattribute__(key), pd.DataFrame)\n        else mpc_frames.__getattribute__(key).values\n        for key in mpc_frames._attributes\n    }\n\n    return Network(mpc)\n</code></pre>"},{"location":"components/network/#load_net_from_pglib","title":"<code>load_net_from_pglib</code>","text":"<p>Load a power grid network from PGLib using matpowercaseframes.</p> <p>Downloads the network file if not locally available and loads it into a Network object.</p> <p>Parameters:</p> Name Type Description Default <code>grid_name</code> <code>str</code> <p>Name of the grid file without the prefix 'pglib_opf_'       (e.g., 'case14_ieee', 'case118_ieee').</p> required <p>Returns:</p> Type Description <code>Network</code> <p>Network object containing the power network configuration.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If download fails.</p> <code>FileNotFoundError</code> <p>If the file cannot be found after download.</p> <code>ValueError</code> <p>If the file format is invalid.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def load_net_from_pglib(grid_name: str) -&gt; Network:\n    \"\"\"Load a power grid network from PGLib using matpowercaseframes.\n\n    Downloads the network file if not locally available and loads it into a Network object.\n\n    Args:\n        grid_name: Name of the grid file without the prefix 'pglib_opf_'\n                  (e.g., 'case14_ieee', 'case118_ieee').\n\n    Returns:\n        Network object containing the power network configuration.\n\n    Raises:\n        requests.exceptions.RequestException: If download fails.\n        FileNotFoundError: If the file cannot be found after download.\n        ValueError: If the file format is invalid.\n    \"\"\"\n\n    # Construct file paths\n    file_path = str(\n        resources.files(\"gridfm_datakit.grids\").joinpath(f\"pglib_opf_{grid_name}.m\"),\n    )\n\n    # Create directory if it doesn't exist\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n\n    # Download file if not exists\n    if not os.path.exists(file_path):\n        url = f\"https://raw.githubusercontent.com/power-grid-lib/pglib-opf/master/pglib_opf_{grid_name}.m\"\n        response = requests.get(url)\n        response.raise_for_status()\n\n        with open(file_path, \"wb\") as f:\n            f.write(response.content)\n\n    file_path = correct_network(file_path)\n\n    # Load network using matpowercaseframes\n    mpc_frames = CaseFrames(file_path)\n    mpc = {\n        key: mpc_frames.__getattribute__(key)\n        if not isinstance(mpc_frames.__getattribute__(key), pd.DataFrame)\n        else mpc_frames.__getattribute__(key).values\n        for key in mpc_frames._attributes\n    }\n\n    return Network(mpc)\n</code></pre>"},{"location":"components/param_handler/","title":"Param Handler","text":"<p>This module provides utilities for handling and manipulating configuration parameters.</p>"},{"location":"components/param_handler/#flatten_dict","title":"<code>flatten_dict</code>","text":"<p>Flattens a nested dictionary into a single-level dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict[str, Any]</code> <p>The dictionary to flatten.</p> required <code>parent_key</code> <code>str</code> <p>Prefix for the keys in the flattened dictionary.</p> <code>''</code> <code>sep</code> <code>str</code> <p>Separator for nested keys. Defaults to '.'.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A flattened version of the input dictionary with dot-separated keys.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def flatten_dict(\n    d: Dict[str, Any],\n    parent_key: str = \"\",\n    sep: str = \".\",\n) -&gt; Dict[str, Any]:\n    \"\"\"Flattens a nested dictionary into a single-level dictionary.\n\n    Args:\n        d: The dictionary to flatten.\n        parent_key: Prefix for the keys in the flattened dictionary.\n        sep: Separator for nested keys. Defaults to '.'.\n\n    Returns:\n        A flattened version of the input dictionary with dot-separated keys.\n    \"\"\"\n    items = []\n    for key, value in d.items():\n        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n        if isinstance(value, dict):\n            items.extend(flatten_dict(value, new_key, sep=sep).items())\n        else:\n            items.append((new_key, value))\n    return dict(items)\n</code></pre>"},{"location":"components/param_handler/#unflatten_dict","title":"<code>unflatten_dict</code>","text":"<p>Reconstructs a nested dictionary from a flattened dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict[str, Any]</code> <p>The flattened dictionary to unflatten.</p> required <code>sep</code> <code>str</code> <p>Separator used in the flattened keys. Defaults to '.'.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A nested dictionary reconstructed from the flattened input.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def unflatten_dict(d: Dict[str, Any], sep: str = \".\") -&gt; Dict[str, Any]:\n    \"\"\"Reconstructs a nested dictionary from a flattened dictionary.\n\n    Args:\n        d: The flattened dictionary to unflatten.\n        sep: Separator used in the flattened keys. Defaults to '.'.\n\n    Returns:\n        A nested dictionary reconstructed from the flattened input.\n    \"\"\"\n    result = {}\n    for key, value in d.items():\n        parts = key.split(sep)\n        target = result\n        for part in parts[:-1]:\n            target = target.setdefault(part, {})\n        target[parts[-1]] = value\n    return result\n</code></pre>"},{"location":"components/param_handler/#merge_dict","title":"<code>merge_dict</code>","text":"<p>Recursively merges updates into a base dictionary.</p> <p>Only merges keys that exist in the base dictionary. Raises errors for invalid updates.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Dict[str, Any]</code> <p>The original dictionary to be updated.</p> required <code>updates</code> <code>Dict[str, Any]</code> <p>The dictionary containing updates.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If a key in updates does not exist in base.</p> <code>TypeError</code> <p>If a key in base is not a dictionary but updates attempt to provide nested values.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def merge_dict(base: Dict[str, Any], updates: Dict[str, Any]) -&gt; None:\n    \"\"\"Recursively merges updates into a base dictionary.\n\n    Only merges keys that exist in the base dictionary. Raises errors for\n    invalid updates.\n\n    Args:\n        base: The original dictionary to be updated.\n        updates: The dictionary containing updates.\n\n    Raises:\n        KeyError: If a key in updates does not exist in base.\n        TypeError: If a key in base is not a dictionary but updates attempt to\n            provide nested values.\n    \"\"\"\n    for key, value in updates.items():\n        if key not in base:\n            raise KeyError(f\"Key '{key}' not found in base configuration.\")\n\n        if isinstance(value, dict):\n            if not isinstance(base[key], dict):\n                raise TypeError(\n                    f\"Default config expects  {type(base[key])}, but got a dict at key '{key}'\",\n                )\n            # Recursively merge dictionaries\n            merge_dict(base[key], value)\n        else:\n            # Update the existing key\n            base[key] = value\n</code></pre>"},{"location":"components/param_handler/#get_load_scenario_generator","title":"<code>get_load_scenario_generator</code>","text":"<p>Creates and returns a load scenario generator based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration namespace containing load generator parameters.</p> required <p>Returns:</p> Type Description <code>LoadScenarioGeneratorBase</code> <p>An instance of a LoadScenarioGeneratorBase subclass configured according</p> <code>LoadScenarioGeneratorBase</code> <p>to the provided arguments.</p> Note <p>Currently supports 'agg_load_profile' and 'powergraph' generator types.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def get_load_scenario_generator(args: NestedNamespace) -&gt; LoadScenarioGeneratorBase:\n    \"\"\"Creates and returns a load scenario generator based on configuration.\n\n    Args:\n        args: Configuration namespace containing load generator parameters.\n\n    Returns:\n        An instance of a LoadScenarioGeneratorBase subclass configured according\n        to the provided arguments.\n\n    Note:\n        Currently supports 'agg_load_profile' and 'powergraph' generator types.\n    \"\"\"\n    if args.generator == \"agg_load_profile\":\n        return LoadScenariosFromAggProfile(\n            args.agg_profile,\n            args.sigma,\n            args.change_reactive_power,\n            args.global_range,\n            args.max_scaling_factor,\n            args.step_size,\n            args.start_scaling_factor,\n        )\n    if args.generator == \"powergraph\":\n        unused_args = {\n            key: value\n            for key, value in args.flatten().items()\n            if key not in [\"type\", \"agg_profile\"]\n        }\n        if unused_args:\n            warnings.warn(\n                f\"The following arguments are not used by the powergraph generator: {unused_args}\",\n                UserWarning,\n            )\n\n        return Powergraph(args.agg_profile)\n</code></pre>"},{"location":"components/param_handler/#initialize_topology_generator","title":"<code>initialize_topology_generator</code>","text":"<p>Initialize the appropriate topology generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing generator type and parameters.</p> required <code>base_net</code> <code>Network</code> <p>Base network to analyze.</p> required <p>Returns:</p> Name Type Description <code>TopologyGenerator</code> <code>TopologyGenerator</code> <p>The initialized topology generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_topology_generator(\n    args: NestedNamespace,\n    base_net: Network,\n) -&gt; TopologyGenerator:\n    \"\"\"Initialize the appropriate topology generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing generator type and parameters.\n        base_net: Base network to analyze.\n\n    Returns:\n        TopologyGenerator: The initialized topology generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"n_minus_k\":\n        if not hasattr(args, \"k\"):\n            raise ValueError(\"k parameter is required for n_minus_k generator\")\n        generator = NMinusKGenerator(args.k, base_net)\n        used_args = {\"k\": args.k, \"base_net\": base_net}\n\n    elif args.type == \"random\":\n        if not all(hasattr(args, attr) for attr in [\"n_topology_variants\", \"k\"]):\n            raise ValueError(\n                \"n_topology_variants and k parameters are required for random generator\",\n            )\n        elements = getattr(args, \"elements\", [\"line\", \"trafo\", \"gen\", \"sgen\"])\n        generator = RandomComponentDropGenerator(\n            args.n_topology_variants,\n            args.k,\n            base_net,\n            elements,\n        )\n        used_args = {\n            \"n_topology_variants\": args.n_topology_variants,\n            \"k\": args.k,\n            \"base_net\": base_net,\n            \"elements\": elements,\n        }\n\n    elif args.type == \"none\":\n        generator = NoPerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the topology generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#initialize_generation_generator","title":"<code>initialize_generation_generator</code>","text":"<p>Initialize the appropriate generation generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing generator type and parameters.</p> required <code>base_net</code> <code>Network</code> <p>Base network to use.</p> required <p>Returns:</p> Name Type Description <code>GenerationGenerator</code> <code>GenerationGenerator</code> <p>The initialized generation generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_generation_generator(\n    args: NestedNamespace,\n    base_net: Network,\n) -&gt; GenerationGenerator:\n    \"\"\"Initialize the appropriate generation generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing generator type and parameters.\n        base_net: Base network to use.\n\n    Returns:\n        GenerationGenerator: The initialized generation generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"cost_permutation\":\n        generator = PermuteGenCostGenerator(base_net)\n        used_args = {\"base_net\": base_net}\n\n    elif args.type == \"cost_perturbation\":\n        if not hasattr(args, \"sigma\"):\n            raise ValueError(\n                \"sigma parameter is required for cost_perturbation generator\",\n            )\n        generator = PerturbGenCostGenerator(base_net, args.sigma)\n        used_args = {\"sigma\": args.sigma, \"base_net\": base_net}\n\n    elif args.type == \"none\":\n        generator = NoGenPerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the generation generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#initialize_admittance_generator","title":"<code>initialize_admittance_generator</code>","text":"<p>Initialize the appropriate line admittance generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing admittance generator type and parameters.</p> required <code>base_net</code> <code>Network</code> <p>Base network to use.</p> required <p>Returns:</p> Name Type Description <code>AdmittanceGenerator</code> <code>AdmittanceGenerator</code> <p>The initialized line admittance generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_admittance_generator(\n    args: NestedNamespace,\n    base_net: Network,\n) -&gt; AdmittanceGenerator:\n    \"\"\"Initialize the appropriate line admittance generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing admittance generator type and parameters.\n        base_net: Base network to use.\n\n    Returns:\n        AdmittanceGenerator: The initialized line admittance generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"random_perturbation\":\n        if not hasattr(args, \"sigma\"):\n            raise ValueError(\n                \"sigma parameter is required for admittance_perturbation generator\",\n            )\n        generator = PerturbAdmittanceGenerator(base_net, args.sigma)\n        used_args = {\"base_net\": base_net, \"sigma\": args.sigma}\n\n    elif args.type == \"none\":\n        generator = NoAdmittancePerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the admittance generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#classes","title":"Classes","text":""},{"location":"components/param_handler/#nestednamespace","title":"<code>NestedNamespace</code>","text":"<p>               Bases: <code>Namespace</code></p> <p>A namespace object that supports nested structures.</p> <p>This class extends argparse.Namespace to support hierarchical configurations, allowing for easy access and manipulation of nested parameters.</p> <p>Attributes:</p> Name Type Description <code>__dict__</code> <p>Dictionary containing the namespace attributes.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>class NestedNamespace(argparse.Namespace):\n    \"\"\"A namespace object that supports nested structures.\n\n    This class extends argparse.Namespace to support hierarchical configurations,\n    allowing for easy access and manipulation of nested parameters.\n\n    Attributes:\n        __dict__: Dictionary containing the namespace attributes.\n    \"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initializes a NestedNamespace with the given keyword arguments.\n\n        Args:\n            **kwargs: Key-value pairs to initialize the namespace.\n        \"\"\"\n        for key, value in kwargs.items():\n            if isinstance(value, dict):\n                # Recursively convert dictionaries to NestedNamespace\n                setattr(self, key, NestedNamespace(**value))\n            else:\n                setattr(self, key, value)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Converts the NestedNamespace back to a dictionary.\n\n        Returns:\n            Dict containing the namespace attributes, with nested NestedNamespace\n            objects converted to dictionaries.\n        \"\"\"\n        result = {}\n        for key, value in self.__dict__.items():\n            if isinstance(value, NestedNamespace):\n                result[key] = value.to_dict()\n            else:\n                result[key] = value\n        return result\n\n    def flatten(self, parent_key: str = \"\", sep: str = \".\") -&gt; Dict[str, Any]:\n        \"\"\"Flattens the namespace into a single-level dictionary.\n\n        Args:\n            parent_key: Prefix for the keys in the flattened dictionary.\n            sep: Separator for nested keys.\n\n        Returns:\n            Dict with dot-separated keys representing the nested structure.\n        \"\"\"\n        items = []\n        for key, value in self.__dict__.items():\n            new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n            if isinstance(value, NestedNamespace):\n                items.extend(value.flatten(new_key, sep=sep).items())\n            else:\n                items.append((new_key, value))\n        return dict(items)\n</code></pre> <code>__init__(**kwargs)</code> \u00b6 <p>Initializes a NestedNamespace with the given keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Key-value pairs to initialize the namespace.</p> <code>{}</code> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes a NestedNamespace with the given keyword arguments.\n\n    Args:\n        **kwargs: Key-value pairs to initialize the namespace.\n    \"\"\"\n    for key, value in kwargs.items():\n        if isinstance(value, dict):\n            # Recursively convert dictionaries to NestedNamespace\n            setattr(self, key, NestedNamespace(**value))\n        else:\n            setattr(self, key, value)\n</code></pre> <code>flatten(parent_key='', sep='.')</code> \u00b6 <p>Flattens the namespace into a single-level dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>parent_key</code> <code>str</code> <p>Prefix for the keys in the flattened dictionary.</p> <code>''</code> <code>sep</code> <code>str</code> <p>Separator for nested keys.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict with dot-separated keys representing the nested structure.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def flatten(self, parent_key: str = \"\", sep: str = \".\") -&gt; Dict[str, Any]:\n    \"\"\"Flattens the namespace into a single-level dictionary.\n\n    Args:\n        parent_key: Prefix for the keys in the flattened dictionary.\n        sep: Separator for nested keys.\n\n    Returns:\n        Dict with dot-separated keys representing the nested structure.\n    \"\"\"\n    items = []\n    for key, value in self.__dict__.items():\n        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n        if isinstance(value, NestedNamespace):\n            items.extend(value.flatten(new_key, sep=sep).items())\n        else:\n            items.append((new_key, value))\n    return dict(items)\n</code></pre> <code>to_dict()</code> \u00b6 <p>Converts the NestedNamespace back to a dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the namespace attributes, with nested NestedNamespace</p> <code>Dict[str, Any]</code> <p>objects converted to dictionaries.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Converts the NestedNamespace back to a dictionary.\n\n    Returns:\n        Dict containing the namespace attributes, with nested NestedNamespace\n        objects converted to dictionaries.\n    \"\"\"\n    result = {}\n    for key, value in self.__dict__.items():\n        if isinstance(value, NestedNamespace):\n            result[key] = value.to_dict()\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"components/power_balance/","title":"Power Balance","text":"<p>This module provides functions for computing power flow balance and branch admittances.</p>"},{"location":"components/power_balance/#functions","title":"Functions","text":""},{"location":"components/power_balance/#compute_branch_admittances","title":"<code>compute_branch_admittances</code>","text":"<p>Compute branch admittances (Yff, Yft, Ytf, Ytt) from branch parameters.</p> Implements the admittance matrix equations <p>Yff = (y_series + y_sh_f) / t2 Yft = -y_series / tap.conjugate() Ytf = -y_series / tap Ytt = y_series + y_sh_t</p> where <ul> <li>y_series = 1/(r + jx) (series admittance)</li> <li>y_sh_f, y_sh_t = shunt admittances (b/2 each side)</li> <li>tap = tap_mag * exp(j*shift) (complex tap with phase shift)</li> <li>t2 = |tap|^2 = tap_mag^2</li> </ul> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>Union[float, ndarray]</code> <p>Series resistance (ohms) - float or numpy array</p> required <code>x</code> <code>Union[float, ndarray]</code> <p>Series reactance (ohms) - float or numpy array</p> required <code>b</code> <code>Union[float, ndarray]</code> <p>Total shunt susceptance (split equally between both ends) - float or numpy array</p> required <code>tap_mag</code> <code>Union[float, ndarray]</code> <p>Tap magnitude (default: 1.0 for AC lines) - float or numpy array</p> required <code>shift</code> <code>Union[float, ndarray]</code> <p>Phase shift in radians (default: 0.0) - float or numpy array</p> required <p>Returns:</p> Type Description <code>Union[complex, ndarray]</code> <p>Tuple of (Yff, Yft, Ytf, Ytt) complex admittances</p> <code>Union[complex, ndarray]</code> <ul> <li>If inputs are scalars: returns scalars (complex)</li> </ul> <code>Union[complex, ndarray]</code> <ul> <li>If inputs are arrays: returns arrays (numpy.ndarray of complex)</li> </ul> Source code in <code>gridfm_datakit/utils/power_balance.py</code> <pre><code>def compute_branch_admittances(\n    r: Union[float, np.ndarray],\n    x: Union[float, np.ndarray],\n    b: Union[float, np.ndarray],\n    tap_mag: Union[float, np.ndarray],\n    shift: Union[float, np.ndarray],\n) -&gt; Tuple[\n    Union[complex, np.ndarray],\n    Union[complex, np.ndarray],\n    Union[complex, np.ndarray],\n    Union[complex, np.ndarray],\n]:\n    \"\"\"\n    Compute branch admittances (Yff, Yft, Ytf, Ytt) from branch parameters.\n\n    Implements the admittance matrix equations:\n        Yff = (y_series + y_sh_f) / t2\n        Yft = -y_series / tap.conjugate()\n        Ytf = -y_series / tap\n        Ytt = y_series + y_sh_t\n\n    where:\n        - y_series = 1/(r + jx) (series admittance)\n        - y_sh_f, y_sh_t = shunt admittances (b/2 each side)\n        - tap = tap_mag * exp(j*shift) (complex tap with phase shift)\n        - t2 = |tap|^2 = tap_mag^2\n\n    Args:\n        r: Series resistance (ohms) - float or numpy array\n        x: Series reactance (ohms) - float or numpy array\n        b: Total shunt susceptance (split equally between both ends) - float or numpy array\n        tap_mag: Tap magnitude (default: 1.0 for AC lines) - float or numpy array\n        shift: Phase shift in radians (default: 0.0) - float or numpy array\n\n    Returns:\n        Tuple of (Yff, Yft, Ytf, Ytt) complex admittances\n        - If inputs are scalars: returns scalars (complex)\n        - If inputs are arrays: returns arrays (numpy.ndarray of complex)\n    \"\"\"\n    # Convert to numpy arrays for vectorized operations\n    r = np.asarray(r)\n    x = np.asarray(x)\n    b = np.asarray(b)\n    tap_mag = np.asarray(tap_mag)\n    shift = np.asarray(shift)\n\n    # Calculate series admittance: y_series = 1/(r + jx)\n    z_series = r + 1j * x\n    y_series = 1.0 / z_series\n\n    # Calculate tap with phase shift: tap = tap_mag * exp(j*shift)\n    tap = tap_mag * (np.cos(shift) + 1j * np.sin(shift))\n    t2 = tap_mag**2  # |tap|^2 = tap_mag^2\n\n    # Calculate shunt admittances (split equally between both ends)\n    y_sh = 1j * (b / 2.0)\n\n    # Calculate admittance matrix elements\n    Yff = (y_series + y_sh) / t2\n    Yft = -y_series / np.conj(tap)\n    Ytf = -y_series / tap\n    Ytt = y_series + y_sh\n\n    return Yff, Yft, Ytf, Ytt\n</code></pre>"},{"location":"components/power_balance/#compute_branch_powers_vectorized","title":"<code>compute_branch_powers_vectorized</code>","text":"<p>Compute branch power flows for all branches in a vectorized fashion.</p> <p>Parameters:</p> Name Type Description Default <code>branch_df</code> <code>DataFrame</code> <p>DataFrame with branch data including Yff, Yft, Ytf, Ytt admittances</p> required <code>bus_df</code> <code>DataFrame</code> <p>DataFrame with bus data including Vm and Va (or Va_dc for DC mode)</p> required <code>dc</code> <code>bool</code> <p>If True, use DC power flow (Va_dc, Vm=1.0), else use AC (Va, Vm)</p> required <code>sn_mva</code> <code>float</code> <p>System base power in MVA used to scale complex power results</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray, ndarray]</code> <p>Tuple of (pf, qf, pt, qt) power flow arrays in MW/MVAR</p> Source code in <code>gridfm_datakit/utils/power_balance.py</code> <pre><code>def compute_branch_powers_vectorized(\n    branch_df: pd.DataFrame,\n    bus_df: pd.DataFrame,\n    dc: bool,\n    sn_mva: float,\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute branch power flows for all branches in a vectorized fashion.\n\n    Args:\n        branch_df: DataFrame with branch data including Yff, Yft, Ytf, Ytt admittances\n        bus_df: DataFrame with bus data including Vm and Va (or Va_dc for DC mode)\n        dc: If True, use DC power flow (Va_dc, Vm=1.0), else use AC (Va, Vm)\n        sn_mva: System base power in MVA used to scale complex power results\n\n    Returns:\n        Tuple of (pf, qf, pt, qt) power flow arrays in MW/MVAR\n    \"\"\"\n    scenarios = branch_df[\"scenario\"].to_numpy(dtype=int)\n    from_bus = branch_df[\"from_bus\"].to_numpy(dtype=int)\n    to_bus = branch_df[\"to_bus\"].to_numpy(dtype=int)\n\n    idx_from = pd.MultiIndex.from_arrays(\n        [scenarios, from_bus],\n        names=[\"scenario\", \"bus\"],\n    )\n    idx_to = pd.MultiIndex.from_arrays([scenarios, to_bus], names=[\"scenario\", \"bus\"])\n\n    bus_df_indexed = bus_df.set_index([\"scenario\", \"bus\"]).copy()\n    Va = np.radians(bus_df_indexed[\"Va_dc\" if dc else \"Va\"])\n    Vm = 1.0 if dc else bus_df_indexed[\"Vm\"]\n    bus_df_indexed[\"V\"] = Vm * (np.cos(Va) + 1j * np.sin(Va))\n    Vf = bus_df_indexed[\"V\"].loc[idx_from].to_numpy(dtype=np.complex128)\n    Vt = bus_df_indexed[\"V\"].loc[idx_to].to_numpy(dtype=np.complex128)\n\n    Yff = branch_df[\"Yff_r\"].to_numpy(dtype=np.float64) + 1j * branch_df[\n        \"Yff_i\"\n    ].to_numpy(dtype=np.float64)\n    Yft = branch_df[\"Yft_r\"].to_numpy(dtype=np.float64) + 1j * branch_df[\n        \"Yft_i\"\n    ].to_numpy(dtype=np.float64)\n    Ytf = branch_df[\"Ytf_r\"].to_numpy(dtype=np.float64) + 1j * branch_df[\n        \"Ytf_i\"\n    ].to_numpy(dtype=np.float64)\n    Ytt = branch_df[\"Ytt_r\"].to_numpy(dtype=np.float64) + 1j * branch_df[\n        \"Ytt_i\"\n    ].to_numpy(dtype=np.float64)\n\n    If = Yff * Vf + Yft * Vt\n    It = Ytt * Vt + Ytf * Vf\n\n    Sf = Vf * np.conj(If) * sn_mva\n    St = Vt * np.conj(It) * sn_mva\n\n    pf = np.real(Sf)\n    qf = np.imag(Sf)\n    pt = np.real(St)\n    qt = np.imag(St)\n\n    return pf, qf, pt, qt\n</code></pre>"},{"location":"components/power_balance/#compute_bus_balance","title":"<code>compute_bus_balance</code>","text":"<p>Compute power balance at each bus for AC or DC mode.</p> <p>Balance equation: P_inj - P_out - P_sh = P_mis (and Q for AC) where: - P_inj: net injection (generation - demand) - P_out: total outgoing branch flows (from + to sides) - P_sh: shunt power consumption</p> <p>Parameters:</p> Name Type Description Default <code>bus_df</code> <code>DataFrame</code> <p>DataFrame with bus data (scenario, bus, Pg, Qg, Pd, Qd, GS, BS, Vm)</p> required <code>branch_df</code> <code>DataFrame</code> <p>DataFrame with branch data (scenario, from_bus, to_bus)</p> required <code>flows</code> <code>DataFrame</code> <p>DataFrame with flow data. For AC: columns (pf, qf, pt, qt). For DC: columns (pf_dc, pt_dc)</p> required <code>dc</code> <code>bool</code> <p>If True, compute DC balance, else AC balance</p> required <code>sn_mva</code> <code>float</code> <p>System base power in MVA used to scale power terms</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns [scenario, bus, P_mis_ac, Q_mis_ac] for AC or [scenario, bus, P_mis_dc] for DC</p> Source code in <code>gridfm_datakit/utils/power_balance.py</code> <pre><code>def compute_bus_balance(\n    bus_df: pd.DataFrame,\n    branch_df: pd.DataFrame,\n    flows: pd.DataFrame,\n    dc: bool,\n    sn_mva: float,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Compute power balance at each bus for AC or DC mode.\n\n    Balance equation: P_inj - P_out - P_sh = P_mis (and Q for AC)\n    where:\n    - P_inj: net injection (generation - demand)\n    - P_out: total outgoing branch flows (from + to sides)\n    - P_sh: shunt power consumption\n\n    Args:\n        bus_df: DataFrame with bus data (scenario, bus, Pg, Qg, Pd, Qd, GS, BS, Vm)\n        branch_df: DataFrame with branch data (scenario, from_bus, to_bus)\n        flows: DataFrame with flow data. For AC: columns (pf, qf, pt, qt). For DC: columns (pf_dc, pt_dc)\n        dc: If True, compute DC balance, else AC balance\n        sn_mva: System base power in MVA used to scale power terms\n\n    Returns:\n        DataFrame with columns [scenario, bus, P_mis_ac, Q_mis_ac] for AC or [scenario, bus, P_mis_dc] for DC\n    \"\"\"\n    # ===== Step 1: Aggregate branch flows per bus =====\n    # For each bus, sum flows where it is the \"from\" bus (pf, qf) and where it is the \"to\" bus (pt, qt)\n    # For AC: include both active (pf, pt) and reactive (qf, qt) flows\n    # For DC: only active flows (pf, pt)\n\n    # Prepare bus mapping: from_bus -&gt; bus and to_bus -&gt; bus\n\n    if not dc:\n        from_bus = pd.concat(\n            [branch_df[[\"scenario\", \"from_bus\"]], flows[[\"pf\", \"qf\"]]],\n            axis=1,\n        ).rename(columns={\"from_bus\": \"bus\"})\n        to_bus = pd.concat(\n            [branch_df[[\"scenario\", \"to_bus\"]], flows[[\"pt\", \"qt\"]]],\n            axis=1,\n        ).rename(columns={\"to_bus\": \"bus\"})\n    else:\n        from_bus = pd.concat(\n            [branch_df[[\"scenario\", \"from_bus\"]], flows[[\"pf_dc\"]]],\n            axis=1,\n        ).rename(columns={\"from_bus\": \"bus\", \"pf_dc\": \"pf\"})\n        to_bus = pd.concat(\n            [branch_df[[\"scenario\", \"to_bus\"]], flows[[\"pt_dc\"]]],\n            axis=1,\n        ).rename(columns={\"to_bus\": \"bus\", \"pt_dc\": \"pt\"})\n\n    # set int dtype for scenario and bus\n    from_bus[\"scenario\"] = from_bus[\"scenario\"].astype(int)\n    from_bus[\"bus\"] = from_bus[\"bus\"].astype(int)\n    to_bus[\"scenario\"] = to_bus[\"scenario\"].astype(int)\n    to_bus[\"bus\"] = to_bus[\"bus\"].astype(int)\n\n    # Sum flows by (scenario, bus)\n    out_from = from_bus.groupby([\"scenario\", \"bus\"], as_index=False).sum()\n    out_to = to_bus.groupby([\"scenario\", \"bus\"], as_index=False).sum()\n\n    # Combine from and to flows, then compute total power flow\n    # Note: pf is power at \"from\" bus, pt is power at \"to\" bus (both positive when flowing from-&gt;to)\n    out = out_from.merge(out_to, on=[\"scenario\", \"bus\"], how=\"outer\").fillna(0.0)\n    out[\"P_out\"] = out[\"pf\"] + out[\"pt\"]\n\n    if not dc:\n        out[\"Q_out\"] = out[\"qf\"] + out[\"qt\"]\n        out = out[[\"scenario\", \"bus\", \"P_out\", \"Q_out\"]]\n    else:\n        out = out[[\"scenario\", \"bus\", \"P_out\"]]\n\n    # ===== Step 2: Compute shunt power consumption =====\n    # Shunt power = G*|V|^2 (active) and -B*|V|^2 (reactive)\n    # For DC: |V| = 1.0, for AC: |V| = Vm from solution\n    absV2 = 1.0 if dc else bus_df[\"Vm\"].to_numpy(dtype=np.float64) ** 2\n    P_sh = bus_df[\"GS\"].to_numpy(dtype=np.float64) * absV2 * sn_mva\n    Q_sh = (\n        -(bus_df[\"BS\"].to_numpy(dtype=np.float64) * absV2 * sn_mva) if not dc else None\n    )\n\n    # ===== Step 3: Compute net injections =====\n    # Net injection = generation - demand\n    if dc:\n        inj = bus_df[[\"scenario\", \"bus\", \"Pg_dc\", \"Pd\"]].copy()\n        inj[\"scenario\"] = inj[\"scenario\"].astype(int)\n        inj[\"bus\"] = inj[\"bus\"].astype(int)\n        inj[\"P_inj\"] = inj[\"Pg_dc\"].astype(np.float64) - inj[\"Pd\"].astype(np.float64)\n        inj[\"P_sh\"] = P_sh\n        inj = inj[[\"scenario\", \"bus\", \"P_inj\", \"P_sh\"]]\n    else:\n        inj = bus_df[[\"scenario\", \"bus\", \"Pg\", \"Qg\", \"Pd\", \"Qd\"]].copy()\n        inj[\"scenario\"] = inj[\"scenario\"].astype(int)\n        inj[\"bus\"] = inj[\"bus\"].astype(int)\n        inj[\"P_inj\"] = inj[\"Pg\"].astype(np.float64) - inj[\"Pd\"].astype(np.float64)\n        inj[\"Q_inj\"] = inj[\"Qg\"].astype(np.float64) - inj[\"Qd\"].astype(np.float64)\n        inj[\"P_sh\"] = P_sh\n        inj[\"Q_sh\"] = Q_sh\n        inj = inj[[\"scenario\", \"bus\", \"P_inj\", \"Q_inj\", \"P_sh\", \"Q_sh\"]]\n\n    # ===== Step 4: Compute power balance mismatch =====\n    # Mismatch = injection - outgoing flows - shunt consumption\n    bal = inj.merge(out, on=[\"scenario\", \"bus\"], how=\"left\").fillna(0.0)\n    if not dc:\n        bal[\"Q_mis_ac\"] = np.abs(bal[\"Q_inj\"] - bal[\"Q_out\"] - bal[\"Q_sh\"])\n        bal[\"P_mis_ac\"] = np.abs(bal[\"P_inj\"] - bal[\"P_out\"] - bal[\"P_sh\"])\n        return bal[[\"scenario\", \"bus\", \"P_mis_ac\", \"Q_mis_ac\"]]\n    else:\n        bal[\"P_mis_dc\"] = np.abs(bal[\"P_inj\"] - bal[\"P_out\"] - bal[\"P_sh\"])\n        # assign nan to scenarios that had nan (it is enough to check Va_dc since data validation ensures that all DC columns are NaN for the same scenarios)\n        scenarios_with_nan = set(bus_df[bus_df[\"Va_dc\"].isna()][\"scenario\"].unique())\n        bal.loc[bal[\"scenario\"].isin(scenarios_with_nan), \"P_mis_dc\"] = np.nan\n        return bal[[\"scenario\", \"bus\", \"P_mis_dc\"]]\n</code></pre>"},{"location":"components/process_network/","title":"Process Network","text":"<p>This module provides functions for processing power networks and scenarios.</p>"},{"location":"components/process_network/#pf_preprocessing","title":"<code>pf_preprocessing</code>","text":"<p>Set variables to the results of OPF.</p> <p>Updates the following network components with OPF results:</p> <ul> <li>sgen.p_mw: active power generation for static generators</li> <li>gen.p_mw, gen.vm_pu: active power and voltage magnitude for generators</li> </ul> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network to preprocess.</p> required <code>res</code> <code>Dict[str, Any]</code> <p>OPF result dictionary containing solution data.</p> required <p>Returns:</p> Type Description <code>Network</code> <p>Updated network with OPF results applied.</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def pf_preprocessing(net: Network, res: Dict[str, Any]) -&gt; Network:\n    \"\"\"Set variables to the results of OPF.\n\n    Updates the following network components with OPF results:\n\n    - sgen.p_mw: active power generation for static generators\n    - gen.p_mw, gen.vm_pu: active power and voltage magnitude for generators\n\n    Args:\n        net: The power network to preprocess.\n        res: OPF result dictionary containing solution data.\n\n    Returns:\n        Updated network with OPF results applied.\n    \"\"\"\n    pg = [\n        res[\"solution\"][\"gen\"][str(i + 1)][\"pg\"] * net.baseMVA\n        for i in net.idx_gens_in_service\n    ]\n    vm = [\n        res[\"solution\"][\"bus\"][str(net.reverse_bus_index_mapping[i])][\"vm\"]\n        for i in range(net.buses.shape[0])\n    ]\n\n    net.Pg_gen = pg\n    net.Vm = vm\n\n    return net\n</code></pre>"},{"location":"components/process_network/#pf_post_processing","title":"<code>pf_post_processing</code>","text":"<p>Post-process solved network results into numpy arrays for CSV export.</p> <p>This function extracts power flow results and builds four arrays matching the column schemas defined in <code>gridfm_datakit.utils.column_names</code>:</p> <ul> <li>Bus data with BUS_COLUMNS (+ DC_BUS_COLUMNS if include_dc_res=True)</li> <li>Generator data with GEN_COLUMNS</li> <li>Branch data with BRANCH_COLUMNS</li> <li>Y-bus nonzero entries with [index1, index2, G, B]</li> </ul> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network to process (must have solved power flow results).</p> required <code>res</code> <code>Dict[str, Any]</code> <p>Power flow result dictionary containing solution data.</p> required <code>include_dc_res</code> <code>bool</code> <p>If True, include DC power flow voltage magnitude/angle (Vm_dc, Va_dc).</p> required <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary containing:</p> <code>Dict[str, ndarray]</code> <ul> <li>\"bus\": np.ndarray with bus-level features</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>\"gen\": np.ndarray with generator features</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>\"branch\": np.ndarray with branch features and admittances</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>\"Y_bus\": np.ndarray with nonzero Y-bus entries</li> </ul> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def pf_post_processing(\n    scenario_index: int,\n    net: Network,\n    res: Dict[str, Any],\n    res_dc: Dict[str, Any],\n    include_dc_res: bool,\n) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Post-process solved network results into numpy arrays for CSV export.\n\n    This function extracts power flow results and builds four arrays matching\n    the column schemas defined in `gridfm_datakit.utils.column_names`:\n\n    - Bus data with BUS_COLUMNS (+ DC_BUS_COLUMNS if include_dc_res=True)\n    - Generator data with GEN_COLUMNS\n    - Branch data with BRANCH_COLUMNS\n    - Y-bus nonzero entries with [index1, index2, G, B]\n\n    Args:\n        net: The power network to process (must have solved power flow results).\n        res: Power flow result dictionary containing solution data.\n        include_dc_res: If True, include DC power flow voltage magnitude/angle (Vm_dc, Va_dc).\n\n    Returns:\n        Dictionary containing:\n        - \"bus\": np.ndarray with bus-level features\n        - \"gen\": np.ndarray with generator features\n        - \"branch\": np.ndarray with branch features and admittances\n        - \"Y_bus\": np.ndarray with nonzero Y-bus entries\n    \"\"\"\n\n    # --- Edge (branch) info ---\n    n_branches = net.branches.shape[0]\n    n_cols = (\n        len(BRANCH_COLUMNS) + len(DC_BRANCH_COLUMNS)\n        if include_dc_res\n        else len(BRANCH_COLUMNS)\n    )\n    X_branch = np.zeros((n_branches, n_cols))\n    X_branch[:, 0] = scenario_index\n    X_branch[:, 1] = list(range(n_branches))\n    X_branch[:, 2] = np.real(net.branches[:, F_BUS])\n    X_branch[:, 3] = np.real(net.branches[:, T_BUS])\n\n    # pf, qf, pt, qt\n    if res[\"solution\"][\"pf\"]:\n        # when solving pf, the flow of all branches is computed, so the number of branches in solution should match the number of branches in network\n        assert len(res[\"solution\"][\"branch\"]) == n_branches, (\n            \"Number of branches in solution should match number of branches in network\"\n        )\n    else:\n        # when solving opf, the flow of only the in-service branches is computed, so the number of branches in solution should match the number of in-service branches in network\n        assert len(res[\"solution\"][\"branch\"]) == len(net.idx_branches_in_service), (\n            \"Number of branches in solution should match number of branches in network\"\n        )\n\n    X_branch[net.idx_branches_in_service, 4] = np.array(\n        [\n            res[\"solution\"][\"branch\"][str(i + 1)][\"pf\"] * net.baseMVA\n            for i in net.idx_branches_in_service\n        ],\n    )\n    X_branch[net.idx_branches_in_service, 5] = np.array(\n        [\n            res[\"solution\"][\"branch\"][str(i + 1)][\"qf\"] * net.baseMVA\n            for i in net.idx_branches_in_service\n        ],\n    )\n    X_branch[net.idx_branches_in_service, 6] = np.array(\n        [\n            res[\"solution\"][\"branch\"][str(i + 1)][\"pt\"] * net.baseMVA\n            for i in net.idx_branches_in_service\n        ],\n    )\n    X_branch[net.idx_branches_in_service, 7] = np.array(\n        [\n            res[\"solution\"][\"branch\"][str(i + 1)][\"qt\"] * net.baseMVA\n            for i in net.idx_branches_in_service\n        ],\n    )\n\n    X_branch[:, 8] = net.branches[:, BR_R]\n    X_branch[:, 9] = net.branches[:, BR_X]\n    X_branch[:, 10] = net.branches[:, BR_B]\n\n    # admittances\n    Ytt, Yff, Yft, Ytf = branch_vectors(net.branches, net.branches.shape[0])\n    X_branch[:, 11] = np.real(Yff)\n    X_branch[:, 12] = np.imag(Yff)\n    X_branch[:, 13] = np.real(Yft)\n    X_branch[:, 14] = np.imag(Yft)\n    X_branch[:, 15] = np.real(Ytf)\n    X_branch[:, 16] = np.imag(Ytf)\n    X_branch[:, 17] = np.real(Ytt)\n    X_branch[:, 18] = np.imag(Ytt)\n\n    X_branch[:, 19] = net.branches[:, TAP]\n    # assign 1 to tap = 0\n    X_branch[net.branches[:, TAP] == 0, 19] = 1\n\n    X_branch[:, 20] = net.branches[:, SHIFT]\n    X_branch[:, 21] = net.branches[:, ANGMIN]\n    X_branch[:, 22] = net.branches[:, ANGMAX]\n    X_branch[:, 23] = net.branches[:, RATE_A]\n    X_branch[:, 24] = net.branches[:, BR_STATUS]\n\n    if include_dc_res:\n        if res_dc is not None:\n            pf_dc = np.array(\n                [\n                    res_dc[\"solution\"][\"branch\"][str(i + 1)][\"pf\"] * net.baseMVA\n                    for i in net.idx_branches_in_service\n                ],\n            )\n            pt_dc = np.array(\n                [\n                    res_dc[\"solution\"][\"branch\"][str(i + 1)][\"pt\"] * net.baseMVA\n                    for i in net.idx_branches_in_service\n                ],\n            )\n            X_branch[net.idx_branches_in_service, 25] = pf_dc\n            X_branch[net.idx_branches_in_service, 26] = pt_dc\n        else:\n            X_branch[net.idx_branches_in_service, 25] = np.nan\n            X_branch[net.idx_branches_in_service, 26] = np.nan\n\n    # --- Bus data ---\n    n_buses = net.buses.shape[0]\n    n_cols = (\n        len(BUS_COLUMNS) + len(DC_BUS_COLUMNS) if include_dc_res else len(BUS_COLUMNS)\n    )\n    X_bus = np.zeros((n_buses, n_cols))\n\n    # --- Loads ---\n    X_bus[:, 0] = scenario_index\n    X_bus[:, 1] = net.buses[:, BUS_I]  # bus\n    X_bus[:, 2] = net.buses[:, PD]\n    X_bus[:, 3] = net.buses[:, QD]\n\n    # --- Generator injections\n    assert len(res[\"solution\"][\"gen\"]) == len(net.idx_gens_in_service), (\n        \"Number of generators in solution should match number of generators in network\"\n    )\n    pg_gen = np.array(\n        [\n            res[\"solution\"][\"gen\"][str(i + 1)][\"pg\"] * net.baseMVA\n            for i in net.idx_gens_in_service\n        ],\n    )\n    qg_gen = np.array(\n        [\n            res[\"solution\"][\"gen\"][str(i + 1)][\"qg\"] * net.baseMVA\n            for i in net.idx_gens_in_service\n        ],\n    )\n    gen_bus = net.gens[net.idx_gens_in_service, GEN_BUS].astype(int)\n    Pg_bus = np.bincount(gen_bus, weights=pg_gen, minlength=n_buses)\n    Qg_bus = np.bincount(gen_bus, weights=qg_gen, minlength=n_buses)\n\n    assert np.all(Pg_bus[net.buses[:, BUS_TYPE] == PQ] == 0)\n    assert np.all(Qg_bus[net.buses[:, BUS_TYPE] == PQ] == 0)\n\n    if include_dc_res:\n        if res_dc is not None:\n            # check if \"gen\" key is in res_dc[\"solution\"]\n            if \"gen\" in res_dc[\"solution\"]:\n                pg_gen_dc = np.array(\n                    [\n                        res_dc[\"solution\"][\"gen\"][str(i + 1)][\"pg\"] * net.baseMVA\n                        for i in net.idx_gens_in_service\n                    ],\n                )\n            else:\n                pg_gen_dc = apply_slack_single_gen(net, pg_gen, Pg_bus, pf_dc, pt_dc)\n            Pg_bus_dc = np.bincount(gen_bus, weights=pg_gen_dc, minlength=n_buses)\n            assert np.all(Pg_bus_dc[net.buses[:, BUS_TYPE] == PQ] == 0)\n\n    X_bus[:, 4] = Pg_bus\n    X_bus[:, 5] = Qg_bus\n\n    # Voltage\n    assert set([int(k) for k in res[\"solution\"][\"bus\"].keys()]) == set(\n        net.reverse_bus_index_mapping.values(),\n    ), \"Buses in solution should match buses in network\"\n\n    X_bus[:, 6] = [\n        res[\"solution\"][\"bus\"][str(net.reverse_bus_index_mapping[i])][\"vm\"]\n        for i in range(n_buses)\n    ]\n    va = np.rad2deg(\n        [\n            res[\"solution\"][\"bus\"][str(net.reverse_bus_index_mapping[i])][\"va\"]\n            for i in range(n_buses)\n        ],\n    )\n\n    # convert to range [-180, 180]\n    va = (va + 180) % 360 - 180\n    X_bus[:, 7] = va\n\n    # one-hot encoding of bus type\n    assert np.all(np.isin(net.buses[:, BUS_TYPE], [PQ, PV, REF])), (\n        \"Bus type should be PQ, PV, or REF, no disconnected buses (4)\"\n    )\n\n    X_bus[np.arange(n_buses), 8 + net.buses[:, BUS_TYPE].astype(int) - 1] = (\n        1  # because type is 1, 2, 3, not 0, 1, 2\n    )\n\n    # base_kv, min_vm_pu, max_vm_pu\n    X_bus[:, 11] = net.buses[:, BASE_KV]\n    X_bus[:, 12] = net.buses[:, VMIN]\n    X_bus[:, 13] = net.buses[:, VMAX]\n\n    X_bus[:, 14] = net.buses[:, GS] / net.baseMVA\n    X_bus[:, 15] = net.buses[:, BS] / net.baseMVA\n\n    if include_dc_res:\n        if res_dc is not None:\n            va = np.rad2deg(\n                [\n                    res_dc[\"solution\"][\"bus\"][str(net.reverse_bus_index_mapping[i])][\n                        \"va\"\n                    ]\n                    for i in range(n_buses)\n                ],\n            )\n            # convert to range [-180, 180]\n            va = (va + 180) % 360 - 180\n            X_bus[:, 16] = va\n            X_bus[:, 17] = Pg_bus_dc\n        else:\n            X_bus[:, 16] = np.nan\n            X_bus[:, 17] = np.nan\n\n    # --- Generator data ---\n\n    n_cost = net.gencosts[0, NCOST]\n    assert np.all(net.gencosts[:, NCOST] == n_cost), (\n        \"NCOST should be the same for all generators\"\n    )\n    n_gens = net.gens.shape[0]\n    n_cols = (\n        len(GEN_COLUMNS) + len(DC_GEN_COLUMNS) if include_dc_res else len(GEN_COLUMNS)\n    )\n\n    X_gen = np.zeros((n_gens, n_cols))\n    X_gen[:, 0] = scenario_index\n    X_gen[:, 1] = list(range(n_gens))\n    X_gen[:, 2] = net.gens[:, GEN_BUS]\n    X_gen[net.idx_gens_in_service, 3] = pg_gen  # 0 if not in service\n    X_gen[net.idx_gens_in_service, 4] = qg_gen  # 0 if not in service\n    X_gen[:, 5] = net.gens[:, PMIN]\n    X_gen[:, 6] = net.gens[:, PMAX]\n    X_gen[:, 7] = net.gens[:, QMIN]\n    X_gen[:, 8] = net.gens[:, QMAX]\n\n    if n_cost == 3:  # order in .m file is c2, c1, c0\n        X_gen[:, 9] = net.gencosts[:, COST + 2]\n        X_gen[:, 10] = net.gencosts[:, COST + 1]\n        X_gen[:, 11] = net.gencosts[:, COST]\n\n    if n_cost == 2:  # order in .m file is c1, c0, and there is no cp2 cost\n        X_gen[:, 9] = net.gencosts[:, COST + 1]\n        X_gen[:, 10] = net.gencosts[:, COST]\n        X_gen[:, 11] = 0  # no cp2 cost for linear cost function\n\n    if n_cost == 1:  # order in .m file is c0, and there is no cp1 or cp2 cost\n        X_gen[:, 9] = net.gencosts[:, COST]\n        X_gen[:, 10] = 0  # no cp1 cost for constant cost function\n        X_gen[:, 11] = 0  # no cp2 cost for constant cost function\n\n    X_gen[net.idx_gens_in_service, 12] = 1\n\n    # slack gen (can be any generator connected to the ref node)\n    slack_gen_idx = np.where(net.gens[:, GEN_BUS] == net.ref_bus_idx)[0]\n    X_gen[slack_gen_idx, 13] = 1\n\n    if include_dc_res:\n        if res_dc is not None:\n            X_gen[net.idx_gens_in_service, 14] = pg_gen_dc\n        else:\n            X_gen[net.idx_gens_in_service, 14] = np.nan\n\n    # --- Y-bus ---\n    Y_bus, Yf, Yt = makeYbus(net.baseMVA, net.buses, net.branches)\n\n    i, j = np.nonzero(Y_bus)\n    # note that Y_bus[i,j] can be != 0 even if a branch from i to j is not in service because there might be other branches connected to the same buses\n\n    s = Y_bus[i, j]\n    G = np.real(s)\n    B = np.imag(s)\n\n    edge_index = np.column_stack((i, j))\n    edge_attr = np.stack((G, B)).T\n    Y_bus = np.zeros(\n        (edge_index.shape[0], edge_attr.shape[1] + edge_index.shape[1] + 1),\n    )\n    Y_bus[:, 0] = scenario_index\n    Y_bus[:, 1:] = np.column_stack((edge_index, edge_attr))\n\n    # ---- runtime data ----\n    n_cols = (\n        len(RUNTIME_COLUMNS) + len(DC_RUNTIME_COLUMNS)\n        if include_dc_res\n        else len(RUNTIME_COLUMNS)\n    )\n    X_runtime = np.zeros((1, n_cols))\n    X_runtime[0, 0] = scenario_index\n    X_runtime[0, 1] = res[\"solve_time\"]\n    if include_dc_res:\n        if res_dc is not None:\n            X_runtime[0, 2] = res_dc[\"solve_time\"]\n        else:\n            X_runtime[0, 2] = np.nan\n    return {\n        \"bus\": X_bus,\n        \"gen\": X_gen,\n        \"branch\": X_branch,\n        \"Y_bus\": Y_bus,\n        \"runtime\": X_runtime,\n    }\n</code></pre>"},{"location":"components/process_network/#process_scenario_opf_mode","title":"<code>process_scenario_opf_mode</code>","text":"<p>Processes a load scenario in OPF mode</p> <p>In OPF mode, perturbations are applied first, then OPF is run to get generator setpoints that account for the perturbed topology. This ensures all constraints are satisfied in the final operating point.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>scenarios</code> <code>ndarray</code> <p>Array of load scenarios with shape (n_loads, n_scenarios, 2).</p> required <code>scenario_index</code> <code>int</code> <p>Index of the current scenario to process.</p> required <code>topology_generator</code> <code>TopologyGenerator</code> <p>Generator for topology perturbations (line/transformer outages).</p> required <code>generation_generator</code> <code>GenerationGenerator</code> <p>Generator for generation cost perturbations.</p> required <code>admittance_generator</code> <code>AdmittanceGenerator</code> <p>Generator for line admittance perturbations.</p> required <code>local_processed_data</code> <code>List[ndarray]</code> <p>List to accumulate processed data tuples.</p> required <code>error_log_file</code> <code>str</code> <p>Path to error log file for recording failures.</p> required <code>include_dc_res</code> <code>bool</code> <p>Whether to include DC power flow results in output.</p> required <code>jl</code> <code>Any</code> <p>Julia interface object for running power flow calculations.</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>Updated list of processed data (bus, gen, branch, Y_bus arrays)</p> Note <p>Random seed is controlled by the calling context (process_scenario_chunk).</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def process_scenario_opf_mode(\n    net: Network,\n    scenarios: np.ndarray,\n    scenario_index: int,\n    topology_generator: TopologyGenerator,\n    generation_generator: GenerationGenerator,\n    admittance_generator: AdmittanceGenerator,\n    local_processed_data: List[np.ndarray],\n    error_log_file: str,\n    include_dc_res: bool,\n    jl: Any,\n) -&gt; List[np.ndarray]:\n    \"\"\"Processes a load scenario in OPF mode\n\n    In OPF mode, perturbations are applied first, then OPF is run to get\n    generator setpoints that account for the perturbed topology. This ensures\n    all constraints are satisfied in the final operating point.\n\n    Args:\n        net: The power network.\n        scenarios: Array of load scenarios with shape (n_loads, n_scenarios, 2).\n        scenario_index: Index of the current scenario to process.\n        topology_generator: Generator for topology perturbations (line/transformer outages).\n        generation_generator: Generator for generation cost perturbations.\n        admittance_generator: Generator for line admittance perturbations.\n        local_processed_data: List to accumulate processed data tuples.\n        error_log_file: Path to error log file for recording failures.\n        include_dc_res: Whether to include DC power flow results in output.\n        jl: Julia interface object for running power flow calculations.\n\n    Returns:\n        Updated list of processed data (bus, gen, branch, Y_bus arrays)\n\n    Note:\n        Random seed is controlled by the calling context (process_scenario_chunk).\n    \"\"\"\n\n    # apply the load scenario to the network\n    net.Pd = scenarios[:, scenario_index, 0]\n    net.Qd = scenarios[:, scenario_index, 1]\n\n    # Generate perturbed topologies\n    perturbations = topology_generator.generate(net)\n\n    # Apply generation perturbations\n    perturbations = generation_generator.generate(perturbations)\n\n    # Apply admittance perturbations\n    perturbations = admittance_generator.generate(perturbations)\n\n    for perturbation in (\n        perturbations\n    ):  # (that returns copies of the network with the topology perturbation applied)\n        res_dcopf = None\n        if include_dc_res:\n            try:\n                res_dcopf = run_dcopf(perturbation, jl)\n            except Exception as e:\n                with open(error_log_file, \"a\") as f:\n                    f.write(\n                        f\"Caught an exception at scenario {scenario_index} in run_dcopf function: {e}\\n\",\n                    )\n        try:\n            # run OPF to get the gen set points. Here the set points account for the topology perturbation.\n            res = run_opf(perturbation, jl)\n        except Exception as e:\n            with open(error_log_file, \"a\") as f:\n                f.write(\n                    f\"Caught an exception at scenario {scenario_index} in run_opf function: {e}\\n\",\n                )\n            continue\n\n        # Append processed power flow data\n        pf_data = pf_post_processing(\n            scenario_index,\n            perturbation,\n            res,\n            res_dcopf,\n            include_dc_res,\n        )\n        local_processed_data.append(\n            (\n                pf_data[\"bus\"],\n                pf_data[\"gen\"],\n                pf_data[\"branch\"],\n                pf_data[\"Y_bus\"],\n                pf_data[\"runtime\"],\n            ),\n        )\n    return local_processed_data\n</code></pre>"},{"location":"components/process_network/#process_scenario_pf_mode","title":"<code>process_scenario_pf_mode</code>","text":"<p>Processes a load scenario in PF mode</p> <p>In PF mode, OPF is run first to get generator setpoints, then topology perturbations are applied. This can lead to constraint violations (overloads, voltage violations) since the setpoints are not re-optimized for the new topology.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <code>scenarios</code> <code>ndarray</code> <p>Array of load scenarios with shape (n_loads, n_scenarios, 2).</p> required <code>scenario_index</code> <code>int</code> <p>Index of the current scenario to process.</p> required <code>topology_generator</code> <code>TopologyGenerator</code> <p>Generator for topology perturbations (line/transformer outages).</p> required <code>generation_generator</code> <code>GenerationGenerator</code> <p>Generator for generation cost perturbations.</p> required <code>admittance_generator</code> <code>AdmittanceGenerator</code> <p>Generator for line admittance perturbations.</p> required <code>local_processed_data</code> <code>List[ndarray]</code> <p>List to accumulate processed data tuples.</p> required <code>error_log_file</code> <code>str</code> <p>Path to error log file for recording failures.</p> required <code>include_dc_res</code> <code>bool</code> <p>Whether to include DC power flow results in output.</p> required <code>pf_fast</code> <code>bool</code> <p>Whether to use fast AC PF solver.</p> required <code>dcpf_fast</code> <code>bool</code> <p>Whether to use fast DC PF solver.</p> required <code>jl</code> <code>Any</code> <p>Julia interface object for running power flow calculations.</p> required <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>Updated list of processed data (bus, gen, branch, Y_bus arrays)</p> Note <p>Random seed is controlled by the calling context (process_scenario_chunk).</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def process_scenario_pf_mode(\n    net: Network,\n    scenarios: np.ndarray,\n    scenario_index: int,\n    topology_generator: TopologyGenerator,\n    generation_generator: GenerationGenerator,\n    admittance_generator: AdmittanceGenerator,\n    local_processed_data: List[np.ndarray],\n    error_log_file: str,\n    include_dc_res: bool,\n    pf_fast: bool,\n    dcpf_fast: bool,\n    jl: Any,\n) -&gt; List[np.ndarray]:\n    \"\"\"Processes a load scenario in PF mode\n\n    In PF mode, OPF is run first to get generator setpoints, then topology\n    perturbations are applied. This can lead to constraint violations (overloads,\n    voltage violations) since the setpoints are not re-optimized for the new topology.\n\n    Args:\n        net: The power network.\n        scenarios: Array of load scenarios with shape (n_loads, n_scenarios, 2).\n        scenario_index: Index of the current scenario to process.\n        topology_generator: Generator for topology perturbations (line/transformer outages).\n        generation_generator: Generator for generation cost perturbations.\n        admittance_generator: Generator for line admittance perturbations.\n        local_processed_data: List to accumulate processed data tuples.\n        error_log_file: Path to error log file for recording failures.\n        include_dc_res: Whether to include DC power flow results in output.\n        pf_fast: Whether to use fast AC PF solver.\n        dcpf_fast: Whether to use fast DC PF solver.\n        jl: Julia interface object for running power flow calculations.\n\n    Returns:\n        Updated list of processed data (bus, gen, branch, Y_bus arrays)\n\n    Note:\n        Random seed is controlled by the calling context (process_scenario_chunk).\n    \"\"\"\n    net = copy.deepcopy(net)\n\n    # apply the load scenario to the network\n    net.Pd = scenarios[:, scenario_index, 0]\n    net.Qd = scenarios[:, scenario_index, 1]\n\n    # Apply generation perturbations before OPF.\n    perturbations = generation_generator.generate((x for x in [net]))\n\n    # Apply admittance perturbations\n    perturbations = admittance_generator.generate(perturbations)\n\n    net = next(perturbations)\n\n    # first run OPF to get the gen set points\n    try:\n        res = run_opf(net, jl)\n    except Exception as e:\n        with open(error_log_file, \"a\") as f:\n            f.write(\n                f\"Caught an exception at scenario {scenario_index} in run_opf function: {e}\\n\",\n            )\n        return local_processed_data\n\n    net_pf = copy.deepcopy(net)\n    net_pf = pf_preprocessing(net_pf, res)\n\n    # Generate perturbed topologies\n    perturbations = topology_generator.generate(net_pf)\n\n    # to get PF points that can violate some OPF inequality constraints (to train PF solvers that can handle points outside of normal operating limits), we apply the topology perturbation after OPF.\n    # The setpoints are then no longer adapted to the new topology, and might lead to e.g. abranch overload or a voltage magnitude violation once we drop an element.\n    for perturbation in perturbations:\n        res_dcpf = None\n        if include_dc_res:\n            try:\n                res_dcpf = run_dcpf(perturbation, jl, fast=dcpf_fast)\n\n            except Exception as e:\n                with open(error_log_file, \"a\") as f:\n                    f.write(\n                        f\"Caught an exception at scenario {scenario_index} when solving dcpf function: {e}\\n\",\n                    )\n\n        try:\n            res = run_pf(perturbation, jl, fast=pf_fast)\n        except Exception as e:\n            with open(error_log_file, \"a\") as f:\n                f.write(\n                    f\"Caught an exception at scenario {scenario_index} when solving in run_pf function: {e}\\n\",\n                )\n            continue\n\n        # Append processed power flow data\n        pf_data = pf_post_processing(\n            scenario_index,\n            perturbation,\n            res,\n            res_dcpf,\n            include_dc_res,\n        )\n        local_processed_data.append(\n            (\n                pf_data[\"bus\"],\n                pf_data[\"gen\"],\n                pf_data[\"branch\"],\n                pf_data[\"Y_bus\"],\n                pf_data[\"runtime\"],\n            ),\n        )\n    return local_processed_data\n</code></pre>"},{"location":"components/process_network/#process_scenario_chunk","title":"<code>process_scenario_chunk</code>","text":"<p>Process a chunk of scenarios for distributed processing.</p> <p>This function processes multiple scenarios in a single worker process, accumulating results before returning them to the main process.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Processing mode (\"opf\" or \"pf\").</p> required <code>start_idx</code> <code>int</code> <p>Starting scenario index (inclusive).</p> required <code>end_idx</code> <code>int</code> <p>Ending scenario index (exclusive).</p> required <code>scenarios</code> <code>ndarray</code> <p>Array of load scenarios with shape (n_loads, n_scenarios, 2).</p> required <code>net</code> <code>Network</code> <p>The power network.</p> required <code>progress_queue</code> <code>Queue</code> <p>Queue for reporting progress to main process.</p> required <code>topology_generator</code> <code>TopologyGenerator</code> <p>Generator for topology perturbations.</p> required <code>generation_generator</code> <code>GenerationGenerator</code> <p>Generator for generation cost perturbations.</p> required <code>admittance_generator</code> <code>AdmittanceGenerator</code> <p>Generator for line admittance perturbations.</p> required <code>error_log_path</code> <code>str</code> <p>Path to error log file for recording failures.</p> required <code>include_dc_res</code> <code>bool</code> <p>Whether to include DC power flow results in output.</p> required <code>pf_fast</code> <code>bool</code> <p>Whether to use fast AC PF solver.</p> required <code>dcpf_fast</code> <code>bool</code> <p>Whether to use fast DC PF solver.</p> required <code>solver_log_dir</code> <code>str</code> <p>Directory for solver logs.</p> required <code>max_iter</code> <code>int</code> <p>Maximum iterations for the solver.</p> required <code>seed</code> <code>int</code> <p>Global random seed for reproducibility.</p> required <p>Returns:</p> Type Description <code>Tuple[Union[None, Exception], Union[None, str], Optional[List[ndarray]]]</code> <p>Tuple containing: - Exception object (None if successful) - Traceback string (None if successful) - List of processed data tuples (bus, gen, branch, Y_bus arrays)</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def process_scenario_chunk(\n    mode: str,\n    start_idx: int,\n    end_idx: int,\n    scenarios: np.ndarray,\n    net: Network,\n    progress_queue: Queue,\n    topology_generator: TopologyGenerator,\n    generation_generator: GenerationGenerator,\n    admittance_generator: AdmittanceGenerator,\n    error_log_path: str,\n    include_dc_res: bool,\n    pf_fast: bool,\n    dcpf_fast: bool,\n    solver_log_dir: str,\n    max_iter: int,\n    seed: int,\n) -&gt; Tuple[\n    Union[None, Exception],\n    Union[None, str],\n    Optional[List[np.ndarray]],\n]:\n    \"\"\"Process a chunk of scenarios for distributed processing.\n\n    This function processes multiple scenarios in a single worker process,\n    accumulating results before returning them to the main process.\n\n    Args:\n        mode: Processing mode (\"opf\" or \"pf\").\n        start_idx: Starting scenario index (inclusive).\n        end_idx: Ending scenario index (exclusive).\n        scenarios: Array of load scenarios with shape (n_loads, n_scenarios, 2).\n        net: The power network.\n        progress_queue: Queue for reporting progress to main process.\n        topology_generator: Generator for topology perturbations.\n        generation_generator: Generator for generation cost perturbations.\n        admittance_generator: Generator for line admittance perturbations.\n        error_log_path: Path to error log file for recording failures.\n        include_dc_res: Whether to include DC power flow results in output.\n        pf_fast: Whether to use fast AC PF solver.\n        dcpf_fast: Whether to use fast DC PF solver.\n        solver_log_dir: Directory for solver logs.\n        max_iter: Maximum iterations for the solver.\n        seed: Global random seed for reproducibility.\n\n    Returns:\n        Tuple containing:\n            - Exception object (None if successful)\n            - Traceback string (None if successful)\n            - List of processed data tuples (bus, gen, branch, Y_bus arrays)\n    \"\"\"\n\n    try:\n        jl = init_julia(max_iter, solver_log_dir)\n        local_processed_data = []\n\n        # Use custom_seed to set seed based on start_idx for this chunk\n        # This ensures each chunk gets a unique but deterministic seed\n        # we multiply by 20_000 to ensure there is no collision with other runs where the seed would be close to each other\n        # example (assuming we have chunks of length 1, hence an increment of 1 between start indices)\n        # Run A: base seed = 42 \u2192 scenario seeds = 42, 43, 44, \u2026, 10041 (for 10,000 scenarios)\n        # Run B: base seed = 120 \u2192 scenario seeds = 120, 121, 122, \u2026, 10119\n        # These sets overlap on seeds 120..10041 (so 9,922 overlapping seeds).\n        # we also add 1 in case the seed is 0, to not have collision witht he seed used for the load perturbations\n        with custom_seed(seed * 20_000 + start_idx + 1):\n            for scenario_index in range(start_idx, end_idx):\n                if mode == \"opf\":\n                    local_processed_data = process_scenario_opf_mode(\n                        net,\n                        scenarios,\n                        scenario_index,\n                        topology_generator,\n                        generation_generator,\n                        admittance_generator,\n                        local_processed_data,\n                        error_log_path,\n                        include_dc_res,\n                        jl,\n                    )\n                elif mode == \"pf\":\n                    local_processed_data = process_scenario_pf_mode(\n                        net,\n                        scenarios,\n                        scenario_index,\n                        topology_generator,\n                        generation_generator,\n                        admittance_generator,\n                        local_processed_data,\n                        error_log_path,\n                        include_dc_res,\n                        pf_fast,\n                        dcpf_fast,\n                        jl,\n                    )\n\n                progress_queue.put(1)  # update queue\n\n        return (\n            None,\n            None,\n            local_processed_data,\n        )\n    except Exception as e:\n        with open(error_log_path, \"a\") as f:\n            f.write(f\"Caught an exception in process_scenario_chunk function: {e}\\n\")\n            f.write(traceback.format_exc())\n            f.write(\"\\n\")\n        for _ in range(end_idx - start_idx):\n            progress_queue.put(1)\n        return e, traceback.format_exc(), None\n</code></pre>"},{"location":"components/save/","title":"Save","text":"<p>This module provides functions for saving power flow data to CSV files.</p>"},{"location":"components/save/#save_node_edge_data","title":"<code>save_node_edge_data</code>","text":"<p>Save processed power system data to partitioned parquet files using parallel processing.</p> <p>This function saves bus, generator, branch, and Y-bus data to separate partitioned parquet directories using parallel processing for improved performance. Data is partitioned by scenario with 1000 scenarios per partition.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>Network object containing system topology information.</p> required <code>node_path</code> <code>str</code> <p>Path for saving bus/node data partitioned parquet directory.</p> required <code>branch_path</code> <code>str</code> <p>Path for saving branch data partitioned parquet directory.</p> required <code>gen_path</code> <code>str</code> <p>Path for saving generator data partitioned parquet directory.</p> required <code>y_bus_path</code> <code>str</code> <p>Path for saving Y-bus data partitioned parquet directory.</p> required <code>runtime_path</code> <code>str</code> <p>Path for saving runtime data partitioned parquet directory.</p> required <code>processed_data</code> <code>List[Tuple[ndarray, ndarray, ndarray, ndarray, ndarray]]</code> <p>List of tuples containing processed data arrays for each scenario.</p> required <code>include_dc_res</code> <code>bool</code> <p>Whether DC power flow data is included in the output.</p> <code>False</code> Source code in <code>gridfm_datakit/save.py</code> <pre><code>def save_node_edge_data(\n    net: Network,\n    node_path: str,\n    branch_path: str,\n    gen_path: str,\n    y_bus_path: str,\n    runtime_path: str,\n    processed_data: List[\n        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n    ],\n    include_dc_res: bool = False,\n) -&gt; None:\n    \"\"\"Save processed power system data to partitioned parquet files using parallel processing.\n\n    This function saves bus, generator, branch, and Y-bus data to separate partitioned parquet directories\n    using parallel processing for improved performance. Data is partitioned by scenario with 1000 scenarios per partition.\n\n    Args:\n        net: Network object containing system topology information.\n        node_path: Path for saving bus/node data partitioned parquet directory.\n        branch_path: Path for saving branch data partitioned parquet directory.\n        gen_path: Path for saving generator data partitioned parquet directory.\n        y_bus_path: Path for saving Y-bus data partitioned parquet directory.\n        runtime_path: Path for saving runtime data partitioned parquet directory.\n        processed_data: List of tuples containing processed data arrays for each scenario.\n        include_dc_res: Whether DC power flow data is included in the output.\n    \"\"\"\n    n_buses = net.buses.shape[0]\n\n    # Determine last scenario index from n_scenarios metadata file\n    last_scenario = -1\n    base_path = os.path.dirname(node_path)\n    n_scenarios_file = os.path.join(base_path, \"n_scenarios.txt\")\n    if os.path.exists(n_scenarios_file):\n        with open(n_scenarios_file, \"r\") as f:\n            last_scenario = int(f.read().strip()) - 1\n\n    # Define arguments per data type\n    tasks = [\n        (\"bus\", processed_data, node_path, last_scenario, n_buses, include_dc_res),\n        (\"gen\", processed_data, gen_path, last_scenario, n_buses, include_dc_res),\n        (\"branch\", processed_data, branch_path, last_scenario, n_buses, include_dc_res),\n        (\"y_bus\", processed_data, y_bus_path, last_scenario, n_buses, include_dc_res),\n        (\n            \"runtime\",\n            processed_data,\n            runtime_path,\n            last_scenario,\n            n_buses,\n            include_dc_res,\n        ),\n    ]\n\n    with ThreadPoolExecutor(max_workers=4) as pool:\n        futures = [pool.submit(_process_and_save, task) for task in tasks]\n        for f in futures:\n            f.result()  # wait for each task to finish\n\n    # Write n_scenarios metadata file\n    total_scenarios = last_scenario + 1 + len(processed_data)\n    with open(n_scenarios_file, \"w\") as f:\n        f.write(str(total_scenarios))\n</code></pre>"},{"location":"components/solvers/","title":"Solvers","text":"<p>This module provides functions for running power flow calculations.</p>"},{"location":"components/solvers/#run_opf","title":"<code>run_opf</code>","text":"<p>Run Optimal Power Flow (OPF) calculation using Julia interface.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>A Network object containing the power system model.</p> required <code>jl</code> <code>Any</code> <p>Julia interface object for running OPF.</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>OPF result containing termination status and solution data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If OPF fails to converge or encounters an error.</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_opf(net: Network, jl: Any) -&gt; Dict[str, Any]:\n    \"\"\"Run Optimal Power Flow (OPF) calculation using Julia interface.\n\n    Args:\n        net: A Network object containing the power system model.\n        jl: Julia interface object for running OPF.\n\n    Returns:\n        OPF result containing termination status and solution data.\n\n    Raises:\n        RuntimeError: If OPF fails to converge or encounters an error.\n    \"\"\"\n    # Create a temporary file for the MATPOWER case\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".m\", delete=False) as temp_file:\n        temp_filename = temp_file.name\n\n    try:\n        # Save network to temporary file\n        net.to_mpc(temp_filename)\n\n        result = jl.run_opf(temp_filename)\n\n        if str(result[\"termination_status\"]) != \"LOCALLY_SOLVED\":\n            raise RuntimeError(f\"OPF did not converge: {result['termination_status']}\")\n\n        return result\n\n    except Exception as e:\n        raise RuntimeError(f\"Error running OPF: {e}\")\n    finally:\n        # Clean up temporary file\n        if os.path.exists(temp_filename):\n            os.unlink(temp_filename)\n</code></pre>"},{"location":"components/solvers/#run_pf","title":"<code>run_pf</code>","text":"<p>Run Power Flow (PF) calculation using Julia interface.</p> <p>This function runs the power flow calculation using the Julia interface and returns the result with termination status.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>A network object containing the power system model.</p> required <code>jl</code> <code>Any</code> <p>Julia interface object for running power flow.</p> required <code>fast</code> <code>Union[bool, None]</code> <p>If True, use the direct (non-optimizer) computation. If None, defaults to False (uses optimizer-based solver).</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Power flow result containing termination status and solution data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If power flow fails to converge or encounters an error.</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_pf(net: Network, jl: Any, fast: Union[bool, None] = None) -&gt; Dict[str, Any]:\n    \"\"\"Run Power Flow (PF) calculation using Julia interface.\n\n    This function runs the power flow calculation using the Julia interface\n    and returns the result with termination status.\n\n    Args:\n        net: A network object containing the power system model.\n        jl: Julia interface object for running power flow.\n        fast: If True, use the direct (non-optimizer) computation. If None, defaults to False (uses optimizer-based solver).\n\n    Returns:\n        Power flow result containing termination status and solution data.\n\n    Raises:\n        RuntimeError: If power flow fails to converge or encounters an error.\n    \"\"\"\n\n    # Create a temporary file for the MATPOWER case\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".m\", delete=False) as temp_file:\n        temp_filename = temp_file.name\n\n    try:\n        # Save network to temporary file\n        net.to_mpc(temp_filename)\n\n        # Run PF\n        result = jl.run_pf_fast(temp_filename) if fast else jl.run_pf(temp_filename)\n        if (\n            fast\n            and str(result[\"termination_status\"]) != \"True\"\n            or (not fast and str(result[\"termination_status\"]) != \"LOCALLY_SOLVED\")\n        ):\n            raise RuntimeError(\n                f\"PF did not converge: {result['termination_status']}, fast={fast}\",\n            )\n\n        return result\n\n    except Exception as e:\n        raise RuntimeError(f\"Error running PF: {e}\")\n    finally:\n        # Clean up temporary file\n        if os.path.exists(temp_filename):\n            os.unlink(temp_filename)\n</code></pre>"},{"location":"components/solvers/#run_dcpf","title":"<code>run_dcpf</code>","text":"<p>Run DC Power Flow (DCPF) calculation using Julia interface.</p> <p>This function runs the DC power flow calculation using the Julia interface and returns the result with termination status.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>A network object containing the power system model.</p> required <code>jl</code> <code>Any</code> <p>Julia interface object for running DC power flow.</p> required <code>fast</code> <code>Union[bool, None]</code> <p>If True, use the direct (non-optimizer) computation. If None, defaults to False (uses optimizer-based solver).</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>DC power flow result containing termination status and solution data.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If DC power flow fails to converge or encounters an error.</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_dcpf(net: Network, jl: Any, fast: Union[bool, None] = None) -&gt; Dict[str, Any]:\n    \"\"\"Run DC Power Flow (DCPF) calculation using Julia interface.\n\n    This function runs the DC power flow calculation using the Julia interface\n    and returns the result with termination status.\n\n    Args:\n        net: A network object containing the power system model.\n        jl: Julia interface object for running DC power flow.\n        fast: If True, use the direct (non-optimizer) computation. If None, defaults to False (uses optimizer-based solver).\n\n    Returns:\n        DC power flow result containing termination status and solution data.\n\n    Raises:\n        RuntimeError: If DC power flow fails to converge or encounters an error.\n    \"\"\"\n\n    # Create a temporary file for the MATPOWER case\n    with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".m\", delete=False) as temp_file:\n        temp_filename = temp_file.name\n\n    try:\n        # Save network to temporary file\n        net.to_mpc(temp_filename)\n\n        # Run DCPF (fast or standard)\n        result = jl.run_dcpf_fast(temp_filename) if fast else jl.run_dcpf(temp_filename)\n\n        if (\n            fast\n            and str(result[\"termination_status\"]) != \"True\"\n            or (not fast and str(result[\"termination_status\"]) != \"LOCALLY_SOLVED\")\n        ):\n            raise RuntimeError(\n                f\"DC PF did not converge: {result['termination_status']}, fast={fast}\",\n            )\n\n        return result\n\n    except Exception as e:\n        raise RuntimeError(f\"Error running DC PF: {e}\")\n    finally:\n        # Clean up temporary file\n        if os.path.exists(temp_filename):\n            os.unlink(temp_filename)\n</code></pre>"},{"location":"components/stats/","title":"Stats","text":"<p>This module provides functions for computing statistics and generating visualizations from generated power flow data.</p>"},{"location":"components/stats/#functions","title":"Functions","text":""},{"location":"components/stats/#compute_stats_from_data","title":"<code>compute_stats_from_data</code>","text":"<p>Compute statistics from parquet data files (vectorized).</p> <p>Computes aggregated statistics from generated power flow data. Processes all scenarios in the parquet files and returns per-scenario metrics as well as global statistics.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Directory containing bus_data.parquet, branch_data.parquet, gen_data.parquet, and optionally runtime_data.parquet</p> required <code>sn_mva</code> <code>float</code> <p>Base MVA used to scale power quantities</p> required <code>n_partitions</code> <code>int</code> <p>Number of partitions to compute stats for (0 for all partitions)</p> <code>0</code> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dictionary with the following keys and corresponding numpy arrays:</p> <code>Dict[str, ndarray]</code> <ul> <li>scenario_ids: Array of scenario IDs</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>n_generators: Array of active generator counts per scenario (int array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>n_branches: Array of active branch counts per scenario (int array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>n_overloads: Array of overloaded branch counts per scenario (loading &gt; 1.01, int array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>max_loading: Array of maximum branch loading per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>branch_loadings: Vector of all branch loading values across all scenarios (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>p_balance_error_ac_max: Array of maximum active power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>p_balance_error_ac_mean: Array of mean active power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>q_balance_error_ac_max: Array of maximum reactive power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>q_balance_error_ac_mean: Array of mean reactive power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>runtime_data_ac_ms: (if runtime data available) Array of AC solver runtime per scenario in milliseconds (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>p_balance_error_dc_max: (if DC data available) Array of maximum DC active power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>p_balance_error_dc_mean: (if DC data available) Array of mean DC active power balance error per scenario (float array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>bus_idx_max_p_balance_error_dc_per_scenario: (if DC data available) Array of bus index with max DC PBE per scenario (int array)</li> </ul> <code>Dict[str, ndarray]</code> <ul> <li>runtime_data_dc_ms: (if DC and runtime data available) Array of DC solver runtime per scenario in milliseconds (float array)</li> </ul> <code>Dict[str, ndarray]</code> <p>Branch loading is computed as max(||S_from||/rate_a, ||S_to||/rate_a) where ||S|| = sqrt(P\u00b2 + Q\u00b2).</p> <code>Dict[str, ndarray]</code> <p>Power balance errors are computed as the mean absolute difference between net injections</p> <code>Dict[str, ndarray]</code> <p>(including shunt contributions) and aggregated branch flows at each bus.</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def compute_stats_from_data(\n    data_dir: str,\n    sn_mva: float,\n    n_partitions: int = 0,\n) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Compute statistics from parquet data files (vectorized).\n\n    Computes aggregated statistics from generated power flow data. Processes all scenarios\n    in the parquet files and returns per-scenario metrics as well as global statistics.\n\n    Args:\n        data_dir: Directory containing bus_data.parquet, branch_data.parquet, gen_data.parquet, and optionally runtime_data.parquet\n        sn_mva: Base MVA used to scale power quantities\n        n_partitions: Number of partitions to compute stats for (0 for all partitions)\n\n    Returns:\n        Dictionary with the following keys and corresponding numpy arrays:\n        - **scenario_ids**: Array of scenario IDs\n        - **n_generators**: Array of active generator counts per scenario (int array)\n        - **n_branches**: Array of active branch counts per scenario (int array)\n        - **n_overloads**: Array of overloaded branch counts per scenario (loading &gt; 1.01, int array)\n        - **max_loading**: Array of maximum branch loading per scenario (float array)\n        - **branch_loadings**: Vector of all branch loading values across all scenarios (float array)\n        - **p_balance_error_ac_max**: Array of maximum active power balance error per scenario (float array)\n        - **p_balance_error_ac_mean**: Array of mean active power balance error per scenario (float array)\n        - **q_balance_error_ac_max**: Array of maximum reactive power balance error per scenario (float array)\n        - **q_balance_error_ac_mean**: Array of mean reactive power balance error per scenario (float array)\n        - **runtime_data_ac_ms**: (if runtime data available) Array of AC solver runtime per scenario in milliseconds (float array)\n        - **p_balance_error_dc_max**: (if DC data available) Array of maximum DC active power balance error per scenario (float array)\n        - **p_balance_error_dc_mean**: (if DC data available) Array of mean DC active power balance error per scenario (float array)\n        - **bus_idx_max_p_balance_error_dc_per_scenario**: (if DC data available) Array of bus index with max DC PBE per scenario (int array)\n        - **runtime_data_dc_ms**: (if DC and runtime data available) Array of DC solver runtime per scenario in milliseconds (float array)\n\n        Branch loading is computed as max(||S_from||/rate_a, ||S_to||/rate_a) where ||S|| = sqrt(P\u00b2 + Q\u00b2).\n        Power balance errors are computed as the mean absolute difference between net injections\n        (including shunt contributions) and aggregated branch flows at each bus.\n    \"\"\"\n    # --- Load from partitioned parquet ---\n    # Get total number of scenarios efficiently\n    total_scenarios = get_num_scenarios(data_dir)\n\n    total_partitions = (\n        total_scenarios + n_scenario_per_partition - 1\n    ) // n_scenario_per_partition\n\n    if n_partitions &gt; 0:\n        sampled_partitions = sorted(\n            np.random.choice(\n                total_partitions,\n                size=min(n_partitions, total_partitions),\n                replace=False,\n            ),\n        )\n        print(\n            f\"Computing stats for {len(sampled_partitions)} partitions out of {total_partitions}\",\n        )\n    else:\n        sampled_partitions = list(range(total_partitions))\n\n    # Read filtered data from partitioned parquet using partition filter\n    bus_file = os.path.join(data_dir, \"bus_data.parquet\")\n    branch_file = os.path.join(data_dir, \"branch_data.parquet\")\n    gen_file = os.path.join(data_dir, \"gen_data.parquet\")\n    runtime_file = os.path.join(data_dir, \"runtime_data.parquet\")\n\n    bus_data = read_partitions(bus_file, sampled_partitions)\n    branch_data = read_partitions(branch_file, sampled_partitions)\n    gen_data = read_partitions(gen_file, sampled_partitions)\n\n    # Runtime data is optional\n    has_runtime = os.path.exists(runtime_file)\n    if has_runtime:\n        runtime_data = read_partitions(runtime_file, sampled_partitions)\n    else:\n        print(\"Runtime data not found, skipping runtime statistics\")\n\n    dc = True if \"p_mw_dc\" in gen_data.columns else False\n    # The canonical scenario ordering (to match the original function's behavior)\n    scenarios = bus_data[\"scenario\"].unique()\n\n    # --- 1) Counts: generators and branches (active by status only) ---\n    n_generators_s = (\n        gen_data.loc[gen_data[\"in_service\"] == 1]\n        .groupby(\"scenario\", sort=False)\n        .size()\n        .reindex(scenarios, fill_value=0)\n    )\n\n    n_branches_s = (\n        branch_data.loc[branch_data[\"br_status\"] == 1]\n        .groupby(\"scenario\", sort=False)\n        .size()\n        .reindex(scenarios, fill_value=0)\n    )\n\n    # --- 2) Branch loadings &amp; overloads (only active and with finite rating) ---\n    active_br = branch_data[\n        (branch_data[\"br_status\"] == 1) &amp; (branch_data[\"rate_a\"] &gt; 0)\n    ]\n\n    # loading_f = ||S_f||/rate_a, loading_t = ||S_t||/rate_a; loading = max(loading_f, loading_t)\n    # Avoid division-by-zero because we've already filtered rate_a &gt; 0\n    s_f = np.sqrt(active_br[\"pf\"].to_numpy() ** 2 + active_br[\"qf\"].to_numpy() ** 2)\n    s_t = np.sqrt(active_br[\"pt\"].to_numpy() ** 2 + active_br[\"qt\"].to_numpy() ** 2)\n    rate = active_br[\"rate_a\"].to_numpy()\n    loading_f = s_f / rate\n    loading_t = s_t / rate\n    loading = np.maximum(loading_f, loading_t)\n\n    # Attach loading to frame for groupby aggregations\n    active_br = active_br.assign(_loading=loading)\n\n    n_overloads_s = (\n        (active_br[\"_loading\"] &gt; 1.01)\n        .groupby(active_br[\"scenario\"], sort=False)\n        .sum()\n        .reindex(scenarios, fill_value=0)\n    )\n\n    max_loading_s = (\n        active_br.groupby(\"scenario\", sort=False)[\"_loading\"]\n        .max()\n        .reindex(scenarios, fill_value=0.0)\n    )\n\n    # Global vector of per-branch loadings (matches prior behavior of extending a list)\n    branch_loadings_vec = active_br[\"_loading\"].to_numpy(copy=False)\n\n    # --- 3) Power balance errors ---\n    balance_ac = compute_bus_balance(\n        bus_data,\n        branch_data,\n        branch_data[[\"pf\", \"qf\", \"pt\", \"qt\"]],\n        False,\n        sn_mva=sn_mva,\n    )\n    group_by_scenario = balance_ac.groupby(\"scenario\")\n    p_balance_ac_max = group_by_scenario[\"P_mis_ac\"].max().reindex(scenarios)\n    p_balance_ac_mean = group_by_scenario[\"P_mis_ac\"].mean().reindex(scenarios)\n    q_balance_ac_max = group_by_scenario[\"Q_mis_ac\"].max().reindex(scenarios)\n    q_balance_ac_mean = group_by_scenario[\"Q_mis_ac\"].mean().reindex(scenarios)\n    if dc:\n        pf_dc, _, pt_dc, _ = compute_branch_powers_vectorized(\n            branch_data,\n            bus_data,\n            True,\n            sn_mva=sn_mva,\n        )\n        balance_dc = compute_bus_balance(\n            bus_data,\n            branch_data,\n            pd.DataFrame({\"pf_dc\": pf_dc, \"pt_dc\": pt_dc}, index=branch_data.index),\n            True,\n            sn_mva=sn_mva,\n        )\n        group_by_scenario = balance_dc.groupby(\"scenario\")\n        p_balance_dc_max = group_by_scenario[\"P_mis_dc\"].max().reindex(scenarios)\n        p_balance_dc_mean = group_by_scenario[\"P_mis_dc\"].mean().reindex(scenarios)\n        # bus index of the bus with the largest DC P-mismatch per scenario\n        idxmax = group_by_scenario[\"P_mis_dc\"].idxmax().dropna()\n        idx_bus_max_p_balance_error_dc_per_scenario = (\n            balance_dc.loc[idxmax.dropna(), [\"scenario\", \"bus\"]]\n            .set_index(\"scenario\")[\"bus\"]\n            .reindex(scenarios)\n        )\n\n    # ---4) Runtime data (optional) ---\n    if has_runtime:\n        runtime_data_ac = (\n            runtime_data.set_index(\"scenario\")[\"ac\"].reindex(scenarios) * 1000.0\n        )\n        if dc:\n            runtime_data_dc = (\n                runtime_data.set_index(\"scenario\")[\"dc\"].reindex(scenarios) * 1000.0\n            )\n\n    # --- Pack results (preserve original array shapes/order) ---\n    result = {\n        \"scenario_ids\": scenarios,\n        \"n_generators\": n_generators_s.to_numpy(dtype=int),\n        \"n_branches\": n_branches_s.to_numpy(dtype=int),\n        \"n_overloads\": n_overloads_s.to_numpy(dtype=int),\n        \"max_loading\": max_loading_s.to_numpy(dtype=float),\n        \"branch_loadings\": branch_loadings_vec.astype(float, copy=False),\n        \"p_balance_error_ac_max\": p_balance_ac_max.to_numpy(dtype=float),\n        \"p_balance_error_ac_mean\": p_balance_ac_mean.to_numpy(dtype=float),\n        \"q_balance_error_ac_max\": q_balance_ac_max.to_numpy(dtype=float),\n        \"q_balance_error_ac_mean\": q_balance_ac_mean.to_numpy(dtype=float),\n    }\n    if has_runtime:\n        result[\"runtime_data_ac_ms\"] = runtime_data_ac.to_numpy(dtype=float)\n\n    if dc:\n        result[\"p_balance_error_dc_max\"] = p_balance_dc_max.to_numpy(dtype=float)\n        result[\"p_balance_error_dc_mean\"] = p_balance_dc_mean.to_numpy(dtype=float)\n        result[\"bus_idx_max_p_balance_error_dc_per_scenario\"] = (\n            idx_bus_max_p_balance_error_dc_per_scenario.to_numpy(dtype=float)\n        )\n        if has_runtime:\n            result[\"runtime_data_dc_ms\"] = runtime_data_dc.to_numpy(dtype=float)\n\n    return result\n</code></pre>"},{"location":"components/stats/#plot_stats","title":"<code>plot_stats</code>","text":"<p>Generate and save statistics plots using matplotlib.</p> <p>Creates a multi-panel histogram plot showing distributions of key metrics across all scenarios. The plot is saved as <code>stats_plot.png</code> in the specified directory with 300 DPI resolution.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Directory containing data files (bus_data.parquet, branch_data.parquet, gen_data.parquet, and optionally runtime_data.parquet)       and where the plot will be saved</p> required <code>sn_mva</code> <code>float</code> <p>Base MVA used to scale power quantities</p> required <code>n_partitions</code> <code>int</code> <p>Number of partitions to compute stats for (0 for all partitions)</p> <code>0</code> <p>The generated plot contains histograms (with log scale on y-axis) for: - Number of generators per scenario - Number of branches per scenario - Number of overloads per scenario - Maximum loading per scenario - Branch loading (all branches across all scenarios) - Active power balance error (mean absolute error per scenario, normalized) - Reactive power balance error (mean absolute error per scenario, normalized) - (If runtime data available) Runtime (AC solver execution time in milliseconds) - (If DC data available) DC active power balance error, bus index with max DC PBE - (If DC and runtime data available) DC runtime</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def plot_stats(data_dir: str, sn_mva: float, n_partitions: int = 0) -&gt; None:\n    \"\"\"Generate and save statistics plots using matplotlib.\n\n    Creates a multi-panel histogram plot showing distributions of key metrics across all scenarios.\n    The plot is saved as `stats_plot.png` in the specified directory with 300 DPI resolution.\n\n    Args:\n        data_dir: Directory containing data files (bus_data.parquet, branch_data.parquet, gen_data.parquet, and optionally runtime_data.parquet)\n                  and where the plot will be saved\n        sn_mva: Base MVA used to scale power quantities\n        n_partitions: Number of partitions to compute stats for (0 for all partitions)\n\n    The generated plot contains histograms (with log scale on y-axis) for:\n    - Number of generators per scenario\n    - Number of branches per scenario\n    - Number of overloads per scenario\n    - Maximum loading per scenario\n    - Branch loading (all branches across all scenarios)\n    - Active power balance error (mean absolute error per scenario, normalized)\n    - Reactive power balance error (mean absolute error per scenario, normalized)\n    - (If runtime data available) Runtime (AC solver execution time in milliseconds)\n    - (If DC data available) DC active power balance error, bus index with max DC PBE\n    - (If DC and runtime data available) DC runtime\n    \"\"\"\n    stats = compute_stats_from_data(data_dir, sn_mva=sn_mva, n_partitions=n_partitions)\n    filename = os.path.join(data_dir, \"stats_plot.png\")\n\n    # Save per-scenario statistics to a parquet file with one row per scenario\n\n    per_scenario = {\n        \"scenario\": stats[\"scenario_ids\"],\n        \"n_generators\": stats[\"n_generators\"],\n        \"n_branches\": stats[\"n_branches\"],\n        \"n_overloads\": stats[\"n_overloads\"],\n        \"max_loading\": stats[\"max_loading\"],\n        \"p_balance_error_ac_max\": stats[\"p_balance_error_ac_max\"],\n        \"p_balance_error_ac_mean\": stats[\"p_balance_error_ac_mean\"],\n        \"q_balance_error_ac_max\": stats[\"q_balance_error_ac_max\"],\n        \"q_balance_error_ac_mean\": stats[\"q_balance_error_ac_mean\"],\n    }\n    if \"runtime_data_ac_ms\" in stats:\n        per_scenario[\"runtime_data_ac_ms\"] = stats[\"runtime_data_ac_ms\"]\n\n    mean_mean_p_balance_error_ac = np.nanmean(stats[\"p_balance_error_ac_mean\"])\n    mean_mean_q_balance_error_ac = np.nanmean(stats[\"q_balance_error_ac_mean\"])\n\n    if \"p_balance_error_dc_max\" in stats:\n        per_scenario[\"p_balance_error_dc_max\"] = stats[\"p_balance_error_dc_max\"]\n        per_scenario[\"p_balance_error_dc_mean\"] = stats[\"p_balance_error_dc_mean\"]\n        per_scenario[\"bus_idx_max_p_balance_error_dc_per_scenario\"] = stats[\n            \"bus_idx_max_p_balance_error_dc_per_scenario\"\n        ]\n        if \"runtime_data_dc_ms\" in stats:\n            per_scenario[\"runtime_data_dc_ms\"] = stats[\"runtime_data_dc_ms\"]\n        mean_mean_p_balance_error_dc = np.nanmean(stats[\"p_balance_error_dc_mean\"])\n\n    df_stats = pd.DataFrame(per_scenario)\n    # Add partition column for scenario-based partitioning (n_scenario_per_partition scenarios per partition)\n    df_stats[\"scenario_partition\"] = (\n        df_stats[\"scenario\"] // n_scenario_per_partition\n    ).astype(\"int64\")\n    df_stats.to_parquet(\n        os.path.join(data_dir, \"stats.parquet\"),\n        partition_cols=[\"scenario_partition\"],\n        engine=\"pyarrow\",\n        index=False,\n    )\n\n    # Titles and data pairs\n    plots = [\n        (\"Number of Generators\", stats[\"n_generators\"]),\n        (\"Number of Branches\", stats[\"n_branches\"]),\n        (\"Number of Overloads\", stats[\"n_overloads\"]),\n        (\"Max Loading\", stats[\"max_loading\"]),\n        (\"Branch Loading\", stats[\"branch_loadings\"]),\n        # (\"Max Active PBE (AC, normalized)\", stats[\"p_balance_error_ac_max\"]),\n        (\n            f\"Mean Active PBE (AC, normalized). Mean={np.format_float_scientific(mean_mean_p_balance_error_ac, precision=2)}\",\n            stats[\"p_balance_error_ac_mean\"],\n        ),\n        # (\"Max Reactive PBE (AC, normalized)\", stats[\"q_balance_error_ac_max\"]),\n        (\n            f\"Mean Reactive PBE (AC, normalized). Mean={np.format_float_scientific(mean_mean_q_balance_error_ac, precision=2)}\",\n            stats[\"q_balance_error_ac_mean\"],\n        ),\n    ]\n\n    # Add runtime plot if runtime data exists\n    if \"runtime_data_ac_ms\" in stats:\n        plots.append(\n            (\n                \"Runtime (AC, ms). Mean={:.2f}\".format(\n                    stats[\"runtime_data_ac_ms\"].mean(),\n                ),\n                stats[\"runtime_data_ac_ms\"],\n            ),\n        )\n\n    # Optionally add DC power balance if available\n    if \"p_balance_error_dc_max\" in stats:\n        plots.append(\n            (\n                \"Max Active PBE (DC in AC model, normalized)\",\n                stats[\"p_balance_error_dc_max\"],\n            ),\n        )\n        plots.append(\n            (\n                f\"Mean Active PBE (DC in AC model, normalized). Mean={mean_mean_p_balance_error_dc:.2f}\",\n                stats[\"p_balance_error_dc_mean\"],\n            ),\n        )\n        plots.append(\n            (\n                \"Bus Index with Max Active PBE (DC in AC model, normalized)\",\n                stats[\"bus_idx_max_p_balance_error_dc_per_scenario\"],\n            ),\n        )\n        if \"runtime_data_dc_ms\" in stats:\n            plots.append(\n                (\n                    \"Runtime (DC, ms). Mean={:.2f}\".format(\n                        np.nanmean(stats[\"runtime_data_dc_ms\"]),\n                    ),\n                    stats[\"runtime_data_dc_ms\"],\n                ),\n            )\n\n    # sort plots by title\n    plots.sort(key=lambda x: x[0])\n    # Define figure and subplots\n    n_plots = len(plots)\n    import math\n\n    fig, axes = plt.subplots(math.ceil(n_plots / 2), 2, figsize=(12, 14))\n    axes = axes.ravel()\n\n    # Plot histograms\n    for ax, (title, data) in zip(axes, plots):\n        print(title)\n        # For DC-related metrics, exclude NaNs from plot but show count in legend\n        if \"DC\" in title:\n            valid = data[~np.isnan(data)]\n            nan_count = int(np.isnan(data).sum())\n            ax.hist(\n                valid,\n                bins=100,\n                color=\"steelblue\",\n                edgecolor=\"black\",\n                alpha=0.7,\n                label=f\"valid={len(valid)}, nan={nan_count}\",\n            )\n            ax.legend()\n        else:\n            if data.size &gt; 0:\n                ax.hist(data, bins=100, color=\"steelblue\", edgecolor=\"black\", alpha=0.7)\n\n        ax.set_title(title, fontsize=12, pad=10)\n        ax.set_xlabel(title, fontsize=10)\n        ax.set_ylabel(\"Count\", fontsize=10)\n        ax.set_yscale(\"log\")\n        ax.grid(True, linestyle=\"--\", alpha=0.4)\n\n    # Remove any unused subplot (if any)\n    for i in range(len(plots), len(axes)):\n        fig.delaxes(axes[i])\n\n    fig.tight_layout()\n    fig.savefig(filename, dpi=300, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    print(f\"Statistics plots saved to {filename}\")\n</code></pre>"},{"location":"components/stats/#plot_feature_distributions","title":"<code>plot_feature_distributions</code>","text":"<p>Create and save violin plots showing the distribution of each feature across all buses.</p> <p>Generates violin plots for each feature column defined in <code>BUS_COLUMNS</code> (and <code>DC_BUS_COLUMNS</code> if DC columns are present in the data). Each plot shows the probability distribution of feature values across selected buses, with overlaid box plots showing quartiles.</p> <p>Parameters:</p> Name Type Description Default <code>node_file</code> <code>str</code> <p>Parquet file containing node data with a 'bus' column (typically bus_data.parquet).</p> required <code>output_dir</code> <code>str</code> <p>Directory where plots will be saved as <code>distribution_{feature_name}.png</code>.</p> required <code>sn_mva</code> <code>float</code> <p>Base MVA used to normalize power-related columns (Pd, Qd, Pg, Qg) by dividing by this value.</p> required <code>buses</code> <code>List[int]</code> <p>List of bus indices to plot. If None, randomly samples 30 buses (or all buses if fewer than 30).</p> <code>None</code> <code>n_partitions</code> <code>int</code> <p>Number of partitions to plot (0 for all partitions)</p> <code>0</code> <p>Each generated plot displays: - Violin plots showing the probability density of feature values per bus - Box plots overlaid on violins showing quartiles, median, and min/max - Power-related features (Pd, Qd, Pg, Qg) are normalized by dividing by <code>sn_mva</code> - Features are plotted for columns defined in <code>gridfm_datakit.utils.column_names.BUS_COLUMNS</code>   and optionally <code>DC_BUS_COLUMNS</code> if DC columns (e.g., Va_dc) are present in the data</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def plot_feature_distributions(\n    node_file: str,\n    output_dir: str,\n    sn_mva: float,\n    buses: List[int] = None,\n    n_partitions: int = 0,\n) -&gt; None:\n    \"\"\"Create and save violin plots showing the distribution of each feature across all buses.\n\n    Generates violin plots for each feature column defined in `BUS_COLUMNS` (and `DC_BUS_COLUMNS` if\n    DC columns are present in the data). Each plot shows the probability distribution of feature values across selected buses,\n    with overlaid box plots showing quartiles.\n\n    Args:\n        node_file: Parquet file containing node data with a 'bus' column (typically bus_data.parquet).\n        output_dir: Directory where plots will be saved as `distribution_{feature_name}.png`.\n        sn_mva: Base MVA used to normalize power-related columns (Pd, Qd, Pg, Qg) by dividing by this value.\n        buses: List of bus indices to plot. If None, randomly samples 30 buses (or all buses if fewer than 30).\n        n_partitions: Number of partitions to plot (0 for all partitions)\n\n    Each generated plot displays:\n    - Violin plots showing the probability density of feature values per bus\n    - Box plots overlaid on violins showing quartiles, median, and min/max\n    - Power-related features (Pd, Qd, Pg, Qg) are normalized by dividing by `sn_mva`\n    - Features are plotted for columns defined in `gridfm_datakit.utils.column_names.BUS_COLUMNS`\n      and optionally `DC_BUS_COLUMNS` if DC columns (e.g., Va_dc) are present in the data\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from gridfm_datakit.utils.column_names import DC_BUS_COLUMNS\n\n    # Get total number of scenarios and partitions\n    data_dir = os.path.dirname(node_file)\n    total_scenarios = get_num_scenarios(data_dir)\n    total_partitions = (\n        total_scenarios + n_scenario_per_partition - 1\n    ) // n_scenario_per_partition\n\n    if n_partitions &gt; 0:\n        sampled_partitions = sorted(\n            np.random.choice(\n                total_partitions,\n                size=min(n_partitions, total_partitions),\n                replace=False,\n            ),\n        )\n        print(\n            f\"Plotting for {len(sampled_partitions)} partitions out of {total_partitions}\",\n        )\n    else:\n        sampled_partitions = list(range(total_partitions))\n\n    # Read filtered data from partitioned parquet using partition filter\n    node_data = read_partitions(node_file, sampled_partitions)\n    os.makedirs(output_dir, exist_ok=True)\n\n    if not buses:\n        # sample 30 buses randomly\n        buses = np.random.choice(\n            node_data[\"bus\"].unique(),\n            size=min(30, len(node_data[\"bus\"].unique())),\n            replace=False,\n        )\n\n    node_data = node_data[node_data[\"bus\"].isin(buses)]\n\n    # normalize by sn_mva\n    for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n        node_data[col] = node_data[col] / sn_mva\n\n    # Group data by bus\n    bus_groups = node_data.groupby(\"bus\")\n    sorted_buses = sorted(bus_groups.groups.keys())\n\n    feature_cols = [\n        \"Pd\",\n        \"Qd\",\n        \"Pg\",\n        \"Qg\",\n        \"Vm\",\n        \"Va\",\n        \"PQ\",\n        \"PV\",\n        \"REF\",\n    ]\n    if \"Va_dc\" in node_data.columns:\n        feature_cols = feature_cols + DC_BUS_COLUMNS\n    else:\n        feature_cols = feature_cols\n\n    for feature_name in feature_cols:\n        fig, ax = plt.subplots(figsize=(15, 6))\n\n        bus_data = [\n            bus_groups.get_group(bus)[feature_name].dropna().values\n            for bus in sorted_buses\n        ]\n\n        parts = ax.violinplot(bus_data, showmeans=True)\n\n        for pc in parts[\"bodies\"]:\n            pc.set_facecolor(\"#D43F3A\")\n            pc.set_alpha(0.7)\n\n        ax.boxplot(\n            bus_data,\n            widths=0.15,\n            showfliers=False,\n            showcaps=True,\n            medianprops=dict(color=\"black\", linewidth=1.5),\n        )\n\n        ax.set_title(f\"{feature_name} Distribution Across Buses\")\n        ax.set_xlabel(\"Bus Index\")\n        ax.set_ylabel(feature_name)\n        ax.set_xticks(range(1, len(sorted_buses) + 1))\n        ax.set_xticklabels(\n            [f\"Bus {bus}\" for bus in sorted_buses],\n            rotation=45,\n            ha=\"right\",\n        )\n\n        ax.grid(True, alpha=0.3)\n        plt.tight_layout()\n\n        out_path = os.path.join(\n            output_dir,\n            f\"distribution_{feature_name}.png\",\n        )\n        plt.savefig(out_path)\n        plt.close()\n</code></pre>"},{"location":"components/topology/","title":"Topology Perturbations","text":"<p>This module provides classes for generating perturbed network topologies.</p>"},{"location":"components/topology/#topologygenerator","title":"<code>TopologyGenerator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for generating perturbed network topologies.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class TopologyGenerator(ABC):\n    \"\"\"Abstract base class for generating perturbed network topologies.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the topology generator.\"\"\"\n        pass\n\n    @abstractmethod\n    def generate(\n        self,\n        net: Network,\n    ) -&gt; Union[Generator[Network, None, None], List[Network]]:\n        \"\"\"Generate perturbed topologies.\n\n        Args:\n            net: The power network to perturb.\n\n        Yields:\n            A perturbed network topology.\n        \"\"\"\n        pass\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the topology generator.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the topology generator.\"\"\"\n    pass\n</code></pre> <code>generate(net)</code> <code>abstractmethod</code> \u00b6 <p>Generate perturbed topologies.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network to perturb.</p> required <p>Yields:</p> Type Description <code>Union[Generator[Network, None, None], List[Network]]</code> <p>A perturbed network topology.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>@abstractmethod\ndef generate(\n    self,\n    net: Network,\n) -&gt; Union[Generator[Network, None, None], List[Network]]:\n    \"\"\"Generate perturbed topologies.\n\n    Args:\n        net: The power network to perturb.\n\n    Yields:\n        A perturbed network topology.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"components/topology/#noperturbationgenerator","title":"<code>NoPerturbationGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generator that yields the original network without any perturbations.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class NoPerturbationGenerator(TopologyGenerator):\n    \"\"\"Generator that yields the original network without any perturbations.\"\"\"\n\n    def generate(\n        self,\n        net: Network,\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Yield the original network without any perturbations.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            The original power network.\n        \"\"\"\n        yield copy.deepcopy(net)\n</code></pre> <code>generate(net)</code> \u00b6 <p>Yield the original network without any perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>The original power network.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: Network,\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Yield the original network without any perturbations.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        The original power network.\n    \"\"\"\n    yield copy.deepcopy(net)\n</code></pre>"},{"location":"components/topology/#nminuskgenerator","title":"<code>NMinusKGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generate perturbed topologies for N-k contingency analysis.</p> <p>Only considers lines and transformers. Generates ALL possible topologies with at most k components set out of service (lines and transformers).</p> <p>Only topologies that are feasible (= no unsupplied buses) are yielded.</p> <p>Attributes:</p> Name Type Description <code>k</code> <p>Maximum number of components to drop.</p> <code>components_to_drop</code> <p>List of tuples containing component indices and types.</p> <code>component_combinations</code> <p>List of all possible combinations of components to drop.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class NMinusKGenerator(TopologyGenerator):\n    \"\"\"Generate perturbed topologies for N-k contingency analysis.\n\n    Only considers lines and transformers. Generates ALL possible topologies with at most k\n    components set out of service (lines and transformers).\n\n    Only topologies that are feasible (= no unsupplied buses) are yielded.\n\n    Attributes:\n        k: Maximum number of components to drop.\n        components_to_drop: List of tuples containing component indices and types.\n        component_combinations: List of all possible combinations of components to drop.\n    \"\"\"\n\n    def __init__(self, k: int, base_net: dict) -&gt; None:\n        \"\"\"Initialize the N-k generator.\n\n        Args:\n            k: Maximum number of components to drop.\n            base_net: The base power network.\n\n        Raises:\n            ValueError: If k is 0.\n            Warning: If k &gt; 1, as this may result in slow data generation.\n        \"\"\"\n        super().__init__()\n        if k &gt; 1:\n            warnings.warn(\"k&gt;1. This may result in slow data generation process.\")\n        if k == 0:\n            raise ValueError(\n                'k must be greater than 0. Use \"none\" as argument for the generator_type if you don\\'t want to generate any perturbation',\n            )\n        self.k = k\n\n        # Prepare the list of components to drop\n        self.components_to_drop = base_net.idx_branches_in_service\n\n        # Generate all combinations of at most k components\n        self.component_combinations = []\n        for r in range(self.k + 1):\n            self.component_combinations.extend(combinations(self.components_to_drop, r))\n\n        print(\n            f\"Number of possible topologies with at most {self.k} dropped components: {len(self.component_combinations)}\",\n        )\n\n    def generate(\n        self,\n        net: Network,\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Generate perturbed topologies by dropping components.\n        Does not change the original network.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            A perturbed network topology with at most k components removed.\n        \"\"\"\n        for selected_components in self.component_combinations:\n            perturbed_topology = copy.deepcopy(net)\n\n            perturbed_topology.deactivate_branches(selected_components)\n\n            # Check network feasibility and yield the topology\n            if perturbed_topology.check_single_connected_component():\n                yield perturbed_topology\n</code></pre> <code>__init__(k, base_net)</code> \u00b6 <p>Initialize the N-k generator.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Maximum number of components to drop.</p> required <code>base_net</code> <code>dict</code> <p>The base power network.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If k is 0.</p> <code>Warning</code> <p>If k &gt; 1, as this may result in slow data generation.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(self, k: int, base_net: dict) -&gt; None:\n    \"\"\"Initialize the N-k generator.\n\n    Args:\n        k: Maximum number of components to drop.\n        base_net: The base power network.\n\n    Raises:\n        ValueError: If k is 0.\n        Warning: If k &gt; 1, as this may result in slow data generation.\n    \"\"\"\n    super().__init__()\n    if k &gt; 1:\n        warnings.warn(\"k&gt;1. This may result in slow data generation process.\")\n    if k == 0:\n        raise ValueError(\n            'k must be greater than 0. Use \"none\" as argument for the generator_type if you don\\'t want to generate any perturbation',\n        )\n    self.k = k\n\n    # Prepare the list of components to drop\n    self.components_to_drop = base_net.idx_branches_in_service\n\n    # Generate all combinations of at most k components\n    self.component_combinations = []\n    for r in range(self.k + 1):\n        self.component_combinations.extend(combinations(self.components_to_drop, r))\n\n    print(\n        f\"Number of possible topologies with at most {self.k} dropped components: {len(self.component_combinations)}\",\n    )\n</code></pre> <code>generate(net)</code> \u00b6 <p>Generate perturbed topologies by dropping components. Does not change the original network.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>A perturbed network topology with at most k components removed.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: Network,\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Generate perturbed topologies by dropping components.\n    Does not change the original network.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        A perturbed network topology with at most k components removed.\n    \"\"\"\n    for selected_components in self.component_combinations:\n        perturbed_topology = copy.deepcopy(net)\n\n        perturbed_topology.deactivate_branches(selected_components)\n\n        # Check network feasibility and yield the topology\n        if perturbed_topology.check_single_connected_component():\n            yield perturbed_topology\n</code></pre>"},{"location":"components/topology/#randomcomponentdropgenerator","title":"<code>RandomComponentDropGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generate perturbed topologies by randomly setting components out of service.</p> <p>Generates perturbed topologies by randomly setting out of service at most k components among the selected element types. Only topologies that are feasible (= no unsupplied buses) are yielded.</p> <p>Attributes:</p> Name Type Description <code>n_topology_variants</code> <p>Number of topology variants to generate.</p> <code>k</code> <p>Maximum number of components to drop.</p> <code>components_to_drop</code> <p>List of tuples containing component indices and types.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class RandomComponentDropGenerator(TopologyGenerator):\n    \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n    Generates perturbed topologies by randomly setting out of service at most k components among the selected element types.\n    Only topologies that are feasible (= no unsupplied buses) are yielded.\n\n    Attributes:\n        n_topology_variants: Number of topology variants to generate.\n        k: Maximum number of components to drop.\n        components_to_drop: List of tuples containing component indices and types.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_topology_variants: int,\n        k: int,\n        base_net: Network,\n        elements: List[str] = [\"branch\", \"gen\"],\n    ) -&gt; None:\n        \"\"\"Initialize the random component drop generator.\n\n        Args:\n            n_topology_variants: Number of topology variants to generate.\n            k: Maximum number of components to drop.\n            base_net: The base power network.\n            elements: List of element types to consider for dropping.\n        \"\"\"\n        super().__init__()\n        self.n_topology_variants = n_topology_variants\n        self.k = k\n\n        # Create a list of all components that can be dropped\n        self.components_to_drop = []\n        if \"branch\" in elements:\n            self.components_to_drop.extend(\n                (idx, \"branch\") for idx in base_net.idx_branches_in_service\n            )\n        if \"gen\" in elements:\n            self.components_to_drop.extend(\n                (idx, \"gen\")\n                for idx in base_net.idx_gens_in_service\n                if base_net.gens[idx, GEN_BUS] != base_net.ref_bus_idx\n            )\n\n    def generate(\n        self,\n        net: Network,\n    ) -&gt; Generator[Network, None, None]:\n        \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            A perturbed network topology.\n        \"\"\"\n        n_generated_topologies = 0\n\n        # Stop after we generated n_topology_variants\n        while n_generated_topologies &lt; self.n_topology_variants:\n            perturbed_topology = copy.deepcopy(net)\n\n            # draw the number of components to drop from a uniform distribution\n            r = np.random.randint(\n                1,\n                self.k + 1,\n            )  # TODO: decide if we want to be able to set 0 components out of service\n\n            # Randomly select r&lt;=k components to drop\n            components = tuple(\n                np.random.choice(range(len(self.components_to_drop)), r, replace=False),\n            )\n\n            # Convert indices back to actual components\n            selected_components = tuple(\n                self.components_to_drop[idx] for idx in components\n            )\n\n            # Separate lines, transformers, generators, and static generators\n            branches_to_drop = [\n                idx for idx, element in selected_components if element == \"branch\"\n            ]\n            gens_to_drop = [\n                idx for idx, element in selected_components if element == \"gen\"\n            ]\n\n            # Drop selected lines and transformers, turn off generators and static generators\n            perturbed_topology.deactivate_branches(branches_to_drop)\n            perturbed_topology.deactivate_gens(gens_to_drop)\n\n            # Check network feasibility and yield the topology\n            if perturbed_topology.check_single_connected_component():\n                yield perturbed_topology\n                n_generated_topologies += 1\n</code></pre> <code>__init__(n_topology_variants, k, base_net, elements=['branch', 'gen'])</code> \u00b6 <p>Initialize the random component drop generator.</p> <p>Parameters:</p> Name Type Description Default <code>n_topology_variants</code> <code>int</code> <p>Number of topology variants to generate.</p> required <code>k</code> <code>int</code> <p>Maximum number of components to drop.</p> required <code>base_net</code> <code>Network</code> <p>The base power network.</p> required <code>elements</code> <code>List[str]</code> <p>List of element types to consider for dropping.</p> <code>['branch', 'gen']</code> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(\n    self,\n    n_topology_variants: int,\n    k: int,\n    base_net: Network,\n    elements: List[str] = [\"branch\", \"gen\"],\n) -&gt; None:\n    \"\"\"Initialize the random component drop generator.\n\n    Args:\n        n_topology_variants: Number of topology variants to generate.\n        k: Maximum number of components to drop.\n        base_net: The base power network.\n        elements: List of element types to consider for dropping.\n    \"\"\"\n    super().__init__()\n    self.n_topology_variants = n_topology_variants\n    self.k = k\n\n    # Create a list of all components that can be dropped\n    self.components_to_drop = []\n    if \"branch\" in elements:\n        self.components_to_drop.extend(\n            (idx, \"branch\") for idx in base_net.idx_branches_in_service\n        )\n    if \"gen\" in elements:\n        self.components_to_drop.extend(\n            (idx, \"gen\")\n            for idx in base_net.idx_gens_in_service\n            if base_net.gens[idx, GEN_BUS] != base_net.ref_bus_idx\n        )\n</code></pre> <code>generate(net)</code> \u00b6 <p>Generate perturbed topologies by randomly setting components out of service.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>Network</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>Network</code> <p>A perturbed network topology.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: Network,\n) -&gt; Generator[Network, None, None]:\n    \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        A perturbed network topology.\n    \"\"\"\n    n_generated_topologies = 0\n\n    # Stop after we generated n_topology_variants\n    while n_generated_topologies &lt; self.n_topology_variants:\n        perturbed_topology = copy.deepcopy(net)\n\n        # draw the number of components to drop from a uniform distribution\n        r = np.random.randint(\n            1,\n            self.k + 1,\n        )  # TODO: decide if we want to be able to set 0 components out of service\n\n        # Randomly select r&lt;=k components to drop\n        components = tuple(\n            np.random.choice(range(len(self.components_to_drop)), r, replace=False),\n        )\n\n        # Convert indices back to actual components\n        selected_components = tuple(\n            self.components_to_drop[idx] for idx in components\n        )\n\n        # Separate lines, transformers, generators, and static generators\n        branches_to_drop = [\n            idx for idx, element in selected_components if element == \"branch\"\n        ]\n        gens_to_drop = [\n            idx for idx, element in selected_components if element == \"gen\"\n        ]\n\n        # Drop selected lines and transformers, turn off generators and static generators\n        perturbed_topology.deactivate_branches(branches_to_drop)\n        perturbed_topology.deactivate_gens(gens_to_drop)\n\n        # Check network feasibility and yield the topology\n        if perturbed_topology.check_single_connected_component():\n            yield perturbed_topology\n            n_generated_topologies += 1\n</code></pre>"},{"location":"components/utils/","title":"Utils","text":"<p>This module provides utility functions for the project.</p>"},{"location":"components/utils/#functions","title":"Functions","text":""},{"location":"components/utils/#get_num_scenarios","title":"<code>get_num_scenarios</code>","text":"<p>Get total number of scenarios from data directory.</p> <p>Reads from n_scenarios.txt metadata file in the data directory.</p> <p>Parameters:</p> Name Type Description Default <code>data_dir</code> <code>str</code> <p>Directory containing parquet files and n_scenarios.txt</p> required <p>Returns:</p> Type Description <code>int</code> <p>Total number of scenarios</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_scenarios.txt metadata file not found</p> Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>def get_num_scenarios(data_dir: str) -&gt; int:\n    \"\"\"Get total number of scenarios from data directory.\n\n    Reads from n_scenarios.txt metadata file in the data directory.\n\n    Args:\n        data_dir: Directory containing parquet files and n_scenarios.txt\n\n    Returns:\n        Total number of scenarios\n\n    Raises:\n        ValueError: If n_scenarios.txt metadata file not found\n    \"\"\"\n    n_scenarios_file = os.path.join(data_dir, \"n_scenarios.txt\")\n    if os.path.exists(n_scenarios_file):\n        with open(n_scenarios_file, \"r\") as f:\n            return int(f.read().strip())\n\n    else:\n        print(\n            f\"No n_scenarios metadata file found in {data_dir}, using bus_data.parquet to get total number of scenarios\",\n        )\n        return int(\n            pd.read_parquet(\n                os.path.join(data_dir, \"bus_data.parquet\"),\n                engine=\"pyarrow\",\n            )[\"scenario\"].max()\n            + 1,\n        )\n</code></pre>"},{"location":"components/utils/#read_partitions","title":"<code>read_partitions</code>","text":"<p>Read sampled partition folders in parallel and concatenate them.</p> Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>def read_partitions(\n    base_path: str,\n    sampled: list,\n    max_workers: int = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Read sampled partition folders in parallel and concatenate them.\"\"\"\n    if max_workers is None:\n        from os import cpu_count\n\n        max_workers = min(32, cpu_count())  # sensible default\n\n    dfs = []\n\n    # Submit all partition reads to the ThreadPool\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        futures = {\n            executor.submit(\n                pd.read_parquet,\n                os.path.join(base_path, f\"scenario_partition={k}\"),\n                engine=\"pyarrow\",\n            ): k\n            for k in sampled\n        }\n\n        # Collect results as they complete with tqdm\n        for future in tqdm(\n            as_completed(futures),\n            total=len(futures),\n            desc=f\"Reading {len(sampled)} partitions from {base_path}\",\n        ):\n            df = future.result()\n            dfs.append(df)\n\n    # Concatenate all partitions\n    return pd.concat(dfs, ignore_index=True)\n</code></pre>"},{"location":"components/utils/#write_ram_usage_distributed","title":"<code>write_ram_usage_distributed</code>","text":"Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>def write_ram_usage_distributed(tqdm_log: TextIO) -&gt; None:\n    process = psutil.Process(os.getpid())  # Parent process\n    mem_usage = process.memory_info().rss / 1024**2  # Parent memory in MB\n\n    # Sum memory usage of all child processes\n    for child in process.children(recursive=True):\n        mem_usage += child.memory_info().rss / 1024**2\n\n    tqdm_log.write(f\"Total RAM usage (Parent + Children): {mem_usage:.2f} MB\\n\")\n</code></pre>"},{"location":"components/utils/#classes","title":"Classes","text":""},{"location":"components/utils/#tee","title":"<code>Tee</code>","text":"Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>class Tee:\n    def __init__(self, *streams):\n        self.streams = streams\n\n    def write(self, data):\n        for s in self.streams:\n            s.write(data)\n            s.flush()\n\n    def flush(self):\n        for s in self.streams:\n            s.flush()\n</code></pre>"},{"location":"components/validation/","title":"Validation","text":"<p>This module provides functions for validating the integrity and physical consistency of generated power flow data.</p>"},{"location":"components/validation/#validate_generated_data","title":"<code>validate_generated_data</code>","text":"<p>Run all validation tests on the generated data.</p> <p>Parameters:</p> Name Type Description Default <code>file_paths</code> <code>Dict[str, str]</code> <p>Dictionary containing paths to data files (bus_data, branch_data, gen_data, y_bus_data).</p> required <code>mode</code> <code>str</code> <p>Operating mode (\"opf\" or \"pf\").</p> required <code>n_partitions</code> <code>int</code> <p>Number of partitions to sample for validation (0 for all partitions).</p> <code>0</code> <code>sn_mva</code> <code>float</code> <p>Base MVA used to scale power quantities</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if all validations pass.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any validation fails.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_generated_data(\n    file_paths: Dict[str, str],\n    mode: str,\n    sn_mva: float,\n    n_partitions: int = 0,\n) -&gt; bool:\n    \"\"\"Run all validation tests on the generated data.\n\n    Args:\n        file_paths: Dictionary containing paths to data files (bus_data, branch_data, gen_data, y_bus_data).\n        mode: Operating mode (\"opf\" or \"pf\").\n        n_partitions: Number of partitions to sample for validation (0 for all partitions).\n        sn_mva: Base MVA used to scale power quantities\n\n    Returns:\n        True if all validations pass.\n\n    Raises:\n        AssertionError: If any validation fails.\n    \"\"\"\n    # Get total scenarios from metadata\n    data_dir = os.path.dirname(file_paths[\"bus_data\"])\n    total_scenarios = get_num_scenarios(data_dir)\n\n    # Step 1: Validate partition structure on ALL partitions\n    # print(\"Step 1: Validating partition structure on all partitions...\")\n    # _validate_partition_structure(file_paths, total_scenarios)\n\n    # Calculate number of partitions (n_scenario_per_partition scenarios per partition)\n    num_partitions = (\n        total_scenarios + n_scenario_per_partition - 1\n    ) // n_scenario_per_partition\n\n    # Sample partitions\n    if n_partitions &gt; 0:\n        n_partitions_to_sample = n_partitions\n        sampled_partitions = sorted(\n            np.random.choice(\n                num_partitions,\n                size=min(n_partitions_to_sample, num_partitions),\n                replace=False,\n            ),\n        )\n        max_scenarios_to_validate = len(sampled_partitions) * n_scenario_per_partition\n        print(\n            f\"Step 2: Running core validations on {len(sampled_partitions)} sampled partitions (up to {max_scenarios_to_validate} scenarios) out of {num_partitions} total\",\n        )\n    else:\n        sampled_partitions = list(range(num_partitions))\n        print(\n            f\"Step 2: Running core validations on all {num_partitions} partitions ({total_scenarios} total scenarios)\",\n        )\n\n    bus_data = read_partitions(file_paths[\"bus_data\"], sampled_partitions)\n    branch_data = read_partitions(file_paths[\"branch_data\"], sampled_partitions)\n    gen_data = read_partitions(file_paths[\"gen_data\"], sampled_partitions)\n    y_bus_data = read_partitions(file_paths[\"y_bus_data\"], sampled_partitions)\n    runtime_data = (\n        read_partitions(file_paths[\"runtime_data\"], sampled_partitions)\n        if \"runtime_data\" in file_paths\n        else None\n    )\n    if runtime_data is None:\n        print(\"No runtime data found, skipping runtime data validation\")\n    else:\n        print(f\"Runtime data found: {runtime_data.shape}\")\n\n    generated_data = {\n        \"bus_data\": bus_data,\n        \"branch_data\": branch_data,\n        \"gen_data\": gen_data,\n        \"y_bus_data\": y_bus_data,\n        \"runtime_data\": runtime_data,\n        \"mode\": mode,\n        \"file_paths\": file_paths,\n    }\n\n    # Run core validations on sampled partitions\n    try:\n        validate_scenario_indexing_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Scenario indexing consistency validation failed: {e}\")\n\n    try:\n        validate_bus_indexing_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Bus indexing consistency validation failed: {e}\")\n\n    try:\n        validate_data_completeness(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Data completeness validation failed: {e}\")\n\n    try:\n        validate_dc_columns_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"DC columns consistency validation failed: {e}\")\n\n    # Check voltage angles are within [-180, 180]\n    try:\n        validate_voltage_angles_within_bounds(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Voltage angles validation failed: {e}\")\n    # Run Y-Bus Consistency Tests\n    try:\n        validate_ybus_diagonal_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Y-bus diagonal consistency validation failed: {e}\")\n\n    # Run Branch Constraint Tests\n    try:\n        validate_deactivated_lines_zero_admittance(generated_data)\n    except Exception as e:\n        raise AssertionError(\n            f\"Deactivated lines zero admittance validation failed: {e}\",\n        )\n\n    try:\n        validate_admittance_calculations(generated_data)\n    except Exception as e:\n        raise AssertionError(\n            f\"Admittance calculations validation failed: {e}\",\n        )\n\n    try:\n        validate_computed_vs_stored_power_flows(generated_data, sn_mva)\n    except Exception as e:\n        raise AssertionError(f\"Computed vs stored power flows validation failed: {e}\")\n\n    try:\n        validate_tap_not_zero(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Tap not zero validation failed: {e}\")\n\n    # Run branch loading validation for both OPF and PF modes\n    # In OPF mode: asserts loading &lt;= 1.01\n    # In PF mode: computes statistics without asserting\n    try:\n        validate_branch_loading_opf_mode(generated_data)\n    except Exception as e:\n        if mode == \"opf\":\n            raise AssertionError(f\"Branch loading OPF mode validation failed: {e}\")\n        else:\n            print(f\"    Branch loading computation encountered errors: {e}\")\n\n    # Run Generator Constraint Tests\n    try:\n        validate_deactivated_generators_zero_output(generated_data)\n    except Exception as e:\n        raise AssertionError(\n            f\"Deactivated generators zero output validation failed: {e}\",\n        )\n\n    try:\n        validate_generator_limits(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Generator limits validation failed: {e}\")\n\n    # Run OPF mode Constraints\n    if mode == \"opf\":\n        try:\n            validate_voltage_magnitude_limits_opf_mode(generated_data)\n        except Exception as e:\n            raise AssertionError(\n                f\"Voltage magnitude limits OPF mode validation failed: {e}\",\n            )\n        try:\n            validate_branch_angle_difference_opf_mode(generated_data)\n        except Exception as e:\n            raise AssertionError(\n                f\"Branch angle difference limits OPF mode validation failed: {e}\",\n            )\n\n    # Run Power Balance Tests\n    try:\n        validate_bus_generation_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Bus generation consistency validation failed: {e}\")\n\n    # DC bus generation consistency (if DC fields present)\n    try:\n        validate_bus_generation_consistency_dc(generated_data)\n    except Exception as e:\n        raise AssertionError(f\"Bus generation DC consistency validation failed: {e}\")\n\n    # Check Pg and Pg_dc match at slack nodes in PF mode\n    if mode == \"pf\":\n        try:\n            validate_non_slack_pg_consistency(generated_data)\n        except Exception as e:\n            raise AssertionError(f\"Slack Pg consistency validation failed: {e}\")\n\n    try:\n        validate_power_balance_equations(generated_data, sn_mva)\n    except Exception as e:\n        raise AssertionError(f\"Power balance equations validation failed: {e}\")\n\n    # Run Generator Cost Perturbation Tests\n    try:\n        validate_constant_cost_generators_unchanged(generated_data)\n    except Exception as e:\n        raise AssertionError(\n            f\"Constant cost generators unchanged validation failed: {e}\",\n        )\n\n    # Run Bus Type and Generator Consistency Tests\n    try:\n        validate_bus_type_generator_consistency(generated_data)\n    except Exception as e:\n        raise AssertionError(\n            f\"Bus type-generator consistency validation failed: {e}\",\n        )\n\n    return True\n</code></pre>"},{"location":"components/validation/#functions","title":"Functions","text":""},{"location":"components/validation/#validate_ybus_diagonal_consistency","title":"<code>validate_ybus_diagonal_consistency</code>","text":"<p>Test Y-bus diagonal consistency with bus and branch data (vectorized).</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_ybus_diagonal_consistency(generated_data: Dict[str, pd.DataFrame]) -&gt; None:\n    \"\"\"Test Y-bus diagonal consistency with bus and branch data (vectorized).\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n    y_bus_data = generated_data[\"y_bus_data\"]\n\n    scenarios = bus_data[\"scenario\"].unique()\n    total_buses = len(bus_data)\n    print(\n        f\"    Y-bus diagonal consistency: validating {total_buses} bus entries across {len(scenarios)} scenarios\",\n    )\n\n    # Aggregate Yff contributions by (scenario, from_bus)\n    yff_sum = (\n        branch_data.groupby([\"scenario\", \"from_bus\"], as_index=False)\n        .agg({\"Yff_r\": \"sum\", \"Yff_i\": \"sum\"})\n        .rename(columns={\"from_bus\": \"bus\", \"Yff_r\": \"yff_sum_g\", \"Yff_i\": \"yff_sum_b\"})\n    )\n\n    # Aggregate Ytt contributions by (scenario, to_bus)\n    ytt_sum = (\n        branch_data.groupby([\"scenario\", \"to_bus\"], as_index=False)\n        .agg({\"Ytt_r\": \"sum\", \"Ytt_i\": \"sum\"})\n        .rename(columns={\"to_bus\": \"bus\", \"Ytt_r\": \"ytt_sum_g\", \"Ytt_i\": \"ytt_sum_b\"})\n    )\n\n    # Prepare bus data with (scenario, bus) as key\n    bus_keyed = bus_data[[\"scenario\", \"bus\", \"GS\", \"BS\"]].copy()\n    bus_keyed[\"scenario\"] = bus_keyed[\"scenario\"].astype(int)\n    bus_keyed[\"bus\"] = bus_keyed[\"bus\"].astype(int)\n\n    # Merge all contributions\n    expected = (\n        bus_keyed.merge(yff_sum, on=[\"scenario\", \"bus\"], how=\"left\")\n        .merge(ytt_sum, on=[\"scenario\", \"bus\"], how=\"left\")\n        .fillna(\n            {\"yff_sum_g\": 0.0, \"yff_sum_b\": 0.0, \"ytt_sum_g\": 0.0, \"ytt_sum_b\": 0.0},\n        )\n    )\n\n    # Compute expected G and B\n    expected[\"expected_g\"] = (\n        expected[\"GS\"] + expected[\"yff_sum_g\"] + expected[\"ytt_sum_g\"]\n    )\n    expected[\"expected_b\"] = (\n        expected[\"BS\"] + expected[\"yff_sum_b\"] + expected[\"ytt_sum_b\"]\n    )\n\n    # Get actual G and B from y_bus_data (diagonal entries only)\n    ybus_diagonal = y_bus_data[(y_bus_data[\"index1\"] == y_bus_data[\"index2\"])][\n        [\"scenario\", \"index1\", \"G\", \"B\"]\n    ].rename(columns={\"index1\": \"bus\"})\n    ybus_diagonal[\"scenario\"] = ybus_diagonal[\"scenario\"].astype(int)\n    ybus_diagonal[\"bus\"] = ybus_diagonal[\"bus\"].astype(int)\n\n    # Merge expected with actual\n    comparison = expected.merge(\n        ybus_diagonal,\n        on=[\"scenario\", \"bus\"],\n        how=\"left\",\n        suffixes=(\"\", \"_actual\"),\n    )\n\n    # Vectorized comparison\n    g_diff = np.abs(comparison[\"expected_g\"] - comparison[\"G\"])\n    b_diff = np.abs(comparison[\"expected_b\"] - comparison[\"B\"])\n\n    tolerance = 1e-6\n    g_mismatches = comparison[g_diff &gt;= tolerance]\n    b_mismatches = comparison[b_diff &gt;= tolerance]\n\n    if len(g_mismatches) &gt; 0:\n        raise AssertionError(f\"G mismatches: {g_mismatches}\")\n    if len(b_mismatches) &gt; 0:\n        raise AssertionError(f\"B mismatches: {b_mismatches}\")\n</code></pre>"},{"location":"components/validation/#validate_deactivated_lines_zero_admittance","title":"<code>validate_deactivated_lines_zero_admittance</code>","text":"<p>Test that deactivated lines have zero power flows and admittances.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_deactivated_lines_zero_admittance(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that deactivated lines have zero power flows and admittances.\"\"\"\n    branch_data = generated_data[\"branch_data\"]\n    deactivated_branches = branch_data[branch_data[\"br_status\"] == 0]\n\n    print(\n        f\"    Deactivated lines zero admittance: validating {len(deactivated_branches)} deactivated branches\",\n    )\n    if not deactivated_branches.empty:\n        assert (deactivated_branches[\"pf\"] == 0).all(), (\n            \"Deactivated branches should have zero pf\"\n        )\n        assert (deactivated_branches[\"qf\"] == 0).all(), (\n            \"Deactivated branches should have zero qf\"\n        )\n        assert (deactivated_branches[\"pt\"] == 0).all(), (\n            \"Deactivated branches should have zero pt\"\n        )\n        assert (deactivated_branches[\"qt\"] == 0).all(), (\n            \"Deactivated branches should have zero qt\"\n        )\n        assert (deactivated_branches[\"Yff_r\"] == 0).all(), (\n            \"Deactivated branches should have zero Yff_r\"\n        )\n        assert (deactivated_branches[\"Yff_i\"] == 0).all(), (\n            \"Deactivated branches should have zero Yff_i\"\n        )\n        assert (deactivated_branches[\"Yft_r\"] == 0).all(), (\n            \"Deactivated branches should have zero Yft_r\"\n        )\n        assert (deactivated_branches[\"Yft_i\"] == 0).all(), (\n            \"Deactivated branches should have zero Yft_i\"\n        )\n        assert (deactivated_branches[\"Ytf_r\"] == 0).all(), (\n            \"Deactivated branches should have zero Ytf_r\"\n        )\n        assert (deactivated_branches[\"Ytf_i\"] == 0).all(), (\n            \"Deactivated branches should have zero Ytf_i\"\n        )\n        assert (deactivated_branches[\"Ytt_r\"] == 0).all(), (\n            \"Deactivated branches should have zero Ytt_r\"\n        )\n        assert (deactivated_branches[\"Ytt_i\"] == 0).all(), (\n            \"Deactivated branches should have zero Ytt_i\"\n        )\n\n    print(\"    Deactivated lines zero admittance: OK\")\n</code></pre>"},{"location":"components/validation/#validate_computed_vs_stored_power_flows","title":"<code>validate_computed_vs_stored_power_flows</code>","text":"<p>Test that computed power flows match stored power flows.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_computed_vs_stored_power_flows(\n    generated_data: Dict[str, pd.DataFrame],\n    sn_mva: float,\n) -&gt; None:\n    \"\"\"Test that computed power flows match stored power flows.\"\"\"\n\n    print(\n        f\"    Validate computed vs stored power flows: validating {len(generated_data['branch_data'])} branches across {len(generated_data['branch_data']['scenario'].unique())} scenarios\",\n    )\n\n    pf, qf, pt, qt = compute_branch_powers_vectorized(\n        generated_data[\"branch_data\"],\n        generated_data[\"bus_data\"],\n        dc=False,\n        sn_mva=sn_mva,\n    )\n    computed_flows = pd.DataFrame(\n        {\n            \"pf\": pf,\n            \"qf\": qf,\n            \"pt\": pt,\n            \"qt\": qt,\n            \"scenario\": generated_data[\"branch_data\"][\"scenario\"],\n            \"from_bus\": generated_data[\"branch_data\"][\"from_bus\"],\n            \"to_bus\": generated_data[\"branch_data\"][\"to_bus\"],\n        },\n        index=generated_data[\"branch_data\"].index,\n    )\n\n    flows_data = generated_data[\"branch_data\"][\n        [\"pf\", \"qf\", \"pt\", \"qt\", \"scenario\", \"from_bus\", \"to_bus\"]\n    ]\n    mismatch = ~np.isclose(computed_flows, flows_data, atol=1e-2, rtol=1e-3)\n    # TODO investigate why atol has to be so large, especially for pf delta\n    if mismatch.any():\n        raise AssertionError(\n            f\"Computed power flows do not match stored power flows, stored: \\n{flows_data[mismatch]}, computed: \\n{computed_flows[mismatch]}\",\n        )\n\n    print(\"    Computed vs stored power flows: OK\")\n</code></pre>"},{"location":"components/validation/#validate_branch_loading_opf_mode","title":"<code>validate_branch_loading_opf_mode</code>","text":"<p>Test branch loading limits in OPF mode, compute loading statistics in PF mode.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_branch_loading_opf_mode(generated_data: Dict[str, pd.DataFrame]) -&gt; None:\n    \"\"\"Test branch loading limits in OPF mode, compute loading statistics in PF mode.\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n\n    scenarios = bus_data[\"scenario\"].unique()\n\n    # Filter to active, rated branches\n    rated_branches = branch_data[\n        (branch_data[\"br_status\"] == 1) &amp; (branch_data[\"rate_a\"] &gt; 0)\n    ].copy()\n\n    mode_label = \"opf\" if generated_data[\"mode\"] == \"opf\" else \"pf\"\n    print(\n        f\"    Branch loading limits ({mode_label} mode): validating {len(rated_branches)} rated branches across {len(scenarios)} scenarios\",\n    )\n\n    # Vectorized computation of loading\n    # Compute apparent power: S = sqrt(P^2 + Q^2)\n    s_from = np.sqrt(\n        rated_branches[\"pf\"].to_numpy() ** 2 + rated_branches[\"qf\"].to_numpy() ** 2,\n    )\n    s_to = np.sqrt(\n        rated_branches[\"pt\"].to_numpy() ** 2 + rated_branches[\"qt\"].to_numpy() ** 2,\n    )\n    rate_a = rated_branches[\"rate_a\"].to_numpy()\n\n    # Loading = max(S_from, S_to) / rate_a\n    loading = np.maximum(s_from, s_to) / rate_a\n\n    # Identify binding and overloaded branches\n    binding_mask = loading &gt;= 0.99\n    overload_mask = loading &gt; 1.01\n\n    binding_loadings = loading[binding_mask]\n    n_binding = len(binding_loadings)\n    n_overloads = overload_mask.sum()\n\n    # In OPF mode, assert no overloads\n    if generated_data[\"mode\"] == \"opf\":\n        if n_overloads &gt; 0:\n            overloaded_idx = np.where(overload_mask)[0]\n            overload_info = rated_branches.iloc[overloaded_idx[0]]\n            raise AssertionError(\n                f\"Scenario {int(overload_info['scenario'])}, \"\n                f\"Branch {int(overload_info['from_bus'])}-&gt;{int(overload_info['to_bus'])}: \"\n                f\"Loading {loading[overloaded_idx[0]]:.3f} exceeds 1.01 in OPF mode\",\n            )\n\n    print(\n        f\"    Binding loading constraints (&gt;= 0.99): {n_binding} branches\",\n    )\n    if generated_data[\"mode\"] == \"pf\":\n        print(f\"    Overloaded branches (&gt; 1.0): {n_overloads} branches\")\n        print(\"    Branch loading limits (PF mode): statistics computed\")\n    else:\n        print(\"    Branch loading limits (OPF mode): OK\")\n</code></pre>"},{"location":"components/validation/#validate_deactivated_generators_zero_output","title":"<code>validate_deactivated_generators_zero_output</code>","text":"<p>Test that deactivated generators have zero output.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_deactivated_generators_zero_output(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that deactivated generators have zero output.\"\"\"\n    gen_data = generated_data[\"gen_data\"]\n    deactivated_gens = gen_data[gen_data[\"in_service\"] == 0]\n\n    print(\n        f\"    Deactivated generators zero output: validating {len(deactivated_gens)} deactivated generators\",\n    )\n    if not deactivated_gens.empty:\n        assert (deactivated_gens[\"p_mw\"] == 0).all(), (\n            \"Deactivated generators should have zero p_mw\"\n        )\n        assert (deactivated_gens[\"q_mvar\"] == 0).all(), (\n            \"Deactivated generators should have zero q_mvar\"\n        )\n\n        if \"p_mw_dc\" in deactivated_gens.columns:\n            # zero or nan (if no solution was found)\n            assert (\n                (deactivated_gens[\"p_mw_dc\"] == 0)\n                | (deactivated_gens[\"p_mw_dc\"].isna())\n            ).all(), \"Deactivated generators should have zero p_mw_dc or be NaN\"\n\n    print(\"    Deactivated generators zero output: OK\")\n</code></pre>"},{"location":"components/validation/#validate_generator_limits","title":"<code>validate_generator_limits</code>","text":"<p>Test that generator outputs respect their limits.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_generator_limits(generated_data: Dict[str, pd.DataFrame]) -&gt; None:\n    \"\"\"Test that generator outputs respect their limits.\"\"\"\n    gen_data = generated_data[\"gen_data\"]\n    gen_data = gen_data[gen_data[\"in_service\"] == 1]\n    # keep only the ones with limits for p_mw\n    filtered_gens = gen_data[\n        gen_data[\"max_p_mw\"].notna() &amp; gen_data[\"min_p_mw\"].notna()\n    ]\n\n    if generated_data[\"mode\"] == \"pf\":\n        filtered_gens = filtered_gens[filtered_gens[\"is_slack_gen\"] == 0]\n\n    print(\n        f\"    Generator limits: validating {len(filtered_gens)} active generators (mode: {generated_data['mode']})\",\n    )\n\n    # Count binding P limits\n    binding_p_min = 0\n    binding_p_max = 0\n    if not filtered_gens.empty:\n        p_within_limits = (\n            filtered_gens[\"p_mw\"] &gt;= filtered_gens[\"min_p_mw\"] - 1e-2\n        ) &amp; (filtered_gens[\"p_mw\"] &lt;= filtered_gens[\"max_p_mw\"] + 1e-2)\n\n        # Check for binding minimum limits\n        p_at_min = (filtered_gens[\"p_mw\"] &lt;= filtered_gens[\"min_p_mw\"] + 1e-2) &amp; (\n            filtered_gens[\"p_mw\"] &gt;= filtered_gens[\"min_p_mw\"] - 1e-2\n        )\n        binding_p_min = p_at_min.sum()\n\n        # Check for binding maximum limits\n        p_at_max = (filtered_gens[\"p_mw\"] &lt;= filtered_gens[\"max_p_mw\"] + 1e-2) &amp; (\n            filtered_gens[\"p_mw\"] &gt;= filtered_gens[\"max_p_mw\"] - 1e-2\n        )\n        binding_p_max = p_at_max.sum()\n\n        assert p_within_limits.all(), (\n            f\"Generator active power should be within limits, current: \\n{filtered_gens.loc[~p_within_limits, ['bus', 'p_mw']]}, \\nmax: \\n{filtered_gens.loc[~p_within_limits, ['bus', 'max_p_mw']]}\"\n        )\n\n    # Count binding Q limits (only in OPF mode)\n    binding_q_min = 0\n    binding_q_max = 0\n    if generated_data[\"mode\"] == \"opf\":\n        filtered_gens_q = filtered_gens[\n            filtered_gens[\"max_q_mvar\"].notna() &amp; filtered_gens[\"min_q_mvar\"].notna()\n        ]\n        q_within_limits = (\n            filtered_gens_q[\"q_mvar\"] &gt;= filtered_gens_q[\"min_q_mvar\"] - 1e-2\n        ) &amp; (filtered_gens_q[\"q_mvar\"] &lt;= filtered_gens_q[\"max_q_mvar\"] + 1e-2)\n\n        # Check for binding minimum limits\n        q_at_min = (\n            filtered_gens_q[\"q_mvar\"] &lt;= filtered_gens_q[\"min_q_mvar\"] + 1e-2\n        ) &amp; (filtered_gens_q[\"q_mvar\"] &gt;= filtered_gens_q[\"min_q_mvar\"] - 1e-2)\n        binding_q_min = q_at_min.sum()\n\n        # Check for binding maximum limits\n        q_at_max = (\n            filtered_gens_q[\"q_mvar\"] &lt;= filtered_gens_q[\"max_q_mvar\"] + 1e-2\n        ) &amp; (filtered_gens_q[\"q_mvar\"] &gt;= filtered_gens_q[\"max_q_mvar\"] - 1e-2)\n        binding_q_max = q_at_max.sum()\n\n        assert q_within_limits.all(), (\n            f\"Generator reactive power should be within limits, expected: {filtered_gens_q.loc[~q_within_limits, ['bus', 'q_mvar']]}, actual: {filtered_gens_q.loc[~q_within_limits, ['bus', 'q_mvar']]}, max: {filtered_gens_q.loc[~q_within_limits, ['bus', 'max_q_mvar']]}\"\n        )\n\n    print(\n        f\"    Binding P limits: {binding_p_min} at minimum, {binding_p_max} at maximum\",\n    )\n    if generated_data[\"mode\"] == \"opf\":\n        print(\n            f\"    Binding Q limits: {binding_q_min} at minimum, {binding_q_max} at maximum\",\n        )\n    print(\"    Generator limits: OK\")\n</code></pre>"},{"location":"components/validation/#validate_voltage_magnitude_limits_opf_mode","title":"<code>validate_voltage_magnitude_limits_opf_mode</code>","text":"<p>Test voltage magnitude limits in OPF mode.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_voltage_magnitude_limits_opf_mode(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test voltage magnitude limits in OPF mode.\"\"\"\n    if generated_data[\"mode\"] != \"opf\":\n        print(\"    Voltage magnitude limits: skipped (not in OPF mode)\")\n        return\n\n    bus_data = generated_data[\"bus_data\"]\n    print(\n        f\"    Voltage magnitude limits (OPF mode): validating {len(bus_data)} bus voltage entries\",\n    )\n    vm_within_limits = (bus_data[\"Vm\"] &gt;= bus_data[\"min_vm_pu\"] - 1e-6) &amp; (\n        bus_data[\"Vm\"] &lt;= bus_data[\"max_vm_pu\"] + 1e-6\n    )\n    assert vm_within_limits.all(), \"Voltage magnitudes should be within limits\"\n    print(\"    Voltage magnitude limits (OPF mode): OK\")\n</code></pre>"},{"location":"components/validation/#validate_bus_generation_consistency","title":"<code>validate_bus_generation_consistency</code>","text":"<p>Test that Pg in bus data equals sum of generators at each bus (vectorized).</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_bus_generation_consistency(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that Pg in bus data equals sum of generators at each bus (vectorized).\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    gen_data = generated_data[\"gen_data\"]\n\n    scenarios = bus_data[\"scenario\"].unique()\n    print(\n        f\"    Bus generation consistency: validating {len(bus_data)} bus entries across {len(scenarios)} scenarios\",\n    )\n\n    # Aggregate generator outputs by (scenario, bus)\n    gen_sum = (\n        gen_data.groupby([\"scenario\", \"bus\"], as_index=False)\n        .agg({\"p_mw\": \"sum\", \"q_mvar\": \"sum\"})\n        .rename(columns={\"p_mw\": \"pg_gen_sum\", \"q_mvar\": \"qg_gen_sum\"})\n    )\n\n    # Prepare bus data with (scenario, bus) as key\n    bus_keyed = bus_data[[\"scenario\", \"bus\", \"Pg\", \"Qg\"]].copy()\n    bus_keyed[\"scenario\"] = bus_keyed[\"scenario\"].astype(int)\n    bus_keyed[\"bus\"] = bus_keyed[\"bus\"].astype(int)\n\n    # Merge bus data with generator sums\n    comparison = bus_keyed.merge(gen_sum, on=[\"scenario\", \"bus\"], how=\"left\").fillna(\n        {\"pg_gen_sum\": 0.0, \"qg_gen_sum\": 0.0},\n    )\n\n    # Vectorized comparison\n    tolerance = 1e-6\n    pg_diff = np.abs(comparison[\"Pg\"] - comparison[\"pg_gen_sum\"])\n    qg_diff = np.abs(comparison[\"Qg\"] - comparison[\"qg_gen_sum\"])\n\n    pg_mismatches = comparison[pg_diff &gt;= tolerance]\n    qg_mismatches = comparison[qg_diff &gt;= tolerance]\n\n    if len(pg_mismatches) &gt; 0:\n        raise AssertionError(f\"Pg mismatches: {pg_mismatches}\")\n    if len(qg_mismatches) &gt; 0:\n        raise AssertionError(f\"Qg mismatches: {qg_mismatches}\")\n\n    print(\"    Bus generation consistency: OK\")\n</code></pre>"},{"location":"components/validation/#validate_power_balance_equations","title":"<code>validate_power_balance_equations</code>","text":"<p>Test power balance equations (Kirchhoff's Current Law).</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_power_balance_equations(\n    generated_data: Dict[str, pd.DataFrame],\n    sn_mva: float,\n) -&gt; None:\n    \"\"\"Test power balance equations (Kirchhoff's Current Law).\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n\n    scenarios = bus_data[\"scenario\"].unique()\n    print(\n        f\"    Power balance equations (Kirchhoff's Law): validating {len(bus_data)} bus entries across {len(scenarios)} scenarios\",\n    )\n\n    power_balance_ac = compute_bus_balance(\n        bus_data,\n        branch_data,\n        branch_data[[\"pf\", \"qf\", \"pt\", \"qt\"]],\n        False,\n        sn_mva=sn_mva,\n    )\n    not_close_zero = ~np.isclose(0.0, power_balance_ac[\"P_mis_ac\"], atol=1e-3)\n    # TODO investigate why atol has to be so large\n    if not_close_zero.any():\n        raise AssertionError(\n            f\"Power balance equations (Kirchhoff's Law) do not hold, mismatches: {power_balance_ac[not_close_zero]}\",\n        )\n\n    print(\"    Power balance equations (Kirchhoff's Law): OK\")\n</code></pre>"},{"location":"components/validation/#validate_constant_cost_generators_unchanged","title":"<code>validate_constant_cost_generators_unchanged</code>","text":"<p>Test that generators with constant-only costs remain unchanged across scenarios (vectorized).</p> <p>Generators with constant costs (only c0 != 0, with c1 == 0 and c2 == 0) should not be perturbed or permuted, so their cost coefficients should remain identical across all scenarios. This validation checks that constraint.</p> <p>Parameters:</p> Name Type Description Default <code>generated_data</code> <code>Dict[str, DataFrame]</code> <p>Dictionary containing gen_data DataFrame.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any constant-cost generator has varying costs across scenarios.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_constant_cost_generators_unchanged(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that generators with constant-only costs remain unchanged across scenarios (vectorized).\n\n    Generators with constant costs (only c0 != 0, with c1 == 0 and c2 == 0) should not\n    be perturbed or permuted, so their cost coefficients should remain identical across\n    all scenarios. This validation checks that constraint.\n\n    Args:\n        generated_data: Dictionary containing gen_data DataFrame.\n\n    Raises:\n        AssertionError: If any constant-cost generator has varying costs across scenarios.\n    \"\"\"\n    gen_data = generated_data[\"gen_data\"]\n\n    if len(gen_data) == 0:\n        print(\"    Constant cost generators unchanged: no generators to validate\")\n        return\n\n    scenarios = gen_data[\"scenario\"].unique()\n\n    # Identify constant-cost generators (c1 == 0 and c2 == 0)\n    # We check the first scenario to identify which generators have constant costs\n    first_scenario_data = gen_data[gen_data[\"scenario\"] == scenarios[0]].copy()\n\n    # Check if generators have non-zero c1 or c2 (columns cp1_eur_per_mw, cp2_eur_per_mw2)\n    # Constant-cost generators have both c1 and c2 equal to zero\n    constant_cost_mask = (first_scenario_data[\"cp1_eur_per_mw\"] == 0) &amp; (\n        first_scenario_data[\"cp2_eur_per_mw2\"] == 0\n    )\n\n    # Use \"idx\" to uniquely identify generators (bus alone is not unique - multiple gens can be at same bus)\n    constant_cost_gen_idx = first_scenario_data[constant_cost_mask][\"idx\"].values\n\n    if len(constant_cost_gen_idx) == 0:\n        print(\n            \"    Constant cost generators unchanged: no constant-cost generators found\",\n        )\n        return\n\n    print(\n        f\"    Constant cost generators unchanged: validating {len(constant_cost_gen_idx)} constant-cost generators across {len(scenarios)} scenarios\",\n    )\n\n    # Filter to constant-cost generators only\n    constant_gen_data = gen_data[gen_data[\"idx\"].isin(constant_cost_gen_idx)][\n        [\"scenario\", \"idx\", \"bus\", \"cp0_eur\", \"cp1_eur_per_mw\", \"cp2_eur_per_mw2\"]\n    ].copy()\n\n    # Get reference costs from first scenario (for each generator idx)\n    reference_costs = constant_gen_data[\n        constant_gen_data[\"scenario\"] == scenarios[0]\n    ].set_index(\"idx\")[[\"cp0_eur\", \"cp1_eur_per_mw\", \"cp2_eur_per_mw2\"]]\n\n    # Merge reference costs with all scenarios for vectorized comparison\n    comparison = constant_gen_data.merge(\n        reference_costs,\n        left_on=\"idx\",\n        right_index=True,\n        suffixes=(\"\", \"_ref\"),\n    )\n\n    # Vectorized comparison across all generators and scenarios\n    tolerance = 1e-9\n    c0_diff = np.abs(comparison[\"cp0_eur\"] - comparison[\"cp0_eur_ref\"])\n    c1_diff = np.abs(comparison[\"cp1_eur_per_mw\"] - comparison[\"cp1_eur_per_mw_ref\"])\n    c2_diff = np.abs(comparison[\"cp2_eur_per_mw2\"] - comparison[\"cp2_eur_per_mw2_ref\"])\n\n    # Find any mismatches\n    mismatches = (\n        (c0_diff &gt;= tolerance) | (c1_diff &gt;= tolerance) | (c2_diff &gt;= tolerance)\n    )\n\n    if mismatches.any():\n        # Get first mismatch for error reporting\n        mismatch_idx = np.where(mismatches)[0][0]\n        mismatch_row = comparison.iloc[mismatch_idx]\n        raise AssertionError(\n            f\"Generator idx={int(mismatch_row['idx'])} at bus {int(mismatch_row['bus'])} (constant-cost) has varying costs across scenarios. \"\n            f\"Scenario {int(mismatch_row['scenario'])}: \"\n            f\"c0={mismatch_row['cp0_eur']:.6f}, c1={mismatch_row['cp1_eur_per_mw']:.6f}, c2={mismatch_row['cp2_eur_per_mw2']:.6f} \"\n            f\"vs reference: c0={mismatch_row['cp0_eur_ref']:.6f}, c1={mismatch_row['cp1_eur_per_mw_ref']:.6f}, c2={mismatch_row['cp2_eur_per_mw2_ref']:.6f}\",\n        )\n\n    print(\"    Constant cost generators unchanged: OK\")\n</code></pre>"},{"location":"components/validation/#validate_bus_type_generator_consistency","title":"<code>validate_bus_type_generator_consistency</code>","text":"<p>Test that bus types are consistent with generator presence (vectorized).</p> <p>Validates fundamental power system constraints: - PV buses (voltage-controlled) must have at least one active generator - PQ buses (load buses) must have NO active generators - REF buses (slack/reference) must have at least one active generator</p> <p>Parameters:</p> Name Type Description Default <code>generated_data</code> <code>Dict[str, DataFrame]</code> <p>Dictionary containing bus_data and gen_data DataFrames.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any bus type constraint is violated.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_bus_type_generator_consistency(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that bus types are consistent with generator presence (vectorized).\n\n    Validates fundamental power system constraints:\n    - PV buses (voltage-controlled) must have at least one active generator\n    - PQ buses (load buses) must have NO active generators\n    - REF buses (slack/reference) must have at least one active generator\n\n    Args:\n        generated_data: Dictionary containing bus_data and gen_data DataFrames.\n\n    Raises:\n        AssertionError: If any bus type constraint is violated.\n    \"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    gen_data = generated_data[\"gen_data\"]\n\n    scenarios = bus_data[\"scenario\"].unique()\n    print(\n        f\"    Bus type-generator consistency: validating {len(bus_data)} bus entries across {len(scenarios)} scenarios\",\n    )\n\n    # Count active generators per (scenario, bus)\n    active_gens = (\n        gen_data[gen_data[\"in_service\"] == 1]\n        .groupby(\n            [\"scenario\", \"bus\"],\n            as_index=False,\n        )\n        .size()\n    )\n    active_gens.columns = [\"scenario\", \"bus\", \"n_active_gens\"]\n\n    # Merge with bus data\n    bus_with_gen_counts = bus_data.merge(\n        active_gens,\n        on=[\"scenario\", \"bus\"],\n        how=\"left\",\n    ).fillna({\"n_active_gens\": 0})\n\n    bus_with_gen_counts[\"n_active_gens\"] = bus_with_gen_counts[\"n_active_gens\"].astype(\n        int,\n    )\n\n    # Validate PV buses have at least one active generator\n    pv_buses = bus_with_gen_counts[bus_with_gen_counts[\"PV\"] == 1]\n    pv_no_gen = pv_buses[pv_buses[\"n_active_gens\"] == 0]\n\n    if len(pv_no_gen) &gt; 0:\n        first_violation = pv_no_gen.iloc[0]\n        raise AssertionError(\n            f\"PV bus {int(first_violation['bus'])} in scenario {int(first_violation['scenario'])} \"\n            f\"has no active generators. PV buses must have at least one active generator to control voltage. \"\n            f\"Found {len(pv_no_gen)} total violations.\",\n        )\n\n    # Validate PQ buses have NO active generators\n    pq_buses = bus_with_gen_counts[bus_with_gen_counts[\"PQ\"] == 1]\n    pq_with_gen = pq_buses[pq_buses[\"n_active_gens\"] &gt; 0]\n\n    if len(pq_with_gen) &gt; 0:\n        first_violation = pq_with_gen.iloc[0]\n        raise AssertionError(\n            f\"PQ bus {int(first_violation['bus'])} in scenario {int(first_violation['scenario'])} \"\n            f\"has {int(first_violation['n_active_gens'])} active generator(s). PQ buses (load buses) \"\n            f\"must have no active generators. Found {len(pq_with_gen)} total violations.\",\n        )\n\n    # Validate REF (slack) buses have at least one active generator\n    ref_buses = bus_with_gen_counts[bus_with_gen_counts[\"REF\"] == 1]\n    ref_no_gen = ref_buses[ref_buses[\"n_active_gens\"] == 0]\n\n    if len(ref_no_gen) &gt; 0:\n        first_violation = ref_no_gen.iloc[0]\n        raise AssertionError(\n            f\"REF/Slack bus {int(first_violation['bus'])} in scenario {int(first_violation['scenario'])} \"\n            f\"has no active generators. REF buses must have at least one active generator to balance the system. \"\n            f\"Found {len(ref_no_gen)} total violations.\",\n        )\n\n    print(\n        f\"    Bus type-generator consistency: validated {len(pv_buses)} PV, {len(pq_buses)} PQ, {len(ref_buses)} REF bus entries\",\n    )\n    print(\"    Bus type-generator consistency: OK\")\n</code></pre>"},{"location":"components/validation/#validate_scenario_indexing_consistency","title":"<code>validate_scenario_indexing_consistency</code>","text":"<p>Test that scenario indices are consistent across all data files.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_scenario_indexing_consistency(\n    generated_data: Dict[str, pd.DataFrame],\n) -&gt; None:\n    \"\"\"Test that scenario indices are consistent across all data files.\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n    gen_data = generated_data[\"gen_data\"]\n    y_bus_data = generated_data[\"y_bus_data\"]\n\n    bus_scenarios = set(bus_data[\"scenario\"].unique())\n    branch_scenarios = set(branch_data[\"scenario\"].unique())\n    gen_scenarios = set(gen_data[\"scenario\"].unique())\n    ybus_scenarios = set(y_bus_data[\"scenario\"].unique())\n\n    print(\n        f\"    Scenario indexing consistency: validating {len(bus_scenarios)} scenarios across 4 data files\",\n    )\n\n    assert bus_scenarios == branch_scenarios == gen_scenarios == ybus_scenarios, (\n        \"All data files should contain the same set of scenario indices\"\n    )\n\n    print(\"    Scenario indexing consistency: OK\")\n</code></pre>"},{"location":"components/validation/#validate_bus_indexing_consistency","title":"<code>validate_bus_indexing_consistency</code>","text":"<p>Test that bus indices are consistent across data files.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_bus_indexing_consistency(generated_data: Dict[str, pd.DataFrame]) -&gt; None:\n    \"\"\"Test that bus indices are consistent across data files.\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n    gen_data = generated_data[\"gen_data\"]\n\n    bus_indices = set(bus_data[\"bus\"].unique())\n    branch_bus_indices = set(branch_data[\"from_bus\"].unique()) | set(\n        branch_data[\"to_bus\"].unique(),\n    )\n    gen_bus_indices = set(gen_data[\"bus\"].unique())\n\n    print(\n        f\"    Bus indexing consistency: validating {len(bus_indices)} buses across 3 data files\",\n    )\n\n    assert gen_bus_indices.issubset(bus_indices), (\n        \"All generator buses should exist in bus data\"\n    )\n    assert branch_bus_indices.issubset(bus_indices), (\n        \"All branch endpoint buses should exist in bus data\"\n    )\n\n    print(\"    Bus indexing consistency: OK\")\n</code></pre>"},{"location":"components/validation/#validate_data_completeness","title":"<code>validate_data_completeness</code>","text":"<p>Test that all required columns are present and contain no NaN values.</p> Source code in <code>gridfm_datakit/validation.py</code> <pre><code>def validate_data_completeness(generated_data: Dict[str, pd.DataFrame]) -&gt; None:\n    \"\"\"Test that all required columns are present and contain no NaN values.\"\"\"\n    bus_data = generated_data[\"bus_data\"]\n    branch_data = generated_data[\"branch_data\"]\n    gen_data = generated_data[\"gen_data\"]\n    y_bus_data = generated_data[\"y_bus_data\"]\n    runtime_data = generated_data[\"runtime_data\"]\n\n    total_entries = len(bus_data) + len(branch_data) + len(gen_data) + len(y_bus_data)\n    print(\n        f\"    Data completeness: validating {total_entries} total entries across 4 data files\",\n    )\n\n    # 1) Ensure 'scenario' column exists everywhere\n    for name, df in [\n        (\"Bus data\", bus_data),\n        (\"Branch data\", branch_data),\n        (\"Generator data\", gen_data),\n        (\"Y-bus data\", y_bus_data),\n    ]:\n        assert \"scenario\" in df.columns, f\"{name} should have scenario column\"\n\n    if runtime_data is not None:\n        assert \"scenario\" in runtime_data.columns, (\n            \"Runtime data should have scenario column\"\n        )\n\n    dc = True if \"Va_dc\" in bus_data.columns else False\n\n    # 2) Check required columns exist and contain no NaN values\n    _require_columns(\n        bus_data,\n        \"Bus data\",\n        BUS_COLUMNS + DC_BUS_COLUMNS if dc else BUS_COLUMNS,\n    )\n    _require_columns(\n        branch_data,\n        \"Branch data\",\n        BRANCH_COLUMNS + DC_BRANCH_COLUMNS if dc else BRANCH_COLUMNS,\n    )\n    _require_columns(\n        gen_data,\n        \"Generator data\",\n        GEN_COLUMNS + DC_GEN_COLUMNS if dc else GEN_COLUMNS,\n    )\n    _require_columns(y_bus_data, \"Y-bus data\", YBUS_COLUMNS)\n\n    _check_no_nan(bus_data, \"Bus data\", BUS_COLUMNS)\n    _check_no_nan(branch_data, \"Branch data\", BRANCH_COLUMNS)\n    _check_no_nan(gen_data, \"Generator data\", GEN_COLUMNS)\n    _check_no_nan(y_bus_data, \"Y-bus data\", YBUS_COLUMNS)\n    if runtime_data is not None:\n        _check_no_nan(runtime_data, \"Runtime data\", RUNTIME_COLUMNS)\n\n    # 3) Non-emptiness\n    assert len(bus_data) &gt; 0, \"Bus data should not be empty\"\n    assert len(branch_data) &gt; 0, \"Branch data should not be empty\"\n    assert len(gen_data) &gt; 0, \"Generator data should not be empty\"\n    assert len(y_bus_data) &gt; 0, \"Y-bus data should not be empty\"\n\n    print(\"    Data completeness: OK (all required columns present and NaN-free)\")\n</code></pre>"},{"location":"manual/admittance_perturbations/","title":"Admittance Perturbations","text":""},{"location":"manual/admittance_perturbations/#overview","title":"Overview","text":"<p>Admittance perturbations introduce changes to branch admittance values by applying random scaling factors to the resistance (\\(R\\)) and reactance (\\(X\\)) parameters of grid branches. This results in more variance and diversity in power flow solutions which is beneficial for training ML models to improve generalization.</p> <p>The module provides two options for admittance perturbation strategies:</p> <ul> <li> <p><code>NoAdmittancePerturbationGenerator</code> yields the original example without any additional changes in branch admittances.</p> </li> <li> <p><code>PerturbAdmittanceGenerator</code> applies a scaling factor to all resistance and reactance values of network branches. The scaling factor is sampled from a uniform distribution with a range given by <code>[max(0, 1-sigma), 1+sigma)</code>, where <code>sigma</code> is a user-defined adjustable parameter.</p> </li> </ul>"},{"location":"manual/generation_perturbations/","title":"Generation Perturbations","text":""},{"location":"manual/generation_perturbations/#overview","title":"Overview","text":"<p>Generation perturbations introduce random changes to the cost functions of generators. The effect of this is that the cost of operating generators in the grid changes across examples, which allows them to be utilized differently when executing optimal power flow. As a result, examples produced will have more diverse generator setpoints which is beneficial for training ML models to improve generalization. Generation perturbation is applied to the existing topology perturbations.</p> <p>The module provides three options for generation perturbation strategies:</p> <ul> <li> <p><code>NoGenPerturbationGenerator</code> yields the original example without any additional changes in generation cost.</p> </li> <li> <p><code>PermuteGenCostGenerator</code> randomly permutes the generator cost coefficients across and among generator elements.</p> </li> <li> <p><code>PerturbGenCostGenerator</code> applies a scaling factor to all generator cost coefficients. The scaling factor is sampled from a uniform distribution with a range given by <code>[max(0, 1-sigma), 1+sigma)</code>, where <code>sigma</code> is a user-defined adjustable parameter.</p> </li> </ul>"},{"location":"manual/generation_perturbations/#constant-cost-generators","title":"Constant-Cost Generators","text":"<p>Generators with constant-only costs (where <code>c1 = 0</code> and <code>c2 = 0</code>, but <code>c0 \u2260 0</code>) are excluded from perturbation and permutation operations. These generators maintain identical cost coefficients across all scenarios.</p>"},{"location":"manual/getting_started/","title":"Getting Started","text":""},{"location":"manual/getting_started/#option-1-run-data-gen-using-interactive-interface","title":"Option 1: Run data gen using interactive interface","text":"<p>To use the interactive interface, either open <code>scripts/interactive_interface.ipynb</code> or copy the following into a Jupyter notebook and follow the instructions:</p> <pre><code>from gridfm_datakit.interactive import interactive_interface\ninteractive_interface()\n</code></pre>"},{"location":"manual/getting_started/#option-2-using-the-command-line-interface","title":"Option 2: Using the command line interface","text":""},{"location":"manual/getting_started/#generate-data","title":"Generate Data","text":"<p>Run the data generation routine from the command line:</p> <pre><code>gridfm-datakit generate path/to/config.yaml\n</code></pre> <pre><code>\n\n## Configuration Overview\n\nRefer to the sections [Network](network.md), [Load Scenarios](load_scenarios.md), and [Topology perturbations](topology_perturbations.md) for a description of the configuration parameters.\n\nSample configuration files are provided in `scripts/config`, e.g. `default.yaml`:\n\n```yaml\nnetwork:\n  name: \"case24_ieee_rts\" # Name of the power grid network (without extension)\n  source: \"pglib\" # Data source for the grid; options: pglib, file\n  # WARNING: the following parameter is only used if source is \"file\"\n  network_dir: \"scripts/grids\" # if using source \"file\", this is the directory containing the network file (relative to the project root)\n\nload:\n  generator: \"agg_load_profile\" # Name of the load generator; options: agg_load_profile, powergraph\n  agg_profile: \"default\" # Name of the aggregated load profile\n  scenarios: 10000 # Number of different load scenarios to generate\n  # WARNING: the following parameters are only used if generator is \"agg_load_profile\"\n  # if using generator \"powergraph\", these parameters are ignored\n  sigma: 0.2 # max local noise\n  change_reactive_power: true # If true, changes reactive power of loads. If False, keeps the ones from the case file\n  global_range: 0.4 # Range of the global scaling factor. used to set the lower bound of the scaling factor\n  max_scaling_factor: 4.0 # Max upper bound of the global scaling factor\n  step_size: 0.05 # Step size when finding the upper bound of the global scaling factor\n  start_scaling_factor: 0.8 # Initial value of the global scaling factor\n\ntopology_perturbation:\n  type: \"random\" # Type of topology generator; options: n_minus_k, random, none\n  # WARNING: the following parameters are only used if type is not \"none\"\n  k: 2 # Maximum number of components to drop in each perturbation\n  n_topology_variants: 10 # Number of unique perturbed topologies per scenario\n  elements: [branch, gen] # elements to perturb. options: branch, gen\n\ngeneration_perturbation:\n  type: \"cost_permutation\" # Type of generation perturbation; options: cost_permutation, cost_perturbation, none\n  # WARNING: the following parameter is only used if type is \"cost_permutation\"\n  sigma: 1.0 # Size of range used for sampling scaling factor\n\nadmittance_perturbation:\n  type: \"random_perturbation\" # Type of admittance perturbation; options: random_perturbation, none\n  # WARNING: the following parameter is only used if type is \"random_perturbation\"\n  sigma: 0.2 # Size of range used for sampling scaling factor\n\nsettings:\n  num_processes: 10 # Number of parallel processes to use\n  data_dir: \"./data_out\" # Directory to save generated data relative to the project root\n  large_chunk_size: 1000 # Number of load scenarios processed before saving\n  overwrite: true # If true, overwrites existing files, if false, appends to files\n  mode: \"pf\" # Mode of the script; options: pf, opf. pf: power flow data where one or more operating limits \u2013 the inequality constraints defined in OPF, e.g., voltage magnitude or branch limits \u2013 may be violated. opf: generates datapoints for training OPF solvers, with cost-optimal dispatches that satisfy all operating limits (OPF-feasible)\n  include_dc_res: true # If true, also stores the results of dc power flow and dc optimal power flow\n  pf_fast: true # Whether to use fast PF solver by default (compute_ac_pf from powermodels.jl); if false, uses Ipopt-based PF. Some networks e.g. case10000_goc do not work with pf_fast: true\n  dcpf_fast: true # Whether to use fast DC PF solver (compute_dc_pf from powermodels.jl); if false, uses optimizer-based DC PF\n  enable_solver_logs: false # If true, write OPF/PF solver logs to {data_dir}/solver_log; PF fast ignores logging\n\n</code></pre>"},{"location":"manual/getting_started/#choosing-the-right-mode","title":"Choosing the right mode","text":"<p>The <code>mode</code> parameter controls how the power flow scenarios are generated and validated:</p>"},{"location":"manual/getting_started/#optimal-power-flow-mode-mode-opf","title":"Optimal Power Flow Mode (<code>mode: \"opf\"</code>)","text":"<ul> <li>Generation: Solves Optimal Power Flow (OPF) for each perturbed topology</li> <li>Constraints: Enforces all operational constraints (voltage limits, branch loading, generator limits)</li> <li>Example Use Case: Generating data to train a neural optimal power flow solver, or a power flow solver for cases within operating limits.</li> <li>Performance: Slower due to OPF solving for each scenario</li> </ul>"},{"location":"manual/getting_started/#power-flow-mode-mode-pf","title":"Power Flow Mode (<code>mode: \"pf\"</code>)","text":"<ul> <li>Generation: Solves OPF for base topology, then applies topology perturbations and solves Power Flow (without changing the generator setpoints)</li> <li>Constraints: Since the topology perturbations are performed after solving OPF, the inequality constraints of OPF (e.g. branch loading, voltage magnitude at PQ buses, generator bounds on reactive power, etc) might be violated.</li> <li>Use Case: Training data for power flow, contingency analysis, etc</li> <li>Performance: Faster as it avoids re-solving OPF for each perturbed scenario</li> <li>PF Solver Choice: Controlled by <code>settings.pf_fast</code>. If <code>true</code>, uses the fast <code>compute_ac_pf</code> path. If <code>false</code>, uses the Ipopt-based AC PF which is slower for smaller grids but has better convergence properties for large grids.</li> </ul>"},{"location":"manual/getting_started/#data-validation","title":"Data Validation","text":"<p>The generated data can be validated using the CLI validation command:</p> <pre><code># Validate with default sampling (100 partitions of 200 scenarios)\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw\n\n# Validate with custom number of partitions\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw --n-partitions 50\n\n# Validate all partitions (slower but complete)\ngridfm-datakit validate ./data_out/case24_ieee_rts/raw --n-partitions 0\n</code></pre> <p>This automatically detects the generation mode and runs appropriate validation checks:</p> <ul> <li>Physical Consistency: Power balance equations, Y-bus matrix consistency</li> <li>Data Integrity: File completeness, scenario indexing, bus indexing</li> <li>Constraint Validation: Generator limits, branch loading (OPF mode only)</li> <li>Power Flow Accuracy: Computed vs stored power flows</li> </ul>"},{"location":"manual/getting_started/#statistics","title":"Statistics","text":"<p>After generating data, you can compute and visualize statistics:</p> <pre><code># Generate statistics plots\ngridfm-datakit stats ./data_out/case24_ieee_rts/raw\n</code></pre> <p>This generates <code>stats_plot.png</code> showing distributions of: - Network topology metrics (generator/branch counts) - Branch loading and overload statistics - Power balance errors</p> <p>The plots help assess dataset quality and identify scenarios with constraint violations or balance errors.</p> <p>To visualize individual feature distributions across buses, run:</p> <pre><code>gridfm-datakit plots ./data_out/case24_ieee_rts/raw --sn-mva 100\n</code></pre> <p>This command saves violin plots for each feature to <code>feature_plots/</code> (or a custom directory specified with <code>--output-dir</code>).</p> <p></p>"},{"location":"manual/getting_started/#output-files","title":"Output Files","text":"<p>The data generation process writes the following artifacts under: <code>{settings.data_dir}/{network.name}/raw</code></p> <ul> <li>tqdm.log: Progress bar log.</li> <li>error.log: Error messages captured during generation.</li> <li>args.log: YAML dump of the configuration used for this run.</li> <li>scenarios_{generator}.parquet: Load scenarios (per-element time series) produced by the selected load generator.</li> <li>scenarios_{generator}.html: Plot of the generated load scenarios.</li> <li>scenarios_{generator}.log: Generator-specific notes (e.g., bounds for the global scaling factor when using <code>agg_load_profile</code>).</li> <li>bus_data.parquet: Bus-level features for each processed scenario (columns <code>BUS_COLUMNS</code> and, if <code>settings.include_dc_res=True</code>, also <code>DC_BUS_COLUMNS</code>).</li> <li>gen_data.parquet: Generator features per scenario (columns <code>GEN_COLUMNS</code>).</li> <li>branch_data.parquet: Branch features per scenario (columns <code>BRANCH_COLUMNS</code>).</li> <li>y_bus_data.parquet: Nonzero Y-bus entries per scenario with columns <code>[scenario, index1, index2, G, B]</code>.</li> <li>stats.parquet: (if <code>settings.no_stats=False</code>) Aggregated statistics collected during generation.</li> <li>stats_plot.html: (if <code>settings.no_stats=False</code>) HTML dashboard of the aggregated statistics.</li> </ul>"},{"location":"manual/load_scenarios/","title":"Load Scenarios","text":"<p>Load perturbations generate multiple load scenarios from an initial case file scenario. Each scenario consists of active and reactive power values for all loads in the network.</p> <p>The module provides two main perturbation strategies:</p>"},{"location":"manual/load_scenarios/#comparison-of-perturbation-strategies","title":"Comparison of Perturbation Strategies","text":"Feature <code>LoadScenariosFromAggProfile</code> <code>Powergraph</code> Global scaling \u2705 Yes \u2705 Yes Local (per-load) scaling \u2705 Yes (via noise) \u274c No Reactive power perturbed \u2705 Optional \u274c No Interpolation \u2705 Yes \u2705 Yes Use of real profile data \u2705 Yes \u2705 Yes"},{"location":"manual/load_scenarios/#mathematical-models","title":"Mathematical Models","text":"<p>Let:</p> <ul> <li> <p>\\(n\\): Number of loads (\\(i \\in \\{1, \\dots, n\\}\\))</p> </li> <li> <p>\\(K\\): Number of scenarios (\\(k \\in \\{1, \\dots, K\\}\\))</p> </li> <li> <p>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active/reactive loads</p> </li> <li> <p>\\(\\text{agg}^k\\): Aggregated load profile value at time step \\(k\\)</p> </li> <li> <p>\\(u\\): Maximum feasible global scaling factor (from OPF)</p> </li> <li> <p>\\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\): Minimum global scaling factor</p> </li> <li> <p>\\(\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])\\): Scaled aggregate profile</p> </li> <li> <p>\\(\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Active power noise</p> </li> <li> <p>\\(\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Reactive power noise (if enabled)</p> </li> </ul>"},{"location":"manual/load_scenarios/#loadscenariosfromaggprofile","title":"<code>LoadScenariosFromAggProfile</code>","text":"<p>Generates load scenarios by scaling all loads of the grid using a global scaling factor derived from an aggregated load profile, while also applying local (load-level) noise to introduce heterogeneity across buses. Both active and reactive power can be perturbed.</p> <p>The process includes:</p> <ol> <li>Determining an upper bound \\(u\\) for load scaling such that the network still     supports a feasible optimal power flow (OPF) solution.</li> <li>Setting the lower bound \\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\).</li> <li>Min-max scaling the aggregate profile to the interval \\([l, u]\\).</li> <li>Applying this global scaling factor to each load's nominal value with additive uniform noise.</li> </ol> <p>For each load \\(i\\) and scenario \\(k\\): $$ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k $$</p> \\[ \\tilde{q}_i^k = \\begin{cases} q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\ q_i &amp; \\text{otherwise} \\end{cases} \\] <p>Notes</p> <ul> <li> <p>The upper bound <code>u</code> is automatically determined by gradually increasing the base load (doing steps of size <code>step_size</code> and solving the OPF until it fails or reaches <code>max_scaling_factor</code>).</p> </li> <li> <p>The lower bound <code>l</code> is computed as a relative percentage (1-<code>global_range</code>) of <code>u</code>.</p> </li> <li> <p>Noise helps simulate local variability across loads within a global trend.</p> </li> </ul> <p>Sample config parameters:</p> <pre><code>load:\n  generator: \"agg_load_profile\" # Name of the load generator; options: agg_load_profile, powergraph\n  agg_profile: \"default\" # Name of the aggregated load profile\n  scenarios: 200 # Number of different load scenarios to generate\n  sigma: 0.2 # max local noise\n  change_reactive_power: true # If true, changes reactive power of loads. If False, keeps the ones from the case file\n  global_range: 0.4 # Range of the global scaling factor. used to set the lower bound of the scaling factor\n  max_scaling_factor: 4.0 # Max upper bound of the global scaling factor\n  step_size: 0.025 # Step size when finding the upper bound of the global scaling factor\n  start_scaling_factor: 0.8 # Initial value of the global scaling factor\n</code></pre>"},{"location":"manual/load_scenarios/#powergraph","title":"<code>Powergraph</code>","text":"<p>Generates load scenarios by scaling all loads of the grid with a normalized global scaling factor, derived from an aggregated load profile. Only the active power is perturbed; reactive power remains fixed across all scenarios. This follows the implementation of PowerGraph: A power grid benchmark dataset for graph neural networks</p> <p>The reference profile is computed by normalizing an aggregated profile:</p> \\[ \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k} \\] <p>Then, for each bus \\(i\\) and scenario \\(k\\):</p> \\[ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\] <p>and reactive power is kept constant:</p> \\[ \\tilde{q}_i^k = q_i \\] <p>Sample config parameters:</p> <pre><code>load:\n  generator: \"powergraph\"\n  agg_profile: \"default\"           # Aggregated load profile name\n  scenarios: 200                   # Number of load scenarios to generate\n</code></pre>"},{"location":"manual/load_scenarios/#aggregated-load-profiles","title":"Aggregated load profiles","text":"<p>The following load profiles are available in the <code>gridfm-datakit/load_profiles</code> directory:</p> <ul> <li> <p><code>default.csv</code>: Default load profile.</p> </li> <li> <p>ERCOT load profiles:</p> <ul> <li><code>ercot_load_act_hr_2024_west.csv</code>: ERCOT load profile for the West region.</li> <li><code>ercot_load_act_hr_2024_south_central.csv</code>: ERCOT load profile for the South Central region.</li> <li><code>ercot_load_act_hr_2024_southern.csv</code>: ERCOT load profile for the Southern region.</li> <li><code>ercot_load_act_hr_2024_total.csv</code>: Total ERCOT load profile.</li> <li><code>ercot_load_act_hr_2024_far_west.csv</code>: ERCOT load profile for the Far West region.</li> <li><code>ercot_load_act_hr_2024_north.csv</code>: ERCOT load profile for the North region.</li> <li><code>ercot_load_act_hr_2024_north_central.csv</code>: ERCOT load profile for the North Central region.</li> <li><code>ercot_load_act_hr_2024_coast.csv</code>: ERCOT load profile for the Coast region.</li> <li><code>ercot_load_act_hr_2024_east.csv</code>: ERCOT load profile for the East region.</li> </ul> </li> </ul>"},{"location":"manual/network/","title":"Network","text":"<p>The network parameters are the following:</p> <pre><code>network:\n  name: \"case24_ieee_rts\" # Name of the power grid network (without extension)\n  source: \"pglib\" # Data source for the grid; options: pglib, file\n  network_dir: \"scripts/grids\" # if using source \"file\", this is the directory containing the network file (relative to the project root)\n\n</code></pre> <p>Networks can be loaded from two different sources, specified in `source:</p>"},{"location":"manual/network/#pglib-repository-recommended","title":"PGLib repository (recommended)","text":"<p>e.g.</p> <pre><code>network:\n  source: \"pglib\"\n  name: \"case24_ieee_rts\"   # Name of the power grid network **without the pglib prefix**\n</code></pre>"},{"location":"manual/network/#local-matpower-files","title":"Local MATPOWER files","text":"<p>e.g.</p> <pre><code>network:\n  source: \"file\"\n  name: \"Texas2k_case1_2016summerpeak\"  # Name of the power grid network **without .m extension**\n  network_dir: \"scripts/grids\"          # Directory containing the network files\n</code></pre>"},{"location":"manual/outputs/","title":"Outputs","text":"<p>This page provides a detailed description of the output files generated by the data generation process. All files are saved under <code>{settings.data_dir}/{network.name}/raw</code>.</p>"},{"location":"manual/outputs/#output-files","title":"Output Files","text":""},{"location":"manual/outputs/#log-files","title":"Log Files","text":""},{"location":"manual/outputs/#tqdmlog","title":"<code>tqdm.log</code>","text":"<p>Progress bar log showing the execution progress of the data generation process.</p>"},{"location":"manual/outputs/#errorlog","title":"<code>error.log</code>","text":"<p>Error messages captured during generation.</p>"},{"location":"manual/outputs/#argslog","title":"<code>args.log</code>","text":"<p>YAML dump of the configuration used for this run.</p>"},{"location":"manual/outputs/#load-scenario-files","title":"Load Scenario Files","text":""},{"location":"manual/outputs/#scenarios_generatorparquet","title":"<code>scenarios_{generator}.parquet</code>","text":"<p>Load scenarios (per-element time series) produced by the selected load generator.</p>"},{"location":"manual/outputs/#scenarios_generatorhtml","title":"<code>scenarios_{generator}.html</code>","text":"<p>Plot of the generated load scenarios.</p>"},{"location":"manual/outputs/#scenarios_generatorlog","title":"<code>scenarios_{generator}.log</code>","text":"<p>Generator-specific notes (e.g., bounds for the global scaling factor when using <code>agg_load_profile</code>).</p>"},{"location":"manual/outputs/#n_scenariostxt","title":"<code>n_scenarios.txt</code>","text":"<p>Metadata file containing the total number of scenarios (used for efficient partition management).</p>"},{"location":"manual/outputs/#network-data-files","title":"Network Data Files","text":"<p>Note: All network data files are saved as partitioned parquet directories. Each file includes a <code>scenario_partition</code> column used for partitioning, which groups scenarios into partitions (default: 200 scenarios per partition).</p>"},{"location":"manual/outputs/#bus_dataparquet","title":"<code>bus_data.parquet</code>","text":"<p>Bus-level features for each processed scenario. Columns:</p> <ul> <li>scenario: Global scenario index (unique identifier)</li> <li>load_scenario_idx: Index of the load scenario</li> <li>bus: Index of the bus</li> <li>Pd: Active power demand at the bus (MW)</li> <li>Qd: Reactive power demand at the bus (MVAr)</li> <li>Pg: Active power generation at the bus (MW)</li> <li>Qg: Reactive power generation at the bus (MVAr)</li> <li>Vm: Voltage magnitude at the bus (p.u.)</li> <li>Va: Voltage angle at the bus (degrees)</li> <li>PQ: Indicates if the bus is a PQ bus (1 if true, 0 if false)</li> <li>PV: Indicates if the bus is a PV bus (1 if true, 0 if false)</li> <li>REF: Indicates if the bus is a reference bus (1 if true, 0 if false)</li> <li>vn_kv: Nominal voltage level at the bus (kV)</li> <li>min_vm_pu: Minimum voltage magnitude limit (p.u.)</li> <li>max_vm_pu: Maximum voltage magnitude limit (p.u.)</li> <li>GS: Shunt conductance at the bus (p.u. at V = 1.0 p.u.)</li> <li>BS: Shunt susceptance at the bus (p.u. at V = 1.0 p.u.)</li> </ul> <p>If <code>settings.include_dc_res=True</code>, also includes DC power flow columns (DC_BUS_COLUMNS): - Va_dc: DC voltage angle (degrees) - Pg_dc: DC active power generation at the bus (MW)</p>"},{"location":"manual/outputs/#gen_dataparquet","title":"<code>gen_data.parquet</code>","text":"<p>Generator features per scenario. Columns:</p> <ul> <li>scenario: Global scenario index (unique identifier)</li> <li>load_scenario_idx: Index of the load scenario</li> <li>idx: Generator row index (0-based)</li> <li>bus: Bus index where the generator is connected</li> <li>p_mw: Active power output (MW)</li> <li>q_mvar: Reactive power output (MVAr)</li> <li>min_p_mw: Minimum active power limit (MW)</li> <li>max_p_mw: Maximum active power limit (MW)</li> <li>min_q_mvar: Minimum reactive power limit (MVAr)</li> <li>max_q_mvar: Maximum reactive power limit (MVAr)</li> <li>cp0_eur: Constant cost coefficient (EUR)</li> <li>cp1_eur_per_mw: Linear cost coefficient (EUR/MW)</li> <li>cp2_eur_per_mw2: Quadratic cost coefficient (EUR/MW\u00b2)</li> <li>in_service: 1 if generator is in service, else 0</li> <li>is_slack_gen: 1 if generator is at the reference bus, else 0</li> </ul> <p>If <code>settings.include_dc_res=True</code>, also includes DC generator column (DC_GEN_COLUMNS): - p_mw_dc: Active power from DC solution (MW)</p>"},{"location":"manual/outputs/#branch_dataparquet","title":"<code>branch_data.parquet</code>","text":"<p>Branch features per scenario. Columns:</p> <ul> <li>scenario: Global scenario index (unique identifier)</li> <li>load_scenario_idx: Index of the load scenario</li> <li>idx: Branch row index (0-based)</li> <li>from_bus: Index of the source bus</li> <li>to_bus: Index of the destination bus</li> <li>pf: Active power flow from source to destination (MW)</li> <li>qf: Reactive power flow from source to destination (MVAr)</li> <li>pt: Active power flow from destination to source (MW)</li> <li>qt: Reactive power flow from destination to source (MVAr)</li> <li>r: Series resistance (p.u.)</li> <li>x: Series reactance (p.u.)</li> <li>b: Total line charging susceptance (p.u.)</li> <li>Yff_r: Real part of the self-admittance at the source bus (p.u.)</li> <li>Yff_i: Imaginary part of the self-admittance at the source bus (p.u.)</li> <li>Yft_r: Real part of the mutual admittance from source to destination bus (p.u.)</li> <li>Yft_i: Imaginary part of the mutual admittance from source to destination bus (p.u.)</li> <li>Ytf_r: Real part of the mutual admittance from destination to source bus (p.u.)</li> <li>Ytf_i: Imaginary part of the mutual admittance from destination to source bus (p.u.)</li> <li>Ytt_r: Real part of the self-admittance at the destination bus (p.u.)</li> <li>Ytt_i: Imaginary part of the self-admittance at the destination bus (p.u.)</li> <li>tap: Transformer tap ratio</li> <li>shift: Phase shift (degrees)</li> <li>ang_min: Minimum angle limit (degrees)</li> <li>ang_max: Maximum angle limit (degrees)</li> <li>rate_a: Rate limit of the branch (MVA)</li> <li>br_status: Branch status (1 if in service, 0 if out of service)</li> </ul> <p>If <code>settings.include_dc_res=True</code>, also includes DC branch columns (DC_BRANCH_COLUMNS): - pf_dc: DC active power flow from source to destination (MW) - pt_dc: DC active power flow from destination to source (MW)</p>"},{"location":"manual/outputs/#y_bus_dataparquet","title":"<code>y_bus_data.parquet</code>","text":"<p>Nonzero Y-bus entries per scenario. Columns:</p> <ul> <li>scenario: Global scenario index (unique identifier)</li> <li>load_scenario_idx: Index of the load scenario</li> <li>index1: Row index in the Y-bus matrix</li> <li>index2: Column index in the Y-bus matrix</li> <li>G: Conductance value (p.u.)</li> <li>B: Susceptance value (p.u.)</li> </ul>"},{"location":"manual/outputs/#runtime-data-files","title":"Runtime Data Files","text":""},{"location":"manual/outputs/#runtime_dataparquet","title":"<code>runtime_data.parquet</code>","text":"<p>Runtime data for each scenario. Columns:</p> <ul> <li>scenario: Global scenario index (unique identifier)</li> <li>load_scenario_idx: Index of the load scenario</li> <li>ac: AC solver execution time (seconds)</li> </ul> <p>If <code>settings.include_dc_res=True</code>, also includes DC runtime column (DC_RUNTIME_COLUMNS): - dc: DC solver execution time (seconds)</p>"},{"location":"manual/outputs/#statistics-files","title":"Statistics Files","text":""},{"location":"manual/outputs/#statsparquet","title":"<code>stats.parquet</code>","text":"<p>Aggregated statistics collected during generation (if <code>settings.no_stats=False</code>), including metrics such as:</p> <ul> <li>Number of generators</li> <li>Number of lines and transformers</li> <li>Number of overloads</li> <li>Maximum loading values</li> <li>Other network performance metrics</li> </ul>"},{"location":"manual/outputs/#stats_plotpng","title":"<code>stats_plot.png</code>","text":"<p>Visualization of the aggregated statistics (if <code>settings.no_stats=False</code>).</p>"},{"location":"manual/outputs/#feature-visualization","title":"Feature Visualization","text":"<p>Feature distribution plots can be generated using the CLI command:</p> <pre><code>gridfm-datakit plots path/to/data/directory\n</code></pre> <p>This creates a <code>feature_plots/</code> directory with violin plots per feature named <code>distribution_{feature_name}.png</code>.</p>"},{"location":"manual/topology_perturbations/","title":"Topology Perturbations","text":""},{"location":"manual/topology_perturbations/#overview","title":"Overview","text":"<p>Topology perturbations generate variations of the original network by altering its topology. These variations simulate contingencies and component failures, and are useful for robustness testing, contingency analysis, and training ML models on diverse grid conditions.</p> <p>The module provides three topology perturbation strategies:</p> <ul> <li> <p><code>NoPerturbationGenerator</code> yields the original topology without changes. It is useful for baseline comparisons and debugging.</p> </li> <li> <p><code>NMinusKGenerator</code> generates all possible combinations of up to k components (lines and transformers) being out of service. Only feasible topologies with no unsupplied buses are returned.</p> </li> <li> <p><code>RandomComponentDropGenerator</code> randomly generates a specified number of feasible topologies by disabling up to k randomly selected components, including lines, transformers, generators, and static generators.</p> </li> </ul>"},{"location":"manual/topology_perturbations/#comparison-of-perturbation-strategies","title":"Comparison of Perturbation Strategies","text":"Feature <code>NoPerturbationGenerator</code> <code>NMinusKGenerator</code> <code>RandomComponentDropGenerator</code> Number of topologies 1 (original) All feasible (up to k elements lost) User-defined Component types supported \u2013 Lines, Transformers Lines, Transformers, Gens, Sgens Randomized generation \u274c No \u274c No \u2705 Yes"}]}