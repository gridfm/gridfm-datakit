{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"gridfm-datakit","text":"<p>This library is brought to you by the GridFM team to generate power flow data to train machine learning and foundation models.</p>"},{"location":"#workflow","title":"Workflow","text":""},{"location":"#comparison-with-other-pf-datasets-libraries","title":"Comparison with other PF datasets/ libraries","text":"Feature Graph Neural Solver [1] OPFData [2] OPFLearn [3] PowerFlowNet [4] TypedGNN [5] PF\u25b3 [6] PGLearn [7] gridfm-datakit [8] Generator Profile\u2705\u274c\u274c\u2705\u2705\u2705\u274c\u2705 N-1\u274c\u2705\u274c\u274c\u2705\u2705\u2705\u2705 &gt; 1000 Buses\u274c\u2705\u2705\u274c\u274c\u2705\u2705\u2705 N-k, k &gt; 1\u274c\u274c\u274c\u274c\u274c\u274c\u274c\u2705 Load Scenarios from Real World\u274c\u274c\u274c\u274c\u274c\u274c\u274c\u2705 Net Param Perturbation\u2705\u274c\u274c\u2705\u2705\u274c\u274c\u2705 Scalable to 1M+\u274c\u274c\u274c\u274c\u274c\u274c\u2705\u2705"},{"location":"installation/","title":"Installation","text":"<ol> <li> <p>\u2b50 Star the repository on GitHub to support the project!</p> </li> <li> <p>Run:</p> </li> </ol> <pre><code>python -m pip install --upgrade pip  # Upgrade pip\npip install gridfm-datakit\n</code></pre>"},{"location":"installation/#for-developers","title":"For Developers","text":"<p>To install the latest development version from github, simply follow these steps:</p> <pre><code>git clone https://github.com/gridfm/gridfm-datakit.git\ncd \"gridfm-datakit\"\npython3 -m venv venv\nsource venv/bin/activate\npython -m pip install --upgrade pip  # Upgrade pip to ensure compatibility with pyproject.toml\npip3 install -e '.[test,dev]'\n</code></pre>"},{"location":"components/cli/","title":"CLI","text":"<p>This module provides a command-line interface for generating power flow data.</p>"},{"location":"components/cli/#main","title":"<code>main</code>","text":"<p>Command-line interface for the data generation script.</p> Source code in <code>gridfm_datakit/cli.py</code> <pre><code>def main():\n    \"\"\"Command-line interface for the data generation script.\"\"\"\n    parser = argparse.ArgumentParser(\n        description=\"Generate power flow data for grid analysis\",\n    )\n\n    parser.add_argument(\n        \"config\",\n        type=str,\n        help=\"Path to config file\",\n    )\n\n    args = parser.parse_args()\n    file_paths = generate_power_flow_data_distributed(args.config)\n\n    print(\"\\nData generation complete.\")\n    print(\"Generated files:\")\n    for key, path in file_paths.items():\n        print(f\"- {key}: {path}\")\n</code></pre>"},{"location":"components/generate/","title":"Generate","text":"<p>This module provides functions for generating power flow data.</p>"},{"location":"components/generate/#_setup_environment","title":"<code>_setup_environment</code>","text":"<p>Setup the environment for data generation.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict, NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace)</p> required <p>Returns:</p> Type Description <code>Tuple[NestedNamespace, str, Dict[str, str]]</code> <p>Tuple of (args, base_path, file_paths)</p> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _setup_environment(\n    config: Union[str, Dict, NestedNamespace],\n) -&gt; Tuple[NestedNamespace, str, Dict[str, str]]:\n    \"\"\"Setup the environment for data generation.\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n\n    Returns:\n        Tuple of (args, base_path, file_paths)\n    \"\"\"\n    # Load config from file if a path is provided\n    if isinstance(config, str):\n        with open(config, \"r\") as f:\n            config = yaml.safe_load(f)\n\n    # Convert dict to NestedNamespace if needed\n    if isinstance(config, dict):\n        args = NestedNamespace(**config)\n    else:\n        args = config\n\n    # Setup output directory\n    base_path = os.path.join(args.settings.data_dir, args.network.name, \"raw\")\n    if os.path.exists(base_path) and args.settings.overwrite:\n        shutil.rmtree(base_path)\n    os.makedirs(base_path, exist_ok=True)\n\n    # Setup file paths\n    file_paths = {\n        \"tqdm_log\": os.path.join(base_path, \"tqdm.log\"),\n        \"error_log\": os.path.join(base_path, \"error.log\"),\n        \"args_log\": os.path.join(base_path, \"args.log\"),\n        \"node_data\": os.path.join(base_path, \"pf_node.csv\"),\n        \"edge_data\": os.path.join(base_path, \"pf_edge.csv\"),\n        \"branch_indices\": os.path.join(base_path, \"branch_idx_removed.csv\"),\n        \"edge_params\": os.path.join(base_path, \"edge_params.csv\"),\n        \"bus_params\": os.path.join(base_path, \"bus_params.csv\"),\n        \"scenarios\": os.path.join(base_path, f\"scenarios_{args.load.generator}.csv\"),\n        \"scenarios_plot\": os.path.join(\n            base_path,\n            f\"scenarios_{args.load.generator}.html\",\n        ),\n        \"scenarios_log\": os.path.join(\n            base_path,\n            f\"scenarios_{args.load.generator}.log\",\n        ),\n        \"feature_plots\": os.path.join(base_path, \"feature_plots\"),\n    }\n\n    # Initialize logs\n    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n    for log_file in [\n        file_paths[\"tqdm_log\"],\n        file_paths[\"error_log\"],\n        file_paths[\"scenarios_log\"],\n        file_paths[\"args_log\"],\n    ]:\n        with open(log_file, \"a\") as f:\n            f.write(f\"\\nNew generation started at {timestamp}\\n\")\n            if log_file == file_paths[\"args_log\"]:\n                yaml.dump(config if isinstance(config, dict) else vars(config), f)\n\n    return args, base_path, file_paths\n</code></pre>"},{"location":"components/generate/#_prepare_network_and_scenarios","title":"<code>_prepare_network_and_scenarios</code>","text":"<p>Prepare the network and generate load scenarios.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration object</p> required <code>file_paths</code> <code>Dict[str, str]</code> <p>Dictionary of file paths</p> required <p>Returns:</p> Type Description <code>Tuple[pandapowerNet, Any]</code> <p>Tuple of (network, scenarios)</p> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _prepare_network_and_scenarios(\n    args: NestedNamespace,\n    file_paths: Dict[str, str],\n) -&gt; Tuple[pandapowerNet, Any]:\n    \"\"\"Prepare the network and generate load scenarios.\n\n    Args:\n        args: Configuration object\n        file_paths: Dictionary of file paths\n\n    Returns:\n        Tuple of (network, scenarios)\n    \"\"\"\n    # Load network\n    if args.network.source == \"pandapower\":\n        net = load_net_from_pp(args.network.name)\n    elif args.network.source == \"pglib\":\n        net = load_net_from_pglib(args.network.name)\n    elif args.network.source == \"file\":\n        net = load_net_from_file(\n            os.path.join(args.network.network_dir, args.network.name) + \".m\",\n        )\n    else:\n        raise ValueError(\"Invalid grid source!\")\n\n    network_preprocessing(net)\n    assert (net.sgen[\"scaling\"] == 1).all(), \"Scaling factor &gt;1 not supported yet!\"\n\n    # Generate load scenarios\n    load_scenario_generator = get_load_scenario_generator(args.load)\n    scenarios = load_scenario_generator(\n        net,\n        args.load.scenarios,\n        file_paths[\"scenarios_log\"],\n    )\n    scenarios_df = load_scenarios_to_df(scenarios)\n    scenarios_df.to_csv(file_paths[\"scenarios\"], index=False)\n    plot_load_scenarios_combined(scenarios_df, file_paths[\"scenarios_plot\"])\n    save_edge_params(net, file_paths[\"edge_params\"])\n    save_bus_params(net, file_paths[\"bus_params\"])\n\n    return net, scenarios\n</code></pre>"},{"location":"components/generate/#_save_generated_data","title":"<code>_save_generated_data</code>","text":"<p>Save the generated data to files.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>Pandapower network</p> required <code>csv_data</code> <code>List</code> <p>List of CSV data</p> required <code>adjacency_lists</code> <code>List</code> <p>List of adjacency lists</p> required <code>branch_idx_removed</code> <code>List</code> <p>List of removed branch indices</p> required <code>global_stats</code> <code>Optional[Stats]</code> <p>Optional statistics object</p> required <code>file_paths</code> <code>Dict[str, str]</code> <p>Dictionary of file paths</p> required <code>base_path</code> <code>str</code> <p>Base output directory</p> required <code>args</code> <code>NestedNamespace</code> <p>Configuration object</p> required Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def _save_generated_data(\n    net: pandapowerNet,\n    csv_data: List,\n    adjacency_lists: List,\n    branch_idx_removed: List,\n    global_stats: Optional[Stats],\n    file_paths: Dict[str, str],\n    base_path: str,\n    args: NestedNamespace,\n) -&gt; None:\n    \"\"\"Save the generated data to files.\n\n    Args:\n        net: Pandapower network\n        csv_data: List of CSV data\n        adjacency_lists: List of adjacency lists\n        branch_idx_removed: List of removed branch indices\n        global_stats: Optional statistics object\n        file_paths: Dictionary of file paths\n        base_path: Base output directory\n        args: Configuration object\n    \"\"\"\n    if len(adjacency_lists) &gt; 0:\n        save_node_edge_data(\n            net,\n            file_paths[\"node_data\"],\n            file_paths[\"edge_data\"],\n            csv_data,\n            adjacency_lists,\n            mode=args.settings.mode,\n        )\n        save_branch_idx_removed(branch_idx_removed, file_paths[\"branch_indices\"])\n        if not args.settings.no_stats and global_stats:\n            global_stats.save(base_path)\n            plot_stats(base_path)\n</code></pre>"},{"location":"components/generate/#generate_power_flow_data","title":"<code>generate_power_flow_data</code>","text":"<p>Generate power flow data based on the provided configuration using sequential processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict, NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace) The config must include settings, network, load, and topology_perturbation configurations.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary containing paths to generated files:</p> <code>Dict[str, str]</code> <p>{ 'node_data': path to node data CSV, 'edge_data': path to edge data CSV, 'branch_indices': path to branch indices CSV, 'edge_params': path to edge parameters CSV, 'bus_params': path to bus parameters CSV, 'scenarios': path to scenarios CSV, 'scenarios_plot': path to scenarios plot HTML, 'scenarios_log': path to scenarios log</p> <code>Dict[str, str]</code> <p>}</p> Note <p>The function creates several output files in the specified data directory:</p> <ul> <li>tqdm.log: Progress tracking</li> <li>error.log: Error messages</li> <li>args.log: Configuration parameters</li> <li>pf_node.csv: Node data</li> <li>pf_edge.csv: Edge data</li> <li>branch_idx_removed.csv: Removed branch indices</li> <li>edge_params.csv: Edge parameters</li> <li>bus_params.csv: Bus parameters</li> <li>scenarios_{generator}.csv: Load scenarios</li> <li>scenarios_{generator}.html: Scenario plots</li> <li>scenarios_{generator}.log: Scenario generation log</li> </ul> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def generate_power_flow_data(\n    config: Union[str, Dict, NestedNamespace],\n) -&gt; Dict[str, str]:\n    \"\"\"Generate power flow data based on the provided configuration using sequential processing.\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n            The config must include settings, network, load, and topology_perturbation configurations.\n\n    Returns:\n        Dictionary containing paths to generated files:\n        {\n            'node_data': path to node data CSV,\n            'edge_data': path to edge data CSV,\n            'branch_indices': path to branch indices CSV,\n            'edge_params': path to edge parameters CSV,\n            'bus_params': path to bus parameters CSV,\n            'scenarios': path to scenarios CSV,\n            'scenarios_plot': path to scenarios plot HTML,\n            'scenarios_log': path to scenarios log\n        }\n\n    Note:\n        The function creates several output files in the specified data directory:\n\n        - tqdm.log: Progress tracking\n        - error.log: Error messages\n        - args.log: Configuration parameters\n        - pf_node.csv: Node data\n        - pf_edge.csv: Edge data\n        - branch_idx_removed.csv: Removed branch indices\n        - edge_params.csv: Edge parameters\n        - bus_params.csv: Bus parameters\n        - scenarios_{generator}.csv: Load scenarios\n        - scenarios_{generator}.html: Scenario plots\n        - scenarios_{generator}.log: Scenario generation log\n    \"\"\"\n    # Setup environment\n    args, base_path, file_paths = _setup_environment(config)\n\n    # Prepare network and scenarios\n    net, scenarios = _prepare_network_and_scenarios(args, file_paths)\n\n    # Initialize topology generator\n    topology_generator = initialize_topology_generator(args.topology_perturbation, net)\n\n    # Initialize generation generator\n    generation_generator = initialize_generation_generator(\n        args.generation_perturbation,\n        net,\n    )\n\n    # Initialize admittance generator\n    admittance_generator = initialize_admittance_generator(\n        args.admittance_perturbation,\n        net,\n    )\n\n    csv_data = []\n    adjacency_lists = []\n    branch_idx_removed = []\n    global_stats = Stats() if not args.settings.no_stats else None\n\n    # Process scenarios sequentially\n    with open(file_paths[\"tqdm_log\"], \"a\") as f:\n        with tqdm(\n            total=args.load.scenarios,\n            desc=\"Processing scenarios\",\n            file=Tee(sys.stdout, f),\n            miniters=5,\n        ) as pbar:\n            for scenario_index in range(args.load.scenarios):\n                # Process the scenario\n                if args.settings.mode == \"pf\":\n                    csv_data, adjacency_lists, branch_idx_removed, global_stats = (\n                        process_scenario(\n                            net,\n                            scenarios,\n                            scenario_index,\n                            topology_generator,\n                            generation_generator,\n                            admittance_generator,\n                            args.settings.no_stats,\n                            csv_data,\n                            adjacency_lists,\n                            branch_idx_removed,\n                            global_stats,\n                            file_paths[\"error_log\"],\n                        )\n                    )\n                elif args.settings.mode == \"contingency\":\n                    csv_data, adjacency_lists, branch_idx_removed, global_stats = (\n                        process_scenario_contingency(\n                            net,\n                            scenarios,\n                            scenario_index,\n                            topology_generator,\n                            generation_generator,\n                            admittance_generator,\n                            args.settings.no_stats,\n                            csv_data,\n                            adjacency_lists,\n                            branch_idx_removed,\n                            global_stats,\n                            file_paths[\"error_log\"],\n                        )\n                    )\n\n                pbar.update(1)\n\n    # Save final data\n    _save_generated_data(\n        net,\n        csv_data,\n        adjacency_lists,\n        branch_idx_removed,\n        global_stats,\n        file_paths,\n        base_path,\n        args,\n    )\n    # Plot features\n    if os.path.exists(file_paths[\"node_data\"]):\n        plot_feature_distributions(\n            file_paths[\"node_data\"],\n            file_paths[\"feature_plots\"],\n            net.sn_mva,\n        )\n    else:\n        print(\"No node data file generated. Skipping feature plotting.\")\n\n    return file_paths\n</code></pre>"},{"location":"components/generate/#generate_power_flow_data_distributed","title":"<code>generate_power_flow_data_distributed</code>","text":"<p>Generate power flow data based on the provided configuration using distributed processing.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Union[str, Dict, NestedNamespace]</code> <p>Configuration can be provided in three ways: 1. Path to a YAML config file (str) 2. Configuration dictionary (Dict) 3. NestedNamespace object (NestedNamespace) The config must include settings, network, load, and topology_perturbation configurations.</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dictionary containing paths to generated files:</p> <code>Dict[str, str]</code> <p>{ 'node_data': path to node data CSV, 'edge_data': path to edge data CSV, 'branch_indices': path to branch indices CSV, 'edge_params': path to edge parameters CSV, 'bus_params': path to bus parameters CSV, 'scenarios': path to scenarios CSV, 'scenarios_plot': path to scenarios plot HTML, 'scenarios_log': path to scenarios log</p> <code>Dict[str, str]</code> <p>}</p> Note <p>The function creates several output files in the specified data directory:</p> <ul> <li>tqdm.log: Progress tracking</li> <li>error.log: Error messages</li> <li>args.log: Configuration parameters</li> <li>pf_node.csv: Node data</li> <li>pf_edge.csv: Edge data</li> <li>branch_idx_removed.csv: Removed branch indices</li> <li>edge_params.csv: Edge parameters</li> <li>bus_params.csv: Bus parameters</li> <li>scenarios_{generator}.csv: Load scenarios</li> <li>scenarios_{generator}.html: Scenario plots</li> <li>scenarios_{generator}.log: Scenario generation log</li> </ul> Source code in <code>gridfm_datakit/generate.py</code> <pre><code>def generate_power_flow_data_distributed(\n    config: Union[str, Dict, NestedNamespace],\n) -&gt; Dict[str, str]:\n    \"\"\"Generate power flow data based on the provided configuration using distributed processing.\n\n\n    Args:\n        config: Configuration can be provided in three ways:\n            1. Path to a YAML config file (str)\n            2. Configuration dictionary (Dict)\n            3. NestedNamespace object (NestedNamespace)\n            The config must include settings, network, load, and topology_perturbation configurations.\n\n    Returns:\n        Dictionary containing paths to generated files:\n        {\n            'node_data': path to node data CSV,\n            'edge_data': path to edge data CSV,\n            'branch_indices': path to branch indices CSV,\n            'edge_params': path to edge parameters CSV,\n            'bus_params': path to bus parameters CSV,\n            'scenarios': path to scenarios CSV,\n            'scenarios_plot': path to scenarios plot HTML,\n            'scenarios_log': path to scenarios log\n        }\n\n    Note:\n        The function creates several output files in the specified data directory:\n\n        - tqdm.log: Progress tracking\n        - error.log: Error messages\n        - args.log: Configuration parameters\n        - pf_node.csv: Node data\n        - pf_edge.csv: Edge data\n        - branch_idx_removed.csv: Removed branch indices\n        - edge_params.csv: Edge parameters\n        - bus_params.csv: Bus parameters\n        - scenarios_{generator}.csv: Load scenarios\n        - scenarios_{generator}.html: Scenario plots\n        - scenarios_{generator}.log: Scenario generation log\n    \"\"\"\n    # Setup environment\n    args, base_path, file_paths = _setup_environment(config)\n\n    # Prepare network and scenarios\n    net, scenarios = _prepare_network_and_scenarios(args, file_paths)\n\n    # Initialize topology generator\n    topology_generator = initialize_topology_generator(args.topology_perturbation, net)\n\n    # Initialize generation generator\n    generation_generator = initialize_generation_generator(\n        args.generation_perturbation,\n        net,\n    )\n\n    # Initialize admittance generator\n    admittance_generator = initialize_admittance_generator(\n        args.admittance_perturbation,\n        net,\n    )\n\n    # Setup multiprocessing\n    manager = Manager()\n    progress_queue = manager.Queue()\n\n    # Process scenarios in chunks\n    large_chunks = np.array_split(\n        range(args.load.scenarios),\n        np.ceil(args.load.scenarios / args.settings.large_chunk_size).astype(int),\n    )\n\n    with open(file_paths[\"tqdm_log\"], \"a\") as f:\n        with tqdm(\n            total=args.load.scenarios,\n            desc=\"Processing scenarios\",\n            file=Tee(sys.stdout, f),\n            miniters=5,\n        ) as pbar:\n            for large_chunk_index, large_chunk in enumerate(large_chunks):\n                write_ram_usage_distributed(f)\n                chunk_size = len(large_chunk)\n                scenario_chunks = np.array_split(\n                    large_chunk,\n                    args.settings.num_processes,\n                )\n\n                tasks = [\n                    (\n                        args.settings.mode,\n                        chunk[0],\n                        chunk[-1] + 1,\n                        scenarios,\n                        net,\n                        progress_queue,\n                        topology_generator,\n                        generation_generator,\n                        admittance_generator,\n                        args.settings.no_stats,\n                        file_paths[\"error_log\"],\n                    )\n                    for chunk in scenario_chunks\n                ]\n\n                # Run parallel processing\n                with Pool(processes=args.settings.num_processes) as pool:\n                    results = [\n                        pool.apply_async(process_scenario_chunk, task) for task in tasks\n                    ]\n\n                    # Update progress\n                    completed = 0\n                    while completed &lt; chunk_size:\n                        progress_queue.get()\n                        pbar.update(1)\n                        completed += 1\n\n                    # Gather results\n                    csv_data = []\n                    adjacency_lists = []\n                    branch_idx_removed = []\n                    global_stats = Stats() if not args.settings.no_stats else None\n\n                    for result in results:\n                        (\n                            e,\n                            traceback,\n                            local_csv_data,\n                            local_adjacency_lists,\n                            local_branch_idx_removed,\n                            local_stats,\n                        ) = result.get()\n                        if isinstance(e, Exception):\n                            print(f\"Error in process_scenario_chunk: {e}\")\n                            print(traceback)\n                            sys.exit(1)\n                        csv_data.extend(local_csv_data)\n                        adjacency_lists.extend(local_adjacency_lists)\n                        branch_idx_removed.extend(local_branch_idx_removed)\n                        if not args.settings.no_stats and local_stats:\n                            global_stats.merge(local_stats)\n\n                    pool.close()\n                    pool.join()\n\n                # Save processed data\n                _save_generated_data(\n                    net,\n                    csv_data,\n                    adjacency_lists,\n                    branch_idx_removed,\n                    global_stats,\n                    file_paths,\n                    base_path,\n                    args,\n                )\n\n                del csv_data, adjacency_lists, global_stats\n                gc.collect()\n\n    # Plot features\n    # check if node_data csv file exists\n    if os.path.exists(file_paths[\"node_data\"]):\n        plot_feature_distributions(\n            file_paths[\"node_data\"],\n            file_paths[\"feature_plots\"],\n            net.sn_mva,\n        )\n    else:\n        print(\"No node data file generated. Skipping feature plotting.\")\n\n    return file_paths\n</code></pre>"},{"location":"components/load/","title":"Load Perturbations","text":"<p>This module provides functions and classes for generating load scenarios.</p>"},{"location":"components/load/#classes","title":"Classes","text":""},{"location":"components/load/#loadscenariogeneratorbase","title":"<code>LoadScenarioGeneratorBase</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for load scenario generators.</p> <p>This class defines the interface and common functionality for generating load scenarios for power grid networks.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class LoadScenarioGeneratorBase(ABC):\n    \"\"\"Abstract base class for load scenario generators.\n\n    This class defines the interface and common functionality for generating\n    load scenarios for power grid networks.\n    \"\"\"\n\n    @abstractmethod\n    def __call__(\n        self,\n        net: pandapowerNet,\n        n_scenarios: int,\n        scenario_log: str,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load scenarios for a power network.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenario_log: Path to log file for scenario generation details.\n\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n        \"\"\"\n        pass\n\n    @staticmethod\n    def interpolate_row(row: np.ndarray, data_points: int) -&gt; np.ndarray:\n        \"\"\"Interpolates a row of data to match the desired number of data points.\n\n        Args:\n            row: Input data array to interpolate.\n            data_points: Number of points in the output array.\n\n        Returns:\n            numpy.ndarray: Interpolated data array of length data_points.\n        \"\"\"\n        if np.all(row == 0):\n            return np.zeros(data_points)\n        x_original = np.linspace(1, len(row), len(row))\n        x_target = np.linspace(1, len(row), data_points)\n        return interp1d(x_original, row, kind=\"linear\")(x_target)\n\n    @staticmethod\n    def find_largest_scaling_factor(\n        net: pandapowerNet,\n        max_scaling: float,\n        step_size: float,\n        start: float,\n        change_reactive_power: bool,\n    ) -&gt; float:\n        \"\"\"Finds the largest load scaling factor that maintains OPF convergence.\n\n        Args:\n            net: The power network.\n            max_scaling: Maximum scaling factor to try.\n            step_size: Increment for scaling factor search.\n            start: Starting scaling factor.\n            change_reactive_power: Whether to scale reactive power.\n\n        Returns:\n            float: Largest scaling factor that maintains OPF convergence.\n\n        Raises:\n            RuntimeError: If OPF does not converge for the starting value.\n        \"\"\"\n        net = deepcopy(\n            net,\n        )  # Without this, we change the base load of the network, whioch impacts the entire data gen\n        p_ref = net.load[\"p_mw\"]\n        q_ref = net.load[\"q_mvar\"]\n        u = start\n\n        # find upper limit\n        converged = True\n        print(\"Finding upper limit u .\", end=\"\", flush=True)\n\n        while (u &lt;= max_scaling) and (converged is True):\n            net.load[\"p_mw\"] = p_ref * u  # we scale the active power\n            if change_reactive_power:  # if we want to change the reactive power, we scale it by the same factor as the active power\n                net.load[\"q_mvar\"] = q_ref * u\n            else:\n                net.load[\"q_mvar\"] = q_ref\n\n            try:\n                pp.runopp(net, numba=True)\n                u += step_size  # we increment the scaling factor by the step size\n                print(\".\", end=\"\", flush=True)\n            except pp.OPFNotConverged as err:\n                if u == start:\n                    raise RuntimeError(\n                        f\"OPF did not converge for the starting value of u={u:.3f}, {err}\",\n                    )\n                print(\n                    f\"\\nOPF did not converge for u={u:.3f}. Using u={u - step_size:.3f} for upper limit\",\n                    flush=True,\n                )\n                u -= step_size\n                converged = False\n\n        return u\n\n    @staticmethod\n    def min_max_scale(series: np.ndarray, new_min: float, new_max: float) -&gt; np.ndarray:\n        \"\"\"Scales a series of values to a new range using min-max normalization.\n\n        Args:\n            series: Input data array to scale.\n            new_min: Minimum value of the output range.\n            new_max: Maximum value of the output range.\n\n        Returns:\n            numpy.ndarray: Scaled data array.\n        \"\"\"\n        old_min, old_max = np.min(series), np.max(series)\n        if old_max == old_min:\n            return np.ones_like(series) * new_min\n        else:\n            return new_min + (series - old_min) * (new_max - new_min) / (\n                old_max - old_min\n            )\n</code></pre> <code>__call__(net, n_scenarios, scenario_log)</code> <code>abstractmethod</code> \u00b6 <p>Generates load scenarios for a power network.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenario_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@abstractmethod\ndef __call__(\n    self,\n    net: pandapowerNet,\n    n_scenarios: int,\n    scenario_log: str,\n) -&gt; np.ndarray:\n    \"\"\"Generates load scenarios for a power network.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenario_log: Path to log file for scenario generation details.\n\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n    \"\"\"\n    pass\n</code></pre> <code>find_largest_scaling_factor(net, max_scaling, step_size, start, change_reactive_power)</code> <code>staticmethod</code> \u00b6 <p>Finds the largest load scaling factor that maintains OPF convergence.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>max_scaling</code> <code>float</code> <p>Maximum scaling factor to try.</p> required <code>step_size</code> <code>float</code> <p>Increment for scaling factor search.</p> required <code>start</code> <code>float</code> <p>Starting scaling factor.</p> required <code>change_reactive_power</code> <code>bool</code> <p>Whether to scale reactive power.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Largest scaling factor that maintains OPF convergence.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If OPF does not converge for the starting value.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef find_largest_scaling_factor(\n    net: pandapowerNet,\n    max_scaling: float,\n    step_size: float,\n    start: float,\n    change_reactive_power: bool,\n) -&gt; float:\n    \"\"\"Finds the largest load scaling factor that maintains OPF convergence.\n\n    Args:\n        net: The power network.\n        max_scaling: Maximum scaling factor to try.\n        step_size: Increment for scaling factor search.\n        start: Starting scaling factor.\n        change_reactive_power: Whether to scale reactive power.\n\n    Returns:\n        float: Largest scaling factor that maintains OPF convergence.\n\n    Raises:\n        RuntimeError: If OPF does not converge for the starting value.\n    \"\"\"\n    net = deepcopy(\n        net,\n    )  # Without this, we change the base load of the network, whioch impacts the entire data gen\n    p_ref = net.load[\"p_mw\"]\n    q_ref = net.load[\"q_mvar\"]\n    u = start\n\n    # find upper limit\n    converged = True\n    print(\"Finding upper limit u .\", end=\"\", flush=True)\n\n    while (u &lt;= max_scaling) and (converged is True):\n        net.load[\"p_mw\"] = p_ref * u  # we scale the active power\n        if change_reactive_power:  # if we want to change the reactive power, we scale it by the same factor as the active power\n            net.load[\"q_mvar\"] = q_ref * u\n        else:\n            net.load[\"q_mvar\"] = q_ref\n\n        try:\n            pp.runopp(net, numba=True)\n            u += step_size  # we increment the scaling factor by the step size\n            print(\".\", end=\"\", flush=True)\n        except pp.OPFNotConverged as err:\n            if u == start:\n                raise RuntimeError(\n                    f\"OPF did not converge for the starting value of u={u:.3f}, {err}\",\n                )\n            print(\n                f\"\\nOPF did not converge for u={u:.3f}. Using u={u - step_size:.3f} for upper limit\",\n                flush=True,\n            )\n            u -= step_size\n            converged = False\n\n    return u\n</code></pre> <code>interpolate_row(row, data_points)</code> <code>staticmethod</code> \u00b6 <p>Interpolates a row of data to match the desired number of data points.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>ndarray</code> <p>Input data array to interpolate.</p> required <code>data_points</code> <code>int</code> <p>Number of points in the output array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Interpolated data array of length data_points.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef interpolate_row(row: np.ndarray, data_points: int) -&gt; np.ndarray:\n    \"\"\"Interpolates a row of data to match the desired number of data points.\n\n    Args:\n        row: Input data array to interpolate.\n        data_points: Number of points in the output array.\n\n    Returns:\n        numpy.ndarray: Interpolated data array of length data_points.\n    \"\"\"\n    if np.all(row == 0):\n        return np.zeros(data_points)\n    x_original = np.linspace(1, len(row), len(row))\n    x_target = np.linspace(1, len(row), data_points)\n    return interp1d(x_original, row, kind=\"linear\")(x_target)\n</code></pre> <code>min_max_scale(series, new_min, new_max)</code> <code>staticmethod</code> \u00b6 <p>Scales a series of values to a new range using min-max normalization.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>ndarray</code> <p>Input data array to scale.</p> required <code>new_min</code> <code>float</code> <p>Minimum value of the output range.</p> required <code>new_max</code> <code>float</code> <p>Maximum value of the output range.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Scaled data array.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>@staticmethod\ndef min_max_scale(series: np.ndarray, new_min: float, new_max: float) -&gt; np.ndarray:\n    \"\"\"Scales a series of values to a new range using min-max normalization.\n\n    Args:\n        series: Input data array to scale.\n        new_min: Minimum value of the output range.\n        new_max: Maximum value of the output range.\n\n    Returns:\n        numpy.ndarray: Scaled data array.\n    \"\"\"\n    old_min, old_max = np.min(series), np.max(series)\n    if old_max == old_min:\n        return np.ones_like(series) * new_min\n    else:\n        return new_min + (series - old_min) * (new_max - new_min) / (\n            old_max - old_min\n        )\n</code></pre>"},{"location":"components/load/#loadscenariosfromaggprofile","title":"<code>LoadScenariosFromAggProfile</code>","text":"<p>               Bases: <code>LoadScenarioGeneratorBase</code></p> <p>Generates load scenarios by scaling an aggregated load profile and adding local noise.</p> <p>Overview</p> <p>This generator uses an aggregated load profile (a time series of normalized demand values) to simulate realistic variations in load over time. The process includes:</p> <ol> <li>Determining an upper bound <code>u</code> for load scaling such that the network still    supports a feasible optimal power flow (OPF) solution.</li> <li>Setting the lower bound \\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\).</li> <li>Min-max scaling the aggregate profile to the interval \\([l, u]\\).</li> <li>Applying this global scaling factor to each load's nominal value with additive uniform noise.</li> </ol> <p>Mathematical Model</p> <p>Let:</p> <ul> <li> <p>\\(n\\): Number of loads (\\(i \\in \\{1, \\dots, n\\}\\))</p> </li> <li> <p>\\(K\\): Number of scenarios (\\(k \\in \\{1, \\dots, K\\}\\))</p> </li> <li> <p>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active/reactive loads</p> </li> <li> <p>\\(\\text{agg}^k\\): Aggregated load profile value at time step \\(k\\)</p> </li> <li> <p>\\(u\\): Maximum feasible global scaling factor (from OPF)</p> </li> <li> <p>\\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\): Minimum global scaling factor</p> </li> <li> <p>\\(\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])\\): Scaled aggregate profile</p> </li> <li> <p>\\(\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Active power noise</p> </li> <li> <p>\\(\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Reactive power noise (if enabled)</p> </li> </ul> <p>Then for each load \\(i\\) and scenario \\(k\\):</p> <p>For each load \\(i\\) and scenario \\(k\\): $$ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k $$</p> \\[ \\tilde{q}_i^k = \\begin{cases} q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\ q_i &amp; \\text{otherwise} \\end{cases} \\] <p>Notes</p> <ul> <li> <p>The upper bound <code>u</code> is automatically determined by gradually increasing the base load and solving the OPF until it fails.</p> </li> <li> <p>The lower bound <code>l</code> is computed as a relative percentage (1-<code>global_range</code>) of <code>u</code>.</p> </li> <li> <p>Noise helps simulate local variability across loads within a global trend.</p> </li> </ul> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class LoadScenariosFromAggProfile(LoadScenarioGeneratorBase):\n    r\"\"\"\n    Generates load scenarios by scaling an aggregated load profile and adding local noise.\n\n    **Overview**\n\n    This generator uses an aggregated load profile (a time series of normalized demand values)\n    to simulate realistic variations in load over time. The process includes:\n\n    1. Determining an upper bound `u` for load scaling such that the network still\n       supports a feasible optimal power flow (OPF) solution.\n    2. Setting the lower bound $l = (1 - \\text{global\\textunderscore range}) \\cdot u$.\n    3. Min-max scaling the aggregate profile to the interval \\([l, u]\\).\n    4. Applying this global scaling factor to each load's nominal value with additive uniform noise.\n\n    **Mathematical Model**\n\n    Let:\n\n    - $n$: Number of loads ($i \\in \\{1, \\dots, n\\}$)\n\n    - $K$: Number of scenarios ($k \\in \\{1, \\dots, K\\}$)\n\n    - $(p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2$: Nominal active/reactive loads\n\n    - $\\text{agg}^k$: Aggregated load profile value at time step $k$\n\n    - $u$: Maximum feasible global scaling factor (from OPF)\n\n    - $l = (1 - \\text{global\\textunderscore range}) \\cdot u$: Minimum global scaling factor\n\n    - $\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])$: Scaled aggregate profile\n\n    - $\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)$: Active power noise\n\n    - $\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)$: Reactive power noise (if enabled)\n\n    Then for each load $i$ and scenario $k$:\n\n    For each load $i$ and scenario $k$:\n    $$\n    \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k\n    $$\n\n    $$\n    \\tilde{q}_i^k =\n    \\begin{cases}\n    q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\\n    q_i &amp; \\text{otherwise}\n    \\end{cases}\n    $$\n\n    **Notes**\n\n    - The upper bound `u` is automatically determined by gradually increasing the base load and solving the OPF until it fails.\n\n    - The lower bound `l` is computed as a relative percentage (1-`global_range`) of `u`.\n\n    - Noise helps simulate local variability across loads within a global trend.\n    \"\"\"\n\n    def __init__(\n        self,\n        agg_load_name: str,\n        sigma: float,\n        change_reactive_power: bool,\n        global_range: float,\n        max_scaling_factor: float,\n        step_size: float,\n        start_scaling_factor: float,\n    ):\n        \"\"\"Initializes the load scenario generator.\n\n        Args:\n            agg_load_name: Name of the aggregated load profile file.\n            sigma: Standard deviation for noise addition.\n            change_reactive_power: Whether to scale reactive power.\n            global_range: Range for scaling factor.\n            max_scaling_factor: Maximum scaling factor to try.\n            step_size: Increment for scaling factor search.\n            start_scaling_factor: Starting scaling factor.\n        \"\"\"\n        self.agg_load_name = agg_load_name\n        self.sigma = sigma\n        self.change_reactive_power = change_reactive_power\n        self.global_range = global_range\n        self.max_scaling_factor = max_scaling_factor\n        self.step_size = step_size\n        self.start_scaling_factor = start_scaling_factor\n\n    def __call__(\n        self,\n        net: pandapowerNet,\n        n_scenarios: int,\n        scenarios_log: str,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load profiles based on aggregated load data.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenarios_log: Path to log file for scenario generation details.\n\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n        Raises:\n            ValueError: If start_scaling_factor is less than global_range.\n        \"\"\"\n        if (\n            self.start_scaling_factor - self.global_range * self.start_scaling_factor\n            &lt; 0\n        ):\n            raise ValueError(\n                \"The start scaling factor must be larger than the global range.\",\n            )\n\n        u = self.find_largest_scaling_factor(\n            net,\n            max_scaling=self.max_scaling_factor,\n            step_size=self.step_size,\n            start=self.start_scaling_factor,\n            change_reactive_power=self.change_reactive_power,\n        )\n        lower = (\n            u - self.global_range * u\n        )  # The lower bound used to be set as e.g. u - 40%, while now it is set as u - 40% of u\n\n        with open(scenarios_log, \"a\") as f:\n            f.write(\"u=\" + str(u) + \"\\n\")\n            f.write(\"l=\" + str(lower) + \"\\n\")\n\n        agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n            f\"{self.agg_load_name}.csv\",\n        )\n        agg_load = pd.read_csv(agg_load_path).to_numpy()\n        agg_load = agg_load.reshape(agg_load.shape[0])\n        ref_curve = self.min_max_scale(agg_load, lower, u)\n        print(\"min, max of ref_curve: {}, {}\".format(ref_curve.min(), ref_curve.max()))\n        print(\"l, u: {}, {}\".format(lower, u))\n\n        p_mw_array = net.load.p_mw.to_numpy()  # we now store the active power at the load elements level, we don't aggregate it at the bus level (which was probably not changing anything since there is usually max one load per bus)\n\n        q_mvar_array = net.load.q_mvar.to_numpy()\n\n        # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n        if n_scenarios &lt;= ref_curve.shape[0]:\n            print(\n                \"cutting the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = ref_curve[:n_scenarios]\n        # if it is larger, we interpolate it\n        else:\n            print(\n                \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n        load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n        noise = np.random.uniform(\n            1 - self.sigma,\n            1 + self.sigma,\n            size=load_profile_pmw.shape,\n        )  # Add uniform noise\n        load_profile_pmw *= noise\n\n        if self.change_reactive_power:\n            load_profile_qmvar = q_mvar_array[:, np.newaxis] * ref_curve\n            noise = np.random.uniform(\n                1 - self.sigma,\n                1 + self.sigma,\n                size=load_profile_qmvar.shape,\n            )  # Add uniform noise\n            load_profile_qmvar *= noise\n        else:\n            load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n            print(\"No change in reactive power across scenarios\")\n\n        # Stack profiles along the last dimension\n        load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n        return load_profiles\n</code></pre> <code>__call__(net, n_scenarios, scenarios_log)</code> \u00b6 <p>Generates load profiles based on aggregated load data.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenarios_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If start_scaling_factor is less than global_range.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __call__(\n    self,\n    net: pandapowerNet,\n    n_scenarios: int,\n    scenarios_log: str,\n) -&gt; np.ndarray:\n    \"\"\"Generates load profiles based on aggregated load data.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenarios_log: Path to log file for scenario generation details.\n\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n    Raises:\n        ValueError: If start_scaling_factor is less than global_range.\n    \"\"\"\n    if (\n        self.start_scaling_factor - self.global_range * self.start_scaling_factor\n        &lt; 0\n    ):\n        raise ValueError(\n            \"The start scaling factor must be larger than the global range.\",\n        )\n\n    u = self.find_largest_scaling_factor(\n        net,\n        max_scaling=self.max_scaling_factor,\n        step_size=self.step_size,\n        start=self.start_scaling_factor,\n        change_reactive_power=self.change_reactive_power,\n    )\n    lower = (\n        u - self.global_range * u\n    )  # The lower bound used to be set as e.g. u - 40%, while now it is set as u - 40% of u\n\n    with open(scenarios_log, \"a\") as f:\n        f.write(\"u=\" + str(u) + \"\\n\")\n        f.write(\"l=\" + str(lower) + \"\\n\")\n\n    agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n        f\"{self.agg_load_name}.csv\",\n    )\n    agg_load = pd.read_csv(agg_load_path).to_numpy()\n    agg_load = agg_load.reshape(agg_load.shape[0])\n    ref_curve = self.min_max_scale(agg_load, lower, u)\n    print(\"min, max of ref_curve: {}, {}\".format(ref_curve.min(), ref_curve.max()))\n    print(\"l, u: {}, {}\".format(lower, u))\n\n    p_mw_array = net.load.p_mw.to_numpy()  # we now store the active power at the load elements level, we don't aggregate it at the bus level (which was probably not changing anything since there is usually max one load per bus)\n\n    q_mvar_array = net.load.q_mvar.to_numpy()\n\n    # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n    if n_scenarios &lt;= ref_curve.shape[0]:\n        print(\n            \"cutting the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = ref_curve[:n_scenarios]\n    # if it is larger, we interpolate it\n    else:\n        print(\n            \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n    load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n    noise = np.random.uniform(\n        1 - self.sigma,\n        1 + self.sigma,\n        size=load_profile_pmw.shape,\n    )  # Add uniform noise\n    load_profile_pmw *= noise\n\n    if self.change_reactive_power:\n        load_profile_qmvar = q_mvar_array[:, np.newaxis] * ref_curve\n        noise = np.random.uniform(\n            1 - self.sigma,\n            1 + self.sigma,\n            size=load_profile_qmvar.shape,\n        )  # Add uniform noise\n        load_profile_qmvar *= noise\n    else:\n        load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n        print(\"No change in reactive power across scenarios\")\n\n    # Stack profiles along the last dimension\n    load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n    return load_profiles\n</code></pre> <code>__init__(agg_load_name, sigma, change_reactive_power, global_range, max_scaling_factor, step_size, start_scaling_factor)</code> \u00b6 <p>Initializes the load scenario generator.</p> <p>Parameters:</p> Name Type Description Default <code>agg_load_name</code> <code>str</code> <p>Name of the aggregated load profile file.</p> required <code>sigma</code> <code>float</code> <p>Standard deviation for noise addition.</p> required <code>change_reactive_power</code> <code>bool</code> <p>Whether to scale reactive power.</p> required <code>global_range</code> <code>float</code> <p>Range for scaling factor.</p> required <code>max_scaling_factor</code> <code>float</code> <p>Maximum scaling factor to try.</p> required <code>step_size</code> <code>float</code> <p>Increment for scaling factor search.</p> required <code>start_scaling_factor</code> <code>float</code> <p>Starting scaling factor.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __init__(\n    self,\n    agg_load_name: str,\n    sigma: float,\n    change_reactive_power: bool,\n    global_range: float,\n    max_scaling_factor: float,\n    step_size: float,\n    start_scaling_factor: float,\n):\n    \"\"\"Initializes the load scenario generator.\n\n    Args:\n        agg_load_name: Name of the aggregated load profile file.\n        sigma: Standard deviation for noise addition.\n        change_reactive_power: Whether to scale reactive power.\n        global_range: Range for scaling factor.\n        max_scaling_factor: Maximum scaling factor to try.\n        step_size: Increment for scaling factor search.\n        start_scaling_factor: Starting scaling factor.\n    \"\"\"\n    self.agg_load_name = agg_load_name\n    self.sigma = sigma\n    self.change_reactive_power = change_reactive_power\n    self.global_range = global_range\n    self.max_scaling_factor = max_scaling_factor\n    self.step_size = step_size\n    self.start_scaling_factor = start_scaling_factor\n</code></pre>"},{"location":"components/load/#powergraph","title":"<code>Powergraph</code>","text":"<p>               Bases: <code>LoadScenarioGeneratorBase</code></p> <p>Load scenario generator using the PowerGraph method.</p> <p>Generates load scenarios by scaling the nominal active power profile with a normalized reference curve while keeping reactive power fixed.</p> <p>Mathematical Model</p> <p>Let:</p> <ul> <li>\\(n\\): Number of loads (indexed by \\(i \\in \\{1, \\dots, n\\}\\))</li> <li>\\(K\\): Number of scenarios (indexed by \\(k \\in \\{1, \\dots, K\\}\\))</li> <li>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active and reactive load vectors</li> <li>\\(\\text{ref}^k \\in [0, 1]\\): Normalized aggregate reference profile at scenario \\(k\\)</li> <li>\\((\\tilde{p}_i^k, \\tilde{q}_i^k) \\in \\mathbb{R}_{\\geq 0}^2\\): Active/reactive load at bus \\(i\\) in scenario \\(k\\)</li> </ul> <p>The reference profile is computed by normalizing an aggregated profile:</p> \\[ \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k} \\] <p>Then, for each bus \\(i\\) and scenario \\(k\\):</p> \\[ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\] <p>and reactive power is kept constant:</p> \\[ \\tilde{q}_i^k = q_i \\] Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>class Powergraph(LoadScenarioGeneratorBase):\n    r\"\"\"\n    Load scenario generator using the PowerGraph method.\n\n    Generates load scenarios by scaling the nominal active power profile\n    with a normalized reference curve while keeping reactive power fixed.\n\n    **Mathematical Model**\n\n    Let:\n\n    - $n$: Number of loads (indexed by $i \\in \\{1, \\dots, n\\}$)\n    - $K$: Number of scenarios (indexed by $k \\in \\{1, \\dots, K\\}$)\n    - $(p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2$: Nominal active and reactive load vectors\n    - $\\text{ref}^k \\in [0, 1]$: Normalized aggregate reference profile at scenario $k$\n    - $(\\tilde{p}_i^k, \\tilde{q}_i^k) \\in \\mathbb{R}_{\\geq 0}^2$: Active/reactive load at bus $i$ in scenario $k$\n\n    The reference profile is computed by normalizing an aggregated profile:\n\n    $$\n    \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k}\n    $$\n\n    Then, for each bus $i$ and scenario $k$:\n\n    $$\n    \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k\n    $$\n\n    and reactive power is kept constant:\n\n    $$\n    \\tilde{q}_i^k = q_i\n    $$\"\"\"\n\n    def __init__(\n        self,\n        agg_load_name: str,\n    ):\n        \"\"\"Initializes the powergraph load scenario generator.\n\n        Args:\n            agg_load_name: Name of the aggregated load profile file.\n        \"\"\"\n        self.agg_load_name = agg_load_name\n\n    def __call__(\n        self,\n        net: pandapowerNet,\n        n_scenarios: int,\n        scenario_log: str,\n    ) -&gt; np.ndarray:\n        \"\"\"Generates load profiles based on aggregated load data.\n\n        Args:\n            net: The power network.\n            n_scenarios: Number of scenarios to generate.\n            scenario_log: Path to log file for scenario generation details.\n\n        Returns:\n            numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n        \"\"\"\n        agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n            f\"{self.agg_load_name}.csv\",\n        )\n        agg_load = pd.read_csv(agg_load_path).to_numpy()\n        agg_load = agg_load.reshape(agg_load.shape[0])\n        ref_curve = agg_load / agg_load.max()\n        print(\"u={}, l={}\".format(ref_curve.max(), ref_curve.min()))\n\n        p_mw_array = net.load.p_mw.to_numpy()  # we now store the active power at the load elements level, we don't aggregate it at the bus level (which was probably not changing anything since there is usually max one load per bus)\n\n        q_mvar_array = net.load.q_mvar.to_numpy()\n\n        # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n        if n_scenarios &lt;= ref_curve.shape[0]:\n            print(\n                \"cutting the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = ref_curve[:n_scenarios]\n        # if it is larger, we interpolate it\n        else:\n            print(\n                \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                    ref_curve.shape[0],\n                    n_scenarios,\n                ),\n            )\n            ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n        load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n        load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n        print(\"No change in reactive power across scenarios\")\n\n        # Stack profiles along the last dimension\n        load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n        return load_profiles\n</code></pre> <code>__call__(net, n_scenarios, scenario_log)</code> \u00b6 <p>Generates load profiles based on aggregated load data.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>n_scenarios</code> <code>int</code> <p>Number of scenarios to generate.</p> required <code>scenario_log</code> <code>str</code> <p>Path to log file for scenario generation details.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __call__(\n    self,\n    net: pandapowerNet,\n    n_scenarios: int,\n    scenario_log: str,\n) -&gt; np.ndarray:\n    \"\"\"Generates load profiles based on aggregated load data.\n\n    Args:\n        net: The power network.\n        n_scenarios: Number of scenarios to generate.\n        scenario_log: Path to log file for scenario generation details.\n\n    Returns:\n        numpy.ndarray: Array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n    \"\"\"\n    agg_load_path = resources.files(\"gridfm_datakit.load_profiles\").joinpath(\n        f\"{self.agg_load_name}.csv\",\n    )\n    agg_load = pd.read_csv(agg_load_path).to_numpy()\n    agg_load = agg_load.reshape(agg_load.shape[0])\n    ref_curve = agg_load / agg_load.max()\n    print(\"u={}, l={}\".format(ref_curve.max(), ref_curve.min()))\n\n    p_mw_array = net.load.p_mw.to_numpy()  # we now store the active power at the load elements level, we don't aggregate it at the bus level (which was probably not changing anything since there is usually max one load per bus)\n\n    q_mvar_array = net.load.q_mvar.to_numpy()\n\n    # if the number of requested scenarios is smaller than the number of timesteps in the load profile, we cut the load profile\n    if n_scenarios &lt;= ref_curve.shape[0]:\n        print(\n            \"cutting the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = ref_curve[:n_scenarios]\n    # if it is larger, we interpolate it\n    else:\n        print(\n            \"interpolating the load profile (original length: {}, requested length: {})\".format(\n                ref_curve.shape[0],\n                n_scenarios,\n            ),\n        )\n        ref_curve = self.interpolate_row(ref_curve, data_points=n_scenarios)\n\n    load_profile_pmw = p_mw_array[:, np.newaxis] * ref_curve\n    load_profile_qmvar = q_mvar_array[:, np.newaxis] * np.ones_like(ref_curve)\n    print(\"No change in reactive power across scenarios\")\n\n    # Stack profiles along the last dimension\n    load_profiles = np.stack((load_profile_pmw, load_profile_qmvar), axis=-1)\n\n    return load_profiles\n</code></pre> <code>__init__(agg_load_name)</code> \u00b6 <p>Initializes the powergraph load scenario generator.</p> <p>Parameters:</p> Name Type Description Default <code>agg_load_name</code> <code>str</code> <p>Name of the aggregated load profile file.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def __init__(\n    self,\n    agg_load_name: str,\n):\n    \"\"\"Initializes the powergraph load scenario generator.\n\n    Args:\n        agg_load_name: Name of the aggregated load profile file.\n    \"\"\"\n    self.agg_load_name = agg_load_name\n</code></pre>"},{"location":"components/load/#load_scenarios_to_df","title":"<code>load_scenarios_to_df</code>","text":"<p>Converts load scenarios array to a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>scenarios</code> <code>ndarray</code> <p>3D numpy array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with columns: load_scenario, load, p_mw, q_mvar.</p> Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def load_scenarios_to_df(scenarios: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"Converts load scenarios array to a DataFrame.\n\n    Args:\n        scenarios: 3D numpy array of shape (n_loads, n_scenarios, 2) containing p_mw and q_mvar values.\n\n    Returns:\n        DataFrame with columns: load_scenario, load, p_mw, q_mvar.\n    \"\"\"\n    n_loads = scenarios.shape[0]\n    n_scenarios = scenarios.shape[1]\n\n    # Flatten the array\n    reshaped_array = scenarios.reshape((-1, 2), order=\"F\")\n\n    # Create a DataFrame\n    df = pd.DataFrame(reshaped_array, columns=[\"p_mw\", \"q_mvar\"])\n\n    # Create load_scenario and bus columns\n    load_idx = np.tile(np.arange(n_loads), n_scenarios)\n    scenarios_idx = np.repeat(np.arange(n_scenarios), n_loads)\n\n    df.insert(0, \"load_scenario\", scenarios_idx)\n    df.insert(1, \"load\", load_idx)\n\n    return df\n</code></pre>"},{"location":"components/load/#plot_load_scenarios_combined","title":"<code>plot_load_scenarios_combined</code>","text":"<p>Generates a combined plot of active and reactive power load scenarios.</p> <p>Creates a two-subplot figure with p_mw and q_mvar plots, one line per bus.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame containing load scenarios with columns: load_scenario, load, p_mw, q_mvar.</p> required <code>output_file</code> <code>str</code> <p>Path where the HTML plot file should be saved.</p> required Source code in <code>gridfm_datakit/perturbations/load_perturbation.py</code> <pre><code>def plot_load_scenarios_combined(df: pd.DataFrame, output_file: str) -&gt; None:\n    \"\"\"Generates a combined plot of active and reactive power load scenarios.\n\n    Creates a two-subplot figure with p_mw and q_mvar plots, one line per bus.\n\n    Args:\n        df: DataFrame containing load scenarios with columns: load_scenario, load, p_mw, q_mvar.\n        output_file: Path where the HTML plot file should be saved.\n    \"\"\"\n    # Create subplots\n    fig = make_subplots(\n        rows=2,\n        cols=1,\n        shared_xaxes=True,\n        vertical_spacing=0.1,\n        subplot_titles=(\"p_mw\", \"q_mvar\"),\n    )\n\n    # Add p_mw plot\n    for load in df[\"load\"].unique():\n        df_load = df[df[\"load\"] == load]\n        fig.add_trace(\n            go.Scatter(\n                x=df_load[\"load_scenario\"],\n                y=df_load[\"p_mw\"],\n                mode=\"lines\",\n                name=f\"Load {load} p_mw\",\n            ),\n            row=1,\n            col=1,\n        )\n\n    # Add q_mvar plot\n    for load in df[\"load\"].unique():\n        df_load = df[df[\"load\"] == load]\n        fig.add_trace(\n            go.Scatter(\n                x=df_load[\"load_scenario\"],\n                y=df_load[\"q_mvar\"],\n                mode=\"lines\",\n                name=f\"Load {load} q_mvar\",\n            ),\n            row=2,\n            col=1,\n        )\n\n    # Update layout\n    fig.update_layout(height=800, width=1500, title_text=\"Load Scenarios\")\n\n    # Save the combined plot to an HTML file\n    fig.write_html(output_file)\n</code></pre>"},{"location":"components/network/","title":"Network","text":"<p>This module provides functions to load power grid networks from various sources.</p>"},{"location":"components/network/#load_net_from_pp","title":"<code>load_net_from_pp</code>","text":"<p>Loads a network from the pandapower library.</p> <p>Parameters:</p> Name Type Description Default <code>grid_name</code> <code>str</code> <p>Name of the grid case file in pandapower library.</p> required <p>Returns:</p> Name Type Description <code>pandapowerNet</code> <code>pandapowerNet</code> <p>Loaded power network configuration.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def load_net_from_pp(grid_name: str) -&gt; pandapowerNet:\n    \"\"\"Loads a network from the pandapower library.\n\n    Args:\n        grid_name: Name of the grid case file in pandapower library.\n\n    Returns:\n        pandapowerNet: Loaded power network configuration.\n    \"\"\"\n    network = getattr(pn, grid_name)()\n    return network\n</code></pre>"},{"location":"components/network/#load_net_from_file","title":"<code>load_net_from_file</code>","text":"<p>Loads a network from a matpower file.</p> <p>Parameters:</p> Name Type Description Default <code>network_path</code> <code>str</code> <p>Path to the matpower file (without extension).</p> required <p>Returns:</p> Name Type Description <code>pandapowerNet</code> <code>pandapowerNet</code> <p>Loaded power network configuration with reindexed buses.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def load_net_from_file(network_path: str) -&gt; pandapowerNet:\n    \"\"\"Loads a network from a matpower file.\n\n    Args:\n        network_path: Path to the matpower file (without extension).\n\n    Returns:\n        pandapowerNet: Loaded power network configuration with reindexed buses.\n    \"\"\"\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    network = pp.converter.from_mpc(str(network_path))\n    warnings.resetwarnings()\n\n    old_bus_indices = network.bus.index\n    new_bus_indices = range(len(network.bus))\n\n    # Create a mapping dictionary\n    bus_mapping = dict(zip(old_bus_indices, new_bus_indices))\n\n    # Reindex the buses in the network\n    pp.reindex_buses(network, bus_mapping)\n\n    return network\n</code></pre>"},{"location":"components/network/#load_net_from_pglib","title":"<code>load_net_from_pglib</code>","text":"<p>Loads a power grid network from PGLib.</p> <p>Downloads the network file if not locally available and loads it into a pandapower network. The buses are reindexed to ensure continuous indices.</p> <p>Parameters:</p> Name Type Description Default <code>grid_name</code> <code>str</code> <p>Name of the grid file without the prefix 'pglib_opf_' (e.g., 'case14_ieee', 'case118_ieee').</p> required <p>Returns:</p> Name Type Description <code>pandapowerNet</code> <code>pandapowerNet</code> <p>Loaded power network configuration with reindexed buses.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If download fails.</p> Source code in <code>gridfm_datakit/network.py</code> <pre><code>def load_net_from_pglib(grid_name: str) -&gt; pandapowerNet:\n    \"\"\"Loads a power grid network from PGLib.\n\n    Downloads the network file if not locally available and loads it into a pandapower network.\n    The buses are reindexed to ensure continuous indices.\n\n    Args:\n        grid_name: Name of the grid file without the prefix 'pglib_opf_' (e.g., 'case14_ieee', 'case118_ieee').\n\n    Returns:\n        pandapowerNet: Loaded power network configuration with reindexed buses.\n\n    Raises:\n        requests.exceptions.RequestException: If download fails.\n    \"\"\"\n    # Construct file paths\n    file_path = str(\n        resources.files(\"gridfm_datakit.grids\").joinpath(f\"pglib_opf_{grid_name}.m\"),\n    )\n\n    # Create directory if it doesn't exist\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n\n    # Download file if not exists\n    if not os.path.exists(file_path):\n        url = f\"https://raw.githubusercontent.com/power-grid-lib/pglib-opf/master/pglib_opf_{grid_name}.m\"\n        response = requests.get(url)\n        response.raise_for_status()\n\n        with open(file_path, \"wb\") as f:\n            f.write(response.content)\n\n    # Load network from file\n    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n    network = pp.converter.from_mpc(file_path)\n    warnings.resetwarnings()\n\n    old_bus_indices = network.bus.index\n    new_bus_indices = range(len(network.bus))\n\n    # Create a mapping dictionary\n    bus_mapping = dict(zip(old_bus_indices, new_bus_indices))\n\n    # Reindex the buses in the network\n    pp.reindex_buses(network, bus_mapping)\n\n    return network\n</code></pre>"},{"location":"components/param_handler/","title":"Param Handler","text":"<p>This module provides utilities for handling and manipulating configuration parameters.</p>"},{"location":"components/param_handler/#flatten_dict","title":"<code>flatten_dict</code>","text":"<p>Flattens a nested dictionary into a single-level dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict[str, Any]</code> <p>The dictionary to flatten.</p> required <code>parent_key</code> <code>str</code> <p>Prefix for the keys in the flattened dictionary.</p> <code>''</code> <code>sep</code> <code>str</code> <p>Separator for nested keys. Defaults to '.'.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A flattened version of the input dictionary with dot-separated keys.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def flatten_dict(\n    d: Dict[str, Any],\n    parent_key: str = \"\",\n    sep: str = \".\",\n) -&gt; Dict[str, Any]:\n    \"\"\"Flattens a nested dictionary into a single-level dictionary.\n\n    Args:\n        d: The dictionary to flatten.\n        parent_key: Prefix for the keys in the flattened dictionary.\n        sep: Separator for nested keys. Defaults to '.'.\n\n    Returns:\n        A flattened version of the input dictionary with dot-separated keys.\n    \"\"\"\n    items = []\n    for key, value in d.items():\n        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n        if isinstance(value, dict):\n            items.extend(flatten_dict(value, new_key, sep=sep).items())\n        else:\n            items.append((new_key, value))\n    return dict(items)\n</code></pre>"},{"location":"components/param_handler/#unflatten_dict","title":"<code>unflatten_dict</code>","text":"<p>Reconstructs a nested dictionary from a flattened dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>Dict[str, Any]</code> <p>The flattened dictionary to unflatten.</p> required <code>sep</code> <code>str</code> <p>Separator used in the flattened keys. Defaults to '.'.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>A nested dictionary reconstructed from the flattened input.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def unflatten_dict(d: Dict[str, Any], sep: str = \".\") -&gt; Dict[str, Any]:\n    \"\"\"Reconstructs a nested dictionary from a flattened dictionary.\n\n    Args:\n        d: The flattened dictionary to unflatten.\n        sep: Separator used in the flattened keys. Defaults to '.'.\n\n    Returns:\n        A nested dictionary reconstructed from the flattened input.\n    \"\"\"\n    result = {}\n    for key, value in d.items():\n        parts = key.split(sep)\n        target = result\n        for part in parts[:-1]:\n            target = target.setdefault(part, {})\n        target[parts[-1]] = value\n    return result\n</code></pre>"},{"location":"components/param_handler/#merge_dict","title":"<code>merge_dict</code>","text":"<p>Recursively merges updates into a base dictionary.</p> <p>Only merges keys that exist in the base dictionary. Raises errors for invalid updates.</p> <p>Parameters:</p> Name Type Description Default <code>base</code> <code>Dict[str, Any]</code> <p>The original dictionary to be updated.</p> required <code>updates</code> <code>Dict[str, Any]</code> <p>The dictionary containing updates.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If a key in updates does not exist in base.</p> <code>TypeError</code> <p>If a key in base is not a dictionary but updates attempt to provide nested values.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def merge_dict(base: Dict[str, Any], updates: Dict[str, Any]) -&gt; None:\n    \"\"\"Recursively merges updates into a base dictionary.\n\n    Only merges keys that exist in the base dictionary. Raises errors for\n    invalid updates.\n\n    Args:\n        base: The original dictionary to be updated.\n        updates: The dictionary containing updates.\n\n    Raises:\n        KeyError: If a key in updates does not exist in base.\n        TypeError: If a key in base is not a dictionary but updates attempt to\n            provide nested values.\n    \"\"\"\n    for key, value in updates.items():\n        if key not in base:\n            raise KeyError(f\"Key '{key}' not found in base configuration.\")\n\n        if isinstance(value, dict):\n            if not isinstance(base[key], dict):\n                raise TypeError(\n                    f\"Default config expects  {type(base[key])}, but got a dict at key '{key}'\",\n                )\n            # Recursively merge dictionaries\n            merge_dict(base[key], value)\n        else:\n            # Update the existing key\n            base[key] = value\n</code></pre>"},{"location":"components/param_handler/#get_load_scenario_generator","title":"<code>get_load_scenario_generator</code>","text":"<p>Creates and returns a load scenario generator based on configuration.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration namespace containing load generator parameters.</p> required <p>Returns:</p> Type Description <code>LoadScenarioGeneratorBase</code> <p>An instance of a LoadScenarioGeneratorBase subclass configured according</p> <code>LoadScenarioGeneratorBase</code> <p>to the provided arguments.</p> Note <p>Currently supports 'agg_load_profile' and 'powergraph' generator types.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def get_load_scenario_generator(args: NestedNamespace) -&gt; LoadScenarioGeneratorBase:\n    \"\"\"Creates and returns a load scenario generator based on configuration.\n\n    Args:\n        args: Configuration namespace containing load generator parameters.\n\n    Returns:\n        An instance of a LoadScenarioGeneratorBase subclass configured according\n        to the provided arguments.\n\n    Note:\n        Currently supports 'agg_load_profile' and 'powergraph' generator types.\n    \"\"\"\n    if args.generator == \"agg_load_profile\":\n        return LoadScenariosFromAggProfile(\n            args.agg_profile,\n            args.sigma,\n            args.change_reactive_power,\n            args.global_range,\n            args.max_scaling_factor,\n            args.step_size,\n            args.start_scaling_factor,\n        )\n    if args.generator == \"powergraph\":\n        unused_args = {\n            key: value\n            for key, value in args.flatten().items()\n            if key not in [\"type\", \"agg_profile\"]\n        }\n        if unused_args:\n            warnings.warn(\n                f\"The following arguments are not used by the powergraph generator: {unused_args}\",\n                UserWarning,\n            )\n\n        return Powergraph(args.agg_profile)\n</code></pre>"},{"location":"components/param_handler/#initialize_topology_generator","title":"<code>initialize_topology_generator</code>","text":"<p>Initialize the appropriate topology generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing generator type and parameters.</p> required <code>base_net</code> <code>pandapowerNet</code> <p>Base network to analyze.</p> required <p>Returns:</p> Name Type Description <code>TopologyGenerator</code> <code>TopologyGenerator</code> <p>The initialized topology generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_topology_generator(\n    args: NestedNamespace,\n    base_net: pandapowerNet,\n) -&gt; TopologyGenerator:\n    \"\"\"Initialize the appropriate topology generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing generator type and parameters.\n        base_net: Base network to analyze.\n\n    Returns:\n        TopologyGenerator: The initialized topology generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"n_minus_k\":\n        if not hasattr(args, \"k\"):\n            raise ValueError(\"k parameter is required for n_minus_k generator\")\n        generator = NMinusKGenerator(args.k, base_net)\n        used_args = {\"k\": args.k, \"base_net\": base_net}\n\n    elif args.type == \"random\":\n        if not all(hasattr(args, attr) for attr in [\"n_topology_variants\", \"k\"]):\n            raise ValueError(\n                \"n_topology_variants and k parameters are required for random generator\",\n            )\n        elements = getattr(args, \"elements\", [\"line\", \"trafo\", \"gen\", \"sgen\"])\n        generator = RandomComponentDropGenerator(\n            args.n_topology_variants,\n            args.k,\n            base_net,\n            elements,\n        )\n        used_args = {\n            \"n_topology_variants\": args.n_topology_variants,\n            \"k\": args.k,\n            \"base_net\": base_net,\n            \"elements\": elements,\n        }\n\n    elif args.type == \"none\":\n        generator = NoPerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the topology generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#initialize_generation_generator","title":"<code>initialize_generation_generator</code>","text":"<p>Initialize the appropriate generation generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing generator type and parameters.</p> required <code>base_net</code> <code>pandapowerNet</code> <p>Base network to use.</p> required <p>Returns:</p> Name Type Description <code>GenerationGenerator</code> <code>GenerationGenerator</code> <p>The initialized generation generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_generation_generator(\n    args: NestedNamespace,\n    base_net: pandapowerNet,\n) -&gt; GenerationGenerator:\n    \"\"\"Initialize the appropriate generation generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing generator type and parameters.\n        base_net: Base network to use.\n\n    Returns:\n        GenerationGenerator: The initialized generation generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"cost_permutation\":\n        generator = PermuteGenCostGenerator(base_net)\n        used_args = {\"base_net\": base_net}\n\n    elif args.type == \"cost_perturbation\":\n        if not hasattr(args, \"sigma\"):\n            raise ValueError(\n                \"sigma parameter is required for cost_perturbation generator\",\n            )\n        generator = PerturbGenCostGenerator(base_net, args.sigma)\n        used_args = {\"sigma\": args.sigma, \"base_net\": base_net}\n\n    elif args.type == \"none\":\n        generator = NoGenPerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the generation generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#initialize_admittance_generator","title":"<code>initialize_admittance_generator</code>","text":"<p>Initialize the appropriate line admittance generator based on the given arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>NestedNamespace</code> <p>Configuration arguments containing admittance generator type and parameters.</p> required <code>base_net</code> <code>pandapowerNet</code> <p>Base network to use.</p> required <p>Returns:</p> Name Type Description <code>AdmittanceGenerator</code> <code>AdmittanceGenerator</code> <p>The initialized line admittance generator.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the generator type is unknown.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def initialize_admittance_generator(\n    args: NestedNamespace,\n    base_net: pandapowerNet,\n) -&gt; AdmittanceGenerator:\n    \"\"\"Initialize the appropriate line admittance generator based on the given arguments.\n\n    Args:\n        args: Configuration arguments containing admittance generator type and parameters.\n        base_net: Base network to use.\n\n    Returns:\n        AdmittanceGenerator: The initialized line admittance generator.\n\n    Raises:\n        ValueError: If the generator type is unknown.\n    \"\"\"\n    if args.type == \"random_perturbation\":\n        if not hasattr(args, \"sigma\"):\n            raise ValueError(\n                \"sigma parameter is required for admittance_perturbation generator\",\n            )\n        generator = PerturbAdmittanceGenerator(base_net, args.sigma)\n        used_args = {\"base_net\": base_net, \"sigma\": args.sigma}\n\n    elif args.type == \"none\":\n        generator = NoAdmittancePerturbationGenerator()\n        used_args = {}\n\n    else:\n        raise ValueError(f\"Unknown generator type: {args.type}\")\n\n    # Check for unused arguments\n    unused_args = {\n        key: value\n        for key, value in args.flatten().items()\n        if key not in used_args and key != \"type\"\n    }\n    if unused_args:\n        warnings.warn(\n            f'The following arguments are not used by the admittance generator \"{args.type}\": {unused_args}',\n            UserWarning,\n        )\n\n    return generator\n</code></pre>"},{"location":"components/param_handler/#classes","title":"Classes","text":""},{"location":"components/param_handler/#nestednamespace","title":"<code>NestedNamespace</code>","text":"<p>               Bases: <code>Namespace</code></p> <p>A namespace object that supports nested structures.</p> <p>This class extends argparse.Namespace to support hierarchical configurations, allowing for easy access and manipulation of nested parameters.</p> <p>Attributes:</p> Name Type Description <code>__dict__</code> <p>Dictionary containing the namespace attributes.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>class NestedNamespace(argparse.Namespace):\n    \"\"\"A namespace object that supports nested structures.\n\n    This class extends argparse.Namespace to support hierarchical configurations,\n    allowing for easy access and manipulation of nested parameters.\n\n    Attributes:\n        __dict__: Dictionary containing the namespace attributes.\n    \"\"\"\n\n    def __init__(self, **kwargs: Any) -&gt; None:\n        \"\"\"Initializes a NestedNamespace with the given keyword arguments.\n\n        Args:\n            **kwargs: Key-value pairs to initialize the namespace.\n        \"\"\"\n        for key, value in kwargs.items():\n            if isinstance(value, dict):\n                # Recursively convert dictionaries to NestedNamespace\n                setattr(self, key, NestedNamespace(**value))\n            else:\n                setattr(self, key, value)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Converts the NestedNamespace back to a dictionary.\n\n        Returns:\n            Dict containing the namespace attributes, with nested NestedNamespace\n            objects converted to dictionaries.\n        \"\"\"\n        result = {}\n        for key, value in self.__dict__.items():\n            if isinstance(value, NestedNamespace):\n                result[key] = value.to_dict()\n            else:\n                result[key] = value\n        return result\n\n    def flatten(self, parent_key: str = \"\", sep: str = \".\") -&gt; Dict[str, Any]:\n        \"\"\"Flattens the namespace into a single-level dictionary.\n\n        Args:\n            parent_key: Prefix for the keys in the flattened dictionary.\n            sep: Separator for nested keys.\n\n        Returns:\n            Dict with dot-separated keys representing the nested structure.\n        \"\"\"\n        items = []\n        for key, value in self.__dict__.items():\n            new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n            if isinstance(value, NestedNamespace):\n                items.extend(value.flatten(new_key, sep=sep).items())\n            else:\n                items.append((new_key, value))\n        return dict(items)\n</code></pre> <code>__init__(**kwargs)</code> \u00b6 <p>Initializes a NestedNamespace with the given keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Key-value pairs to initialize the namespace.</p> <code>{}</code> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def __init__(self, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes a NestedNamespace with the given keyword arguments.\n\n    Args:\n        **kwargs: Key-value pairs to initialize the namespace.\n    \"\"\"\n    for key, value in kwargs.items():\n        if isinstance(value, dict):\n            # Recursively convert dictionaries to NestedNamespace\n            setattr(self, key, NestedNamespace(**value))\n        else:\n            setattr(self, key, value)\n</code></pre> <code>flatten(parent_key='', sep='.')</code> \u00b6 <p>Flattens the namespace into a single-level dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>parent_key</code> <code>str</code> <p>Prefix for the keys in the flattened dictionary.</p> <code>''</code> <code>sep</code> <code>str</code> <p>Separator for nested keys.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict with dot-separated keys representing the nested structure.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def flatten(self, parent_key: str = \"\", sep: str = \".\") -&gt; Dict[str, Any]:\n    \"\"\"Flattens the namespace into a single-level dictionary.\n\n    Args:\n        parent_key: Prefix for the keys in the flattened dictionary.\n        sep: Separator for nested keys.\n\n    Returns:\n        Dict with dot-separated keys representing the nested structure.\n    \"\"\"\n    items = []\n    for key, value in self.__dict__.items():\n        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n        if isinstance(value, NestedNamespace):\n            items.extend(value.flatten(new_key, sep=sep).items())\n        else:\n            items.append((new_key, value))\n    return dict(items)\n</code></pre> <code>to_dict()</code> \u00b6 <p>Converts the NestedNamespace back to a dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing the namespace attributes, with nested NestedNamespace</p> <code>Dict[str, Any]</code> <p>objects converted to dictionaries.</p> Source code in <code>gridfm_datakit/utils/param_handler.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Converts the NestedNamespace back to a dictionary.\n\n    Returns:\n        Dict containing the namespace attributes, with nested NestedNamespace\n        objects converted to dictionaries.\n    \"\"\"\n    result = {}\n    for key, value in self.__dict__.items():\n        if isinstance(value, NestedNamespace):\n            result[key] = value.to_dict()\n        else:\n            result[key] = value\n    return result\n</code></pre>"},{"location":"components/process_network/","title":"Process Network","text":"<p>This module provides functions for processing power networks.</p>"},{"location":"components/process_network/#network_preprocessing","title":"<code>network_preprocessing</code>","text":"<p>Adds names to bus dataframe and bus types to load, bus, gen, sgen dataframes.</p> <p>This function performs several preprocessing steps:</p> <ol> <li>Assigns names to all network components</li> <li>Determines bus types (PQ, PV, REF)</li> <li>Assigns bus types to connected components</li> <li>Performs validation checks on the network structure</li> </ol> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network to preprocess.</p> required <p>Raises:</p> Type Description <code>AssertionError</code> <p>If network structure violates expected constraints: - More than one load per bus - REF bus not matching ext_grid connection - PQ bus definition mismatch</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def network_preprocessing(net: pandapowerNet) -&gt; None:\n    \"\"\"Adds names to bus dataframe and bus types to load, bus, gen, sgen dataframes.\n\n    This function performs several preprocessing steps:\n\n    1. Assigns names to all network components\n    2. Determines bus types (PQ, PV, REF)\n    3. Assigns bus types to connected components\n    4. Performs validation checks on the network structure\n\n    Args:\n        net: The power network to preprocess.\n\n    Raises:\n        AssertionError: If network structure violates expected constraints:\n            - More than one load per bus\n            - REF bus not matching ext_grid connection\n            - PQ bus definition mismatch\n    \"\"\"\n    # Clean-Up things in Data-Frame // give numbered item names\n    for i, row in net.bus.iterrows():\n        net.bus.at[i, \"name\"] = \"Bus \" + str(i)\n    for i, row in net.load.iterrows():\n        net.load.at[i, \"name\"] = \"Load \" + str(i)\n    for i, row in net.sgen.iterrows():\n        net.sgen.at[i, \"name\"] = \"Sgen \" + str(i)\n    for i, row in net.gen.iterrows():\n        net.gen.at[i, \"name\"] = \"Gen \" + str(i)\n    for i, row in net.shunt.iterrows():\n        net.shunt.at[i, \"name\"] = \"Shunt \" + str(i)\n    for i, row in net.ext_grid.iterrows():\n        net.ext_grid.at[i, \"name\"] = \"Ext_Grid \" + str(i)\n    for i, row in net.line.iterrows():\n        net.line.at[i, \"name\"] = \"Line \" + str(i)\n    for i, row in net.trafo.iterrows():\n        net.trafo.at[i, \"name\"] = \"Trafo \" + str(i)\n\n    num_buses = len(net.bus)\n    bus_types = np.zeros(num_buses, dtype=int)\n\n    # assert one slack bus\n    assert len(net.ext_grid) == 1\n    indices_slack = np.unique(np.array(net.ext_grid[\"bus\"]))\n\n    indices_PV = np.union1d(\n        np.unique(np.array(net.sgen[\"bus\"])),\n        np.unique(np.array(net.gen[\"bus\"])),\n    )\n    indices_PV = np.setdiff1d(\n        indices_PV,\n        indices_slack,\n    )  # Exclude slack indices from PV indices\n\n    indices_PQ = np.setdiff1d(\n        np.arange(num_buses),\n        np.union1d(indices_PV, indices_slack),\n    )\n\n    bus_types[indices_PQ] = PQ  # Set PV bus types to 1\n    bus_types[indices_PV] = PV  # Set PV bus types to 2\n    bus_types[indices_slack] = REF  # Set Slack bus types to 3\n\n    net.bus[\"type\"] = bus_types\n\n    # assign type of the bus connected to each load and generator\n    net.load[\"type\"] = net.bus.type[net.load.bus].to_list()\n    net.gen[\"type\"] = net.bus.type[net.gen.bus].to_list()\n    net.sgen[\"type\"] = net.bus.type[net.sgen.bus].to_list()\n\n    # there is no more than one load per bus:\n    assert net.load.bus.unique().shape[0] == net.load.bus.shape[0]\n\n    # REF bus is bus with ext grid:\n    assert (\n        np.where(net.bus[\"type\"] == REF)[0]  # REF bus indicated by case file\n        == net.ext_grid.bus.values\n    ).all()  # Buses connected to an ext grid\n\n    # PQ buses are buses with no gen nor ext_grid, only load or nothing connected to them\n    assert (\n        (net.bus[\"type\"] == PQ)  # PQ buses indicated by case file\n        == ~np.isin(\n            range(net.bus.shape[0]),\n            np.concatenate(\n                [net.ext_grid.bus.values, net.gen.bus.values, net.sgen.bus.values],\n            ),\n        )\n    ).all()  # Buses which are NOT connected to a gen nor an ext grid\n</code></pre>"},{"location":"components/process_network/#pf_preprocessing","title":"<code>pf_preprocessing</code>","text":"<p>Sets variables to the results of OPF.</p> <p>Updates the following network components with OPF results:</p> <ul> <li>sgen.p_mw: active power generation for static generators</li> <li>gen.p_mw, gen.vm_pu: active power and voltage magnitude for generators</li> </ul> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network to preprocess.</p> required <p>Returns:</p> Type Description <code>pandapowerNet</code> <p>The updated power network with OPF results.</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def pf_preprocessing(net: pandapowerNet) -&gt; pandapowerNet:\n    \"\"\"Sets variables to the results of OPF.\n\n    Updates the following network components with OPF results:\n\n    - sgen.p_mw: active power generation for static generators\n    - gen.p_mw, gen.vm_pu: active power and voltage magnitude for generators\n\n    Args:\n        net: The power network to preprocess.\n\n    Returns:\n        The updated power network with OPF results.\n    \"\"\"\n    net.sgen[[\"p_mw\"]] = net.res_sgen[\n        [\"p_mw\"]\n    ]  # sgens are not voltage controlled, so we set P only\n    net.gen[[\"p_mw\", \"vm_pu\"]] = net.res_gen[[\"p_mw\", \"vm_pu\"]]\n    return net\n</code></pre>"},{"location":"components/process_network/#pf_post_processing","title":"<code>pf_post_processing</code>","text":"<p>Post-processes PF data to build the final data representation.</p> <p>Creates a matrix of shape (n_buses, 10) or (n_buses, 12) for DC power flow, with columns: (bus, Pd, Qd, Pg, Qg, Vm, Va, PQ, PV, REF) plus (Vm_dc, Va_dc) for DC power flow.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network to process.</p> required <code>dcpf</code> <code>bool</code> <p>Whether to include DC power flow results. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Matrix containing the processed power flow data.</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def pf_post_processing(net: pandapowerNet, dcpf: bool = False) -&gt; np.ndarray:\n    \"\"\"Post-processes PF data to build the final data representation.\n\n    Creates a matrix of shape (n_buses, 10) or (n_buses, 12) for DC power flow,\n    with columns: (bus, Pd, Qd, Pg, Qg, Vm, Va, PQ, PV, REF) plus (Vm_dc, Va_dc)\n    for DC power flow.\n\n    Args:\n        net: The power network to process.\n        dcpf: Whether to include DC power flow results. Defaults to False.\n\n    Returns:\n        numpy.ndarray: Matrix containing the processed power flow data.\n    \"\"\"\n    X = np.zeros((net.bus.shape[0], 12 if dcpf else 10))\n    all_loads = (\n        pd.concat([net.res_load])[[\"p_mw\", \"q_mvar\", \"bus\"]].groupby(\"bus\").sum()\n    )\n\n    all_gens = (\n        pd.concat([net.res_gen, net.res_sgen, net.res_ext_grid])[\n            [\"p_mw\", \"q_mvar\", \"bus\"]\n        ]\n        .groupby(\"bus\")\n        .sum()\n    )\n\n    assert (net.bus.index.values == list(range(X.shape[0]))).all()\n\n    X[:, 0] = net.bus.index.values\n\n    # Active and reactive power demand\n    X[all_loads.index, 1] = all_loads.p_mw  # Pd\n    X[all_loads.index, 2] = all_loads.q_mvar  # Qd\n\n    # Active and reactive power generated\n    X[net.bus.type == PV, 3] = all_gens.p_mw[\n        net.res_bus.type == PV\n    ]  # active Power generated\n    X[net.bus.type == PV, 4] = all_gens.q_mvar[\n        net.res_bus.type == PV\n    ]  # reactive Power generated\n    X[net.bus.type == REF, 3] = all_gens.p_mw[\n        net.res_bus.type == REF\n    ]  # active Power generated\n    X[net.bus.type == REF, 4] = all_gens.q_mvar[\n        net.res_bus.type == REF\n    ]  # reactive Power generated\n\n    # Voltage\n    X[:, 5] = net.res_bus.vm_pu  # voltage magnitude\n    X[:, 6] = net.res_bus.va_degree  # voltage angle\n    X[:, 7:10] = pd.get_dummies(net.bus[\"type\"]).values\n\n    if dcpf:\n        X[:, 10] = net.bus[\"Vm_dc\"]\n        X[:, 11] = net.bus[\"Va_dc\"]\n    return X\n</code></pre>"},{"location":"components/process_network/#get_adjacency_list","title":"<code>get_adjacency_list</code>","text":"<p>Gets adjacency list for network.</p> <p>Creates an adjacency list representation of the network's bus admittance matrix, including real and imaginary components of the admittance.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Array containing edge indices and attributes (G, B).</p> Source code in <code>gridfm_datakit/process/process_network.py</code> <pre><code>def get_adjacency_list(net: pandapowerNet) -&gt; np.ndarray:\n    \"\"\"Gets adjacency list for network.\n\n    Creates an adjacency list representation of the network's bus admittance matrix,\n    including real and imaginary components of the admittance.\n\n    Args:\n        net: The power network.\n\n    Returns:\n        numpy.ndarray: Array containing edge indices and attributes (G, B).\n    \"\"\"\n    ppc = net._ppc\n    Y_bus, Yf, Yt = makeYbus_pypower(ppc[\"baseMVA\"], ppc[\"bus\"], ppc[\"branch\"])\n\n    i, j = np.nonzero(Y_bus)\n    # note that Y_bus[i,j] can be != 0 even if a branch from i to j is not in service because there might be other branches connected to the same buses\n\n    s = Y_bus[i, j]\n    G = np.real(s)\n    B = np.imag(s)\n\n    edge_index = np.column_stack((i, j))\n    edge_attr = np.stack((G, B)).T\n    adjacency_lists = np.column_stack((edge_index, edge_attr))\n    return adjacency_lists\n</code></pre>"},{"location":"components/save/","title":"Save","text":"<p>This module provides functions for saving network data to files.</p>"},{"location":"components/save/#save_edge_params","title":"<code>save_edge_params</code>","text":"<p>Saves edge parameters for the network to a CSV file.</p> <p>Extracts and saves branch parameters including admittance matrices and rate limits.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>path</code> <code>str</code> <p>Path where the edge parameters CSV file should be saved.</p> required Source code in <code>gridfm_datakit/save.py</code> <pre><code>def save_edge_params(net: pandapowerNet, path: str):\n    \"\"\"Saves edge parameters for the network to a CSV file.\n\n    Extracts and saves branch parameters including admittance matrices and rate limits.\n\n    Args:\n        net: The power network.\n        path: Path where the edge parameters CSV file should be saved.\n    \"\"\"\n    pp.rundcpp(net)  # need to run dcpp to create the ppc structure\n    ppc = net._ppc\n    to_bus = np.real(ppc[\"branch\"][:, T_BUS])\n    from_bus = np.real(ppc[\"branch\"][:, F_BUS])\n    Ytt, Yff, Yft, Ytf = branch_vectors(ppc[\"branch\"], ppc[\"branch\"].shape[0])\n    Ytt_r = np.real(Ytt)\n    Ytt_i = np.imag(Ytt)\n    Yff_r = np.real(Yff)\n    Yff_i = np.imag(Yff)\n    Yft_r = np.real(Yft)\n    Yft_i = np.imag(Yft)\n    Ytf_r = np.real(Ytf)\n    Ytf_i = np.imag(Ytf)\n\n    rate_a = np.real(ppc[\"branch\"][:, RATE_A])\n    edge_params = pd.DataFrame(\n        np.column_stack(\n            (\n                from_bus,\n                to_bus,\n                Yff_r,\n                Yff_i,\n                Yft_r,\n                Yft_i,\n                Ytf_r,\n                Ytf_i,\n                Ytt_r,\n                Ytt_i,\n                rate_a,\n            ),\n        ),\n        columns=[\n            \"from_bus\",\n            \"to_bus\",\n            \"Yff_r\",\n            \"Yff_i\",\n            \"Yft_r\",\n            \"Yft_i\",\n            \"Ytf_r\",\n            \"Ytf_i\",\n            \"Ytt_r\",\n            \"Ytt_i\",\n            \"rate_a\",\n        ],\n    )\n    # comvert everything to float32\n    edge_params = edge_params.astype(np.float32)\n    edge_params.to_csv(path, index=False)\n</code></pre>"},{"location":"components/save/#save_bus_params","title":"<code>save_bus_params</code>","text":"<p>Saves bus parameters for the network to a CSV file.</p> <p>Extracts and saves bus parameters including voltage limits and base values.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>path</code> <code>str</code> <p>Path where the bus parameters CSV file should be saved.</p> required Source code in <code>gridfm_datakit/save.py</code> <pre><code>def save_bus_params(net: pandapowerNet, path: str):\n    \"\"\"Saves bus parameters for the network to a CSV file.\n\n    Extracts and saves bus parameters including voltage limits and base values.\n\n    Args:\n        net: The power network.\n        path: Path where the bus parameters CSV file should be saved.\n    \"\"\"\n    idx = net.bus.index\n    base_kv = net.bus.vn_kv\n    bus_type = net.bus.type\n    vmin = net.bus.min_vm_pu\n    vmax = net.bus.max_vm_pu\n\n    bus_params = pd.DataFrame(\n        np.column_stack((idx, bus_type, vmin, vmax, base_kv)),\n        columns=[\"bus\", \"type\", \"vmin\", \"vmax\", \"baseKV\"],\n    )\n    bus_params.to_csv(path, index=False)\n</code></pre>"},{"location":"components/save/#save_branch_idx_removed","title":"<code>save_branch_idx_removed</code>","text":"<p>Saves indices of removed branches for each scenario.</p> <p>Appends the removed branch indices to an existing CSV file or creates a new one.</p> <p>Parameters:</p> Name Type Description Default <code>branch_idx_removed</code> <code>List[List[int]]</code> <p>List of removed branch indices for each scenario.</p> required <code>path</code> <code>str</code> <p>Path where the branch indices CSV file should be saved.</p> required Source code in <code>gridfm_datakit/save.py</code> <pre><code>def save_branch_idx_removed(branch_idx_removed: List[List[int]], path: str):\n    \"\"\"Saves indices of removed branches for each scenario.\n\n    Appends the removed branch indices to an existing CSV file or creates a new one.\n\n    Args:\n        branch_idx_removed: List of removed branch indices for each scenario.\n        path: Path where the branch indices CSV file should be saved.\n    \"\"\"\n    if os.path.exists(path):\n        existing_df = pd.read_csv(path, usecols=[\"scenario\"])\n        if not existing_df.empty:\n            last_scenario = existing_df[\"scenario\"].iloc[-1]\n    else:\n        last_scenario = -1\n\n    scenario_idx = np.arange(\n        last_scenario + 1,\n        last_scenario + 1 + len(branch_idx_removed),\n    )\n    branch_idx_removed_df = pd.DataFrame(branch_idx_removed)\n    branch_idx_removed_df.insert(0, \"scenario\", scenario_idx)\n    branch_idx_removed_df.to_csv(\n        path,\n        mode=\"a\",\n        header=not os.path.exists(path),\n        index=False,\n    )  # append to existing file or create new one\n</code></pre>"},{"location":"components/save/#save_node_edge_data","title":"<code>save_node_edge_data</code>","text":"<p>Saves generated node and edge data to CSV files.</p> <p>Saves generated data for nodes and edges, appending to existing files if they exist.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <code>node_path</code> <code>str</code> <p>Path where node data should be saved.</p> required <code>edge_path</code> <code>str</code> <p>Path where edge data should be saved.</p> required <code>csv_data</code> <code>list</code> <p>List of node-level data for each scenario.</p> required <code>adjacency_lists</code> <code>list</code> <p>List of edge-level adjacency lists for each scenario.</p> required <code>mode</code> <code>str</code> <p>Analysis mode, either 'pf' for power flow or 'contingency' for contingency analysis.</p> <code>'pf'</code> Source code in <code>gridfm_datakit/save.py</code> <pre><code>def save_node_edge_data(\n    net: pandapowerNet,\n    node_path: str,\n    edge_path: str,\n    csv_data: list,\n    adjacency_lists: list,\n    mode: str = \"pf\",\n):\n    \"\"\"Saves generated node and edge data to CSV files.\n\n    Saves generated data for nodes and edges,\n    appending to existing files if they exist.\n\n    Args:\n        net: The power network.\n        node_path: Path where node data should be saved.\n        edge_path: Path where edge data should be saved.\n        csv_data: List of node-level data for each scenario.\n        adjacency_lists: List of edge-level adjacency lists for each scenario.\n        mode: Analysis mode, either 'pf' for power flow or 'contingency' for contingency analysis.\n    \"\"\"\n    n_buses = net.bus.shape[0]\n\n    # Determine last scenario index\n    last_scenario = -1\n    if os.path.exists(node_path):\n        existing_df = pd.read_csv(node_path, usecols=[\"scenario\"])\n        if not existing_df.empty:\n            last_scenario = existing_df[\"scenario\"].iloc[-1]\n\n    # Create DataFrame for node data\n    if mode == \"pf\":\n        df = pd.DataFrame(\n            csv_data,\n            columns=[\n                \"bus\",\n                \"Pd\",\n                \"Qd\",\n                \"Pg\",\n                \"Qg\",\n                \"Vm\",\n                \"Va\",\n                \"PQ\",\n                \"PV\",\n                \"REF\",\n            ],\n        )\n    elif (\n        mode == \"contingency\"\n    ):  # we add the dc voltage to the node data for benchmarking purposes\n        df = pd.DataFrame(\n            csv_data,\n            columns=[\n                \"bus\",\n                \"Pd\",\n                \"Qd\",\n                \"Pg\",\n                \"Qg\",\n                \"Vm\",\n                \"Va\",\n                \"PQ\",\n                \"PV\",\n                \"REF\",\n                \"Vm_dc\",\n                \"Va_dc\",\n            ],\n        )\n\n    df[\"bus\"] = df[\"bus\"].astype(\"int64\")\n\n    # Shift scenario indices\n    scenario_indices = np.repeat(\n        range(last_scenario + 1, last_scenario + 1 + (df.shape[0] // n_buses)),\n        n_buses,\n    )  # repeat each scenario index n_buses times since there are n_buses rows for each scenario\n    df.insert(0, \"scenario\", scenario_indices)\n\n    # Append to CSV\n    df.to_csv(node_path, mode=\"a\", header=not os.path.exists(node_path), index=False)\n\n    # Create DataFrame for edge data\n    adj_df = pd.DataFrame(\n        np.concatenate(adjacency_lists),\n        columns=[\"index1\", \"index2\", \"G\", \"B\"],\n    )\n\n    adj_df[[\"index1\", \"index2\"]] = adj_df[[\"index1\", \"index2\"]].astype(\"int64\")\n\n    # Shift scenario indices\n    scenario_indices = np.concatenate(\n        [\n            np.full(adjacency_lists[i].shape[0], last_scenario + 1 + i, dtype=\"int64\")\n            for i in range(len(adjacency_lists))\n        ],\n    )  # for each scenario, we repeat the scenario index as many times as there are edges in the scenario\n    adj_df.insert(0, \"scenario\", scenario_indices)\n\n    # Append to CSV\n    adj_df.to_csv(\n        edge_path,\n        mode=\"a\",\n        header=not os.path.exists(edge_path),\n        index=False,\n    )\n</code></pre>"},{"location":"components/solvers/","title":"Solvers","text":"<p>This module provides functions for running power flow calculations.</p>"},{"location":"components/solvers/#run_opf","title":"<code>run_opf</code>","text":"<p>Runs Optimal Power Flow (OPF) and adds additional information to network elements.</p> <p>This function runs the OPF calculation and adds bus index and type information to the results dataframes. It also performs various validation checks on the results.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>A pandapower network object containing the power system model.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to pp.runopp().</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the OPF converged successfully, False otherwise.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any of the validation checks fail, including: - Mismatch in active/reactive power - Power bounds violations - Bus power mismatches - Power balance violations</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_opf(net: pandapowerNet, **kwargs: Any) -&gt; bool:\n    \"\"\"Runs Optimal Power Flow (OPF) and adds additional information to network elements.\n\n    This function runs the OPF calculation and adds bus index and type information to the\n    results dataframes. It also performs various validation checks on the results.\n\n    Args:\n        net: A pandapower network object containing the power system model.\n        **kwargs: Additional keyword arguments to pass to pp.runopp().\n\n    Returns:\n        bool: True if the OPF converged successfully, False otherwise.\n\n    Raises:\n        AssertionError: If any of the validation checks fail, including:\n            - Mismatch in active/reactive power\n            - Power bounds violations\n            - Bus power mismatches\n            - Power balance violations\n    \"\"\"\n\n    pp.runopp(net, numba=True, **kwargs)\n\n    # add bus index and type to dataframe of opf results\n    net.res_gen[\"bus\"] = net.gen.bus\n    net.res_gen[\"type\"] = net.gen.type\n    net.res_load[\"bus\"] = net.load.bus\n    net.res_load[\"type\"] = net.load.type\n    net.res_sgen[\"bus\"] = net.sgen.bus\n    net.res_sgen[\"type\"] = net.sgen.type\n    net.res_shunt[\"bus\"] = net.shunt.bus\n    net.res_ext_grid[\"bus\"] = net.ext_grid.bus\n    net.res_bus[\"type\"] = net.bus[\"type\"]\n\n    # The load of course stays the same as before\n    assert (net.load.p_mw == net.res_load.p_mw).all(), \"Active power load has changed\"\n    assert (net.load.q_mvar == net.res_load.q_mvar).all(), (\n        \"Reactive power load has changed\"\n    )\n\n    # Checking bounds on active and reactive power\n    # TODO: see with matteo how we want to handle this\n    if len(net.gen) != 0:\n        in_service_gen = net.gen[net.gen.in_service]\n        in_service_res_gen = net.res_gen[net.gen.in_service]\n\n        if \"max_p_mw\" in net.gen.columns and \"min_p_mw\" in net.gen.columns:\n            valid_gen = in_service_gen.dropna(\n                subset=[\"max_p_mw\", \"min_p_mw\"],\n                how=\"any\",\n            )\n            valid_res_gen = in_service_res_gen.loc[valid_gen.index]\n\n            if not valid_gen.empty:\n                assert (valid_gen.max_p_mw - valid_res_gen.p_mw &gt; -1e-4).all(), (\n                    f\"Active power exceeds upper bound: \"\n                    f\"{valid_res_gen.p_mw[valid_gen.max_p_mw - valid_res_gen.p_mw &lt;= -1e-4]} exceeds \"\n                    f\"{valid_gen.max_p_mw[valid_gen.max_p_mw - valid_res_gen.p_mw &lt;= -1e-4]}\"\n                )\n                assert (valid_res_gen.p_mw - valid_gen.min_p_mw &gt; -1e-4).all(), (\n                    f\"Active power falls below lower bound: \"\n                    f\"{valid_res_gen.p_mw[valid_res_gen.p_mw - valid_gen.min_p_mw &lt;= -1e-4]} below \"\n                    f\"{valid_gen.min_p_mw[valid_res_gen.p_mw - valid_gen.min_p_mw &lt;= -1e-4]}\"\n                )\n\n        if \"max_q_mvar\" in net.gen.columns and \"min_q_mvar\" in net.gen.columns:\n            valid_q_gen = in_service_gen.dropna(\n                subset=[\"max_q_mvar\", \"min_q_mvar\"],\n                how=\"any\",\n            )\n            valid_q_res_gen = in_service_res_gen.loc[valid_q_gen.index]\n\n            if not valid_q_gen.empty:\n                assert (\n                    valid_q_gen.max_q_mvar - valid_q_res_gen.q_mvar &gt; -1e-4\n                ).all(), (\n                    f\"Reactive power exceeds upper bound: \"\n                    f\"{valid_q_res_gen.q_mvar[valid_q_gen.max_q_mvar - valid_q_res_gen.q_mvar &lt;= -1e-4]} exceeds \"\n                    f\"{valid_q_gen.max_q_mvar[valid_q_gen.max_q_mvar - valid_q_res_gen.q_mvar &lt;= -1e-4]}\"\n                )\n                assert (\n                    valid_q_res_gen.q_mvar - valid_q_gen.min_q_mvar &gt; -1e-4\n                ).all(), (\n                    f\"Reactive power falls below lower bound: \"\n                    f\"{valid_q_res_gen.q_mvar[valid_q_res_gen.q_mvar - valid_q_gen.min_q_mvar &lt;= -1e-4]} below \"\n                    f\"{valid_q_gen.min_q_mvar[valid_q_res_gen.q_mvar - valid_q_gen.min_q_mvar &lt;= -1e-4]}\"\n                )\n\n    if len(net.sgen) != 0:\n        in_service_sgen = net.sgen[net.sgen.in_service]\n        in_service_res_sgen = net.res_sgen[net.sgen.in_service]\n\n        if \"max_p_mw\" in net.sgen.columns and \"min_p_mw\" in net.sgen.columns:\n            valid_sgen = in_service_sgen.dropna(\n                subset=[\"max_p_mw\", \"min_p_mw\"],\n                how=\"any\",\n            )\n            valid_res_sgen = in_service_res_sgen.loc[valid_sgen.index]\n\n            if not valid_sgen.empty:\n                assert (valid_sgen.max_p_mw - valid_res_sgen.p_mw &gt; -1e-4).all(), (\n                    f\"Active power exceeds upper bound for static generators: \"\n                    f\"{valid_res_sgen.p_mw[valid_sgen.max_p_mw - valid_res_sgen.p_mw &lt;= -1e-4]} exceeds \"\n                    f\"{valid_sgen.max_p_mw[valid_sgen.max_p_mw - valid_res_sgen.p_mw &lt;= -1e-4]}\"\n                )\n                assert (valid_res_sgen.p_mw - valid_sgen.min_p_mw &gt; -1e-4).all(), (\n                    f\"Active power falls below lower bound for static generators: \"\n                    f\"{valid_res_sgen.p_mw[valid_res_sgen.p_mw - valid_sgen.min_p_mw &lt;= -1e-4]} below \"\n                    f\"{valid_sgen.min_p_mw[valid_res_sgen.p_mw - valid_sgen.min_p_mw &lt;= -1e-4]}\"\n                )\n\n        if \"max_q_mvar\" in net.sgen.columns and \"min_q_mvar\" in net.sgen.columns:\n            valid_q_sgen = in_service_sgen.dropna(\n                subset=[\"max_q_mvar\", \"min_q_mvar\"],\n                how=\"any\",\n            )\n            valid_q_res_sgen = in_service_res_sgen.loc[valid_q_sgen.index]\n\n            if not valid_q_sgen.empty:\n                assert (\n                    valid_q_sgen.max_q_mvar - valid_q_res_sgen.q_mvar &gt; -1e-4\n                ).all(), (\n                    f\"Reactive power exceeds upper bound for static generators: \"\n                    f\"{valid_q_res_sgen.q_mvar[valid_q_sgen.max_q_mvar - valid_q_res_sgen.q_mvar &lt;= -1e-4]} exceeds \"\n                    f\"{valid_q_sgen.max_q_mvar[valid_q_sgen.max_q_mvar - valid_q_res_sgen.q_mvar &lt;= -1e-4]}\"\n                )\n                assert (\n                    valid_q_res_sgen.q_mvar - valid_q_sgen.min_q_mvar &gt; -1e-4\n                ).all(), (\n                    f\"Reactive power falls below lower bound for static generators: \"\n                    f\"{valid_q_res_sgen.q_mvar[valid_q_res_sgen.q_mvar - valid_q_sgen.min_q_mvar &lt;= -1e-4]} below \"\n                    f\"{valid_q_sgen.min_q_mvar[valid_q_res_sgen.q_mvar - valid_q_sgen.min_q_mvar &lt;= -1e-4]}\"\n                )\n\n    total_p_diff, total_q_diff = calculate_power_imbalance(net)\n    assert np.abs(total_q_diff) &lt; 1e-1, (\n        f\"Total reactive power imbalance in OPF: {total_q_diff}\"\n    )\n    assert np.abs(total_p_diff) &lt; 1e-1, (\n        f\"Total active power imbalance in OPF: {total_p_diff}\"\n    )\n\n    return net.OPF_converged\n</code></pre>"},{"location":"components/solvers/#run_pf","title":"<code>run_pf</code>","text":"<p>Runs Power Flow (PF) calculation and adds additional information to network elements.</p> <p>This function runs the power flow calculation and adds bus index and type information to the results dataframes. It also performs validation checks on the results.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>A pandapower network object containing the power system model.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to pp.runpp().</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the power flow converged successfully, False otherwise.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any of the validation checks fail, including: - Bus power mismatches - Power balance violations</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_pf(net: pandapowerNet, **kwargs: Any) -&gt; bool:\n    \"\"\"Runs Power Flow (PF) calculation and adds additional information to network elements.\n\n    This function runs the power flow calculation and adds bus index and type information\n    to the results dataframes. It also performs validation checks on the results.\n\n    Args:\n        net: A pandapower network object containing the power system model.\n        **kwargs: Additional keyword arguments to pass to pp.runpp().\n\n    Returns:\n        bool: True if the power flow converged successfully, False otherwise.\n\n    Raises:\n        AssertionError: If any of the validation checks fail, including:\n            - Bus power mismatches\n            - Power balance violations\n    \"\"\"\n    pp.runpp(net, **kwargs)\n\n    # add bus number to df of opf results\n    net.res_gen[\"bus\"] = net.gen.bus\n    net.res_gen[\"type\"] = net.gen.type\n\n    net.res_load[\"bus\"] = net.load.bus\n    net.res_load[\"type\"] = net.load.type\n\n    net.res_sgen[\"bus\"] = net.sgen.bus\n    net.res_sgen[\"type\"] = net.sgen.type\n\n    net.res_shunt[\"bus\"] = net.shunt.bus\n    net.res_ext_grid[\"bus\"] = net.ext_grid.bus\n    net.res_bus[\"type\"] = net.bus[\"type\"]\n\n    total_p_diff, total_q_diff = calculate_power_imbalance(net)\n\n    assert np.abs(total_q_diff) &lt; 1e-2, (\n        f\"Total reactive power imbalance in PF: {total_q_diff}\"\n    )\n    assert np.abs(total_p_diff) &lt; 1e-2, (\n        f\"Total active power imbalance in PF: {total_p_diff}\"\n    )\n\n    return net.converged\n</code></pre>"},{"location":"components/solvers/#run_dcpf","title":"<code>run_dcpf</code>","text":"<p>Runs DC Power Flow (DCPF) calculation and adds additional information to network elements.</p> <p>This function runs the DC power flow calculation and adds bus index and type information to the results dataframes. It also performs validation checks on the results.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>A pandapower network object containing the power system model.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to pp.rundcpp().</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the DC power flow converged successfully, False otherwise.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If any of the validation checks fail, including: - Bus power mismatches</p> Source code in <code>gridfm_datakit/process/solvers.py</code> <pre><code>def run_dcpf(net: pandapowerNet, **kwargs: Any) -&gt; bool:\n    \"\"\"Runs DC Power Flow (DCPF) calculation and adds additional information to network elements.\n\n    This function runs the DC power flow calculation and adds bus index and type information\n    to the results dataframes. It also performs validation checks on the results.\n\n    Args:\n        net: A pandapower network object containing the power system model.\n        **kwargs: Additional keyword arguments to pass to pp.rundcpp().\n\n    Returns:\n        bool: True if the DC power flow converged successfully, False otherwise.\n\n    Raises:\n        AssertionError: If any of the validation checks fail, including:\n            - Bus power mismatches\n    \"\"\"\n    pp.rundcpp(net, **kwargs)\n\n    # add bus number to df of opf results\n    net.res_gen[\"bus\"] = net.gen.bus\n    net.res_gen[\"type\"] = net.gen.type\n\n    net.res_load[\"bus\"] = net.load.bus\n    net.res_load[\"type\"] = net.load.type\n\n    net.res_sgen[\"bus\"] = net.sgen.bus\n    net.res_sgen[\"type\"] = net.sgen.type\n\n    net.res_shunt[\"bus\"] = net.shunt.bus\n    net.res_ext_grid[\"bus\"] = net.ext_grid.bus\n    net.res_bus[\"type\"] = net.bus[\"type\"]\n\n    total_p_diff, total_q_diff = calculate_power_imbalance(net)\n\n    print(\n        \"Total reactive power imbalance in DCPF: \",\n        total_q_diff,\n        \" (It is normal that this is not 0 as we are using a DC model)\",\n    )\n    print(\n        \"Total active power imbalance in DCPF: \",\n        total_p_diff,\n        \" (Should be close to 0)\",\n    )\n\n    return net.converged\n</code></pre>"},{"location":"components/stats/","title":"Stats","text":"<p>This module provides functions and classes for tracking and analyzing statistics related to power grid networks.</p>"},{"location":"components/stats/#plot_stats","title":"<code>plot_stats</code>","text":"<p>Generates and saves HTML plots of network statistics.</p> <p>Creates histograms for various network statistics including number of generators, lines, transformers, overloads, and maximum loading. Saves the plots to an HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Directory path where the stats CSV file is located and where the HTML plot will be saved.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If stats.csv is not found in the base_path directory.</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def plot_stats(base_path: str) -&gt; None:\n    \"\"\"Generates and saves HTML plots of network statistics.\n\n    Creates histograms for various network statistics including number of generators,\n    lines, transformers, overloads, and maximum loading. Saves the plots to an HTML file.\n\n    Args:\n        base_path: Directory path where the stats CSV file is located and where\n            the HTML plot will be saved.\n\n    Raises:\n        FileNotFoundError: If stats.csv is not found in the base_path directory.\n    \"\"\"\n    stats_to_plot = Stats()\n    stats_to_plot.load(base_path)\n    filename = base_path + \"/stats_plot.html\"\n\n    with open(filename, \"w\") as f:\n        # Plot for n_generators\n        fig_generators = px.histogram(stats_to_plot.n_generators)\n        fig_generators.update_layout(xaxis_title=\"Number of Generators\")\n        f.write(fig_generators.to_html(full_html=False, include_plotlyjs=\"cdn\"))\n\n        # Plot for n_lines\n        fig_lines = px.histogram(stats_to_plot.n_lines)\n        fig_lines.update_layout(xaxis_title=\"Number of Lines\")\n        f.write(fig_lines.to_html(full_html=False, include_plotlyjs=False))\n\n        # Plot for n_trafos\n        fig_trafos = px.histogram(stats_to_plot.n_trafos)\n        fig_trafos.update_layout(xaxis_title=\"Number of Transformers\")\n        f.write(fig_trafos.to_html(full_html=False, include_plotlyjs=False))\n\n        # Plot for n_overloads\n        fig_overloads = px.histogram(stats_to_plot.n_overloads)\n        fig_overloads.update_layout(xaxis_title=\"Number of Overloads\")\n        f.write(fig_overloads.to_html(full_html=False, include_plotlyjs=False))\n\n        # Plot for max_loading\n        fig_max_loading = px.histogram(stats_to_plot.max_loading)\n        fig_max_loading.update_layout(xaxis_title=\"Max Loading\")\n        f.write(fig_max_loading.to_html(full_html=False, include_plotlyjs=False))\n\n        # Plot for total_p_diff\n        fig_total_p_diff = px.histogram(stats_to_plot.total_p_diff)\n        fig_total_p_diff.update_layout(xaxis_title=\"Total Active Power Imbalance\")\n        f.write(fig_total_p_diff.to_html(full_html=False, include_plotlyjs=False))\n\n        # Plot for total_q_diff\n        fig_total_q_diff = px.histogram(stats_to_plot.total_q_diff)\n        fig_total_q_diff.update_layout(xaxis_title=\"Total Reactive Power Imbalance\")\n        f.write(fig_total_q_diff.to_html(full_html=False, include_plotlyjs=False))\n</code></pre>"},{"location":"components/stats/#classes","title":"Classes","text":""},{"location":"components/stats/#stats_1","title":"<code>Stats</code>","text":"<p>A class to track and analyze statistics related to power grid networks.</p> <p>This class maintains data lists of various network metrics including number of lines, transformers, generators, overloads, maximum loading, total active power imbalance, and total reactive power imbalance.</p> <p>Attributes:</p> Name Type Description <code>n_lines</code> <p>List of number of in-service lines over time.</p> <code>n_trafos</code> <p>List of number of in-service transformers over time.</p> <code>n_generators</code> <p>List of total in-service generators (gen + sgen) over time.</p> <code>n_overloads</code> <p>List of number of overloaded elements over time.</p> <code>max_loading</code> <p>List of maximum loading percentages over time.</p> <code>total_p_diff</code> <p>List of total active power imbalance over time.</p> <code>total_q_diff</code> <p>List of total reactive power imbalance over time.</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>class Stats:  # network stats\n    \"\"\"A class to track and analyze statistics related to power grid networks.\n\n    This class maintains data lists of various network metrics including\n    number of lines, transformers, generators, overloads, maximum loading, total active power imbalance, and total reactive power imbalance.\n\n    Attributes:\n        n_lines: List of number of in-service lines over time.\n        n_trafos: List of number of in-service transformers over time.\n        n_generators: List of total in-service generators (gen + sgen) over time.\n        n_overloads: List of number of overloaded elements over time.\n        max_loading: List of maximum loading percentages over time.\n        total_p_diff: List of total active power imbalance over time.\n        total_q_diff: List of total reactive power imbalance over time.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initializes the Stats object with empty lists for all tracked metrics.\"\"\"\n        self.n_lines = []\n        self.n_trafos = []\n        self.n_generators = []\n        self.n_overloads = []\n        self.max_loading = []\n        self.total_p_diff = []\n        self.total_q_diff = []\n\n    def update(self, net: pandapowerNet) -&gt; None:\n        \"\"\"Adds the current state of the network to the data lists.\n\n        Args:\n            net: A pandapower network object containing the current state of the grid.\n        \"\"\"\n        self.n_lines.append(net.line.in_service.sum())\n        self.n_trafos.append(net.trafo.in_service.sum())\n        self.n_generators.append(net.gen.in_service.sum() + net.sgen.in_service.sum())\n        self.n_overloads.append(\n            np.sum(\n                [\n                    (net.res_line[\"loading_percent\"] &gt; 100.01).sum(),\n                    (net.res_trafo[\"loading_percent\"] &gt; 100.01).sum(),\n                ],\n            ),\n        )\n\n        self.max_loading.append(\n            np.max(\n                [\n                    net.res_line[\"loading_percent\"].max(),\n                    net.res_trafo[\"loading_percent\"].max(),\n                ],\n            ),\n        )\n        total_p_diff, total_q_diff = calculate_power_imbalance(net)\n        self.total_p_diff.append(total_p_diff)\n        self.total_q_diff.append(total_q_diff)\n\n    def merge(self, other: \"Stats\") -&gt; None:\n        \"\"\"Merges another Stats object into this one.\n\n        Args:\n            other: Another Stats object whose data will be merged into this one.\n        \"\"\"\n        self.n_lines.extend(other.n_lines)\n        self.n_trafos.extend(other.n_trafos)\n        self.n_generators.extend(other.n_generators)\n        self.n_overloads.extend(other.n_overloads)\n        self.max_loading.extend(other.max_loading)\n        self.total_p_diff.extend(other.total_p_diff)\n        self.total_q_diff.extend(other.total_q_diff)\n\n    def save(self, base_path: str) -&gt; None:\n        \"\"\"Saves the tracked statistics to a CSV file.\n\n        If the file already exists, appends the new data with a continuous index.\n        If the file doesn't exist, creates a new file.\n\n        Args:\n            base_path: Directory path where the CSV file will be saved.\n        \"\"\"\n        filename = os.path.join(base_path, \"stats.csv\")\n\n        new_data = pd.DataFrame(\n            {\n                \"n_lines\": self.n_lines,\n                \"n_trafos\": self.n_trafos,\n                \"n_generators\": self.n_generators,\n                \"n_overloads\": self.n_overloads,\n                \"max_loading\": self.max_loading,\n                \"total_p_diff\": self.total_p_diff,\n                \"total_q_diff\": self.total_q_diff,\n            },\n        )\n\n        if os.path.exists(filename):\n            # Read existing file to determine the new index start\n            existing_data = pd.read_csv(filename)\n            start_index = existing_data.index[-1] + 1 if not existing_data.empty else 0\n            new_data.index = range(start_index, start_index + len(new_data))\n\n            new_data.to_csv(filename, mode=\"a\", header=False)\n        else:\n            new_data.to_csv(filename, index=True)\n\n    def load(self, base_path: str) -&gt; None:\n        \"\"\"Loads the tracked statistics from a CSV file.\n\n        Args:\n            base_path: Directory path where the CSV file is saved.\n\n        Raises:\n            FileNotFoundError: If stats.csv is not found in the base_path directory.\n        \"\"\"\n        filename = os.path.join(base_path, \"stats.csv\")\n        df = pd.read_csv(filename)\n        self.n_lines = df[\"n_lines\"].values\n        self.n_trafos = df[\"n_trafos\"].values\n        self.n_generators = df[\"n_generators\"].values\n        self.n_overloads = df[\"n_overloads\"].values\n        self.max_loading = df[\"max_loading\"].values\n        self.total_p_diff = df[\"total_p_diff\"].values\n        self.total_q_diff = df[\"total_q_diff\"].values\n</code></pre> <code>__init__()</code> \u00b6 <p>Initializes the Stats object with empty lists for all tracked metrics.</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initializes the Stats object with empty lists for all tracked metrics.\"\"\"\n    self.n_lines = []\n    self.n_trafos = []\n    self.n_generators = []\n    self.n_overloads = []\n    self.max_loading = []\n    self.total_p_diff = []\n    self.total_q_diff = []\n</code></pre> <code>load(base_path)</code> \u00b6 <p>Loads the tracked statistics from a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Directory path where the CSV file is saved.</p> required <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If stats.csv is not found in the base_path directory.</p> Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def load(self, base_path: str) -&gt; None:\n    \"\"\"Loads the tracked statistics from a CSV file.\n\n    Args:\n        base_path: Directory path where the CSV file is saved.\n\n    Raises:\n        FileNotFoundError: If stats.csv is not found in the base_path directory.\n    \"\"\"\n    filename = os.path.join(base_path, \"stats.csv\")\n    df = pd.read_csv(filename)\n    self.n_lines = df[\"n_lines\"].values\n    self.n_trafos = df[\"n_trafos\"].values\n    self.n_generators = df[\"n_generators\"].values\n    self.n_overloads = df[\"n_overloads\"].values\n    self.max_loading = df[\"max_loading\"].values\n    self.total_p_diff = df[\"total_p_diff\"].values\n    self.total_q_diff = df[\"total_q_diff\"].values\n</code></pre> <code>merge(other)</code> \u00b6 <p>Merges another Stats object into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Stats</code> <p>Another Stats object whose data will be merged into this one.</p> required Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def merge(self, other: \"Stats\") -&gt; None:\n    \"\"\"Merges another Stats object into this one.\n\n    Args:\n        other: Another Stats object whose data will be merged into this one.\n    \"\"\"\n    self.n_lines.extend(other.n_lines)\n    self.n_trafos.extend(other.n_trafos)\n    self.n_generators.extend(other.n_generators)\n    self.n_overloads.extend(other.n_overloads)\n    self.max_loading.extend(other.max_loading)\n    self.total_p_diff.extend(other.total_p_diff)\n    self.total_q_diff.extend(other.total_q_diff)\n</code></pre> <code>save(base_path)</code> \u00b6 <p>Saves the tracked statistics to a CSV file.</p> <p>If the file already exists, appends the new data with a continuous index. If the file doesn't exist, creates a new file.</p> <p>Parameters:</p> Name Type Description Default <code>base_path</code> <code>str</code> <p>Directory path where the CSV file will be saved.</p> required Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def save(self, base_path: str) -&gt; None:\n    \"\"\"Saves the tracked statistics to a CSV file.\n\n    If the file already exists, appends the new data with a continuous index.\n    If the file doesn't exist, creates a new file.\n\n    Args:\n        base_path: Directory path where the CSV file will be saved.\n    \"\"\"\n    filename = os.path.join(base_path, \"stats.csv\")\n\n    new_data = pd.DataFrame(\n        {\n            \"n_lines\": self.n_lines,\n            \"n_trafos\": self.n_trafos,\n            \"n_generators\": self.n_generators,\n            \"n_overloads\": self.n_overloads,\n            \"max_loading\": self.max_loading,\n            \"total_p_diff\": self.total_p_diff,\n            \"total_q_diff\": self.total_q_diff,\n        },\n    )\n\n    if os.path.exists(filename):\n        # Read existing file to determine the new index start\n        existing_data = pd.read_csv(filename)\n        start_index = existing_data.index[-1] + 1 if not existing_data.empty else 0\n        new_data.index = range(start_index, start_index + len(new_data))\n\n        new_data.to_csv(filename, mode=\"a\", header=False)\n    else:\n        new_data.to_csv(filename, index=True)\n</code></pre> <code>update(net)</code> \u00b6 <p>Adds the current state of the network to the data lists.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>A pandapower network object containing the current state of the grid.</p> required Source code in <code>gridfm_datakit/utils/stats.py</code> <pre><code>def update(self, net: pandapowerNet) -&gt; None:\n    \"\"\"Adds the current state of the network to the data lists.\n\n    Args:\n        net: A pandapower network object containing the current state of the grid.\n    \"\"\"\n    self.n_lines.append(net.line.in_service.sum())\n    self.n_trafos.append(net.trafo.in_service.sum())\n    self.n_generators.append(net.gen.in_service.sum() + net.sgen.in_service.sum())\n    self.n_overloads.append(\n        np.sum(\n            [\n                (net.res_line[\"loading_percent\"] &gt; 100.01).sum(),\n                (net.res_trafo[\"loading_percent\"] &gt; 100.01).sum(),\n            ],\n        ),\n    )\n\n    self.max_loading.append(\n        np.max(\n            [\n                net.res_line[\"loading_percent\"].max(),\n                net.res_trafo[\"loading_percent\"].max(),\n            ],\n        ),\n    )\n    total_p_diff, total_q_diff = calculate_power_imbalance(net)\n    self.total_p_diff.append(total_p_diff)\n    self.total_q_diff.append(total_q_diff)\n</code></pre>"},{"location":"components/topology/","title":"Topology Perturbations","text":"<p>This module provides classes for generating perturbed network topologies.</p>"},{"location":"components/topology/#topologygenerator","title":"<code>TopologyGenerator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for generating perturbed network topologies.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class TopologyGenerator(ABC):\n    \"\"\"Abstract base class for generating perturbed network topologies.\"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the topology generator.\"\"\"\n        pass\n\n    @abstractmethod\n    def generate(\n        self,\n        net: pp.pandapowerNet,\n    ) -&gt; Union[Generator[pp.pandapowerNet, None, None], List[pp.pandapowerNet]]:\n        \"\"\"Generate perturbed topologies.\n\n        Args:\n            net: The power network to perturb.\n\n        Yields:\n            A perturbed network topology.\n        \"\"\"\n        pass\n</code></pre> <code>__init__()</code> \u00b6 <p>Initialize the topology generator.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the topology generator.\"\"\"\n    pass\n</code></pre> <code>generate(net)</code> <code>abstractmethod</code> \u00b6 <p>Generate perturbed topologies.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network to perturb.</p> required <p>Yields:</p> Type Description <code>Union[Generator[pandapowerNet, None, None], List[pandapowerNet]]</code> <p>A perturbed network topology.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>@abstractmethod\ndef generate(\n    self,\n    net: pp.pandapowerNet,\n) -&gt; Union[Generator[pp.pandapowerNet, None, None], List[pp.pandapowerNet]]:\n    \"\"\"Generate perturbed topologies.\n\n    Args:\n        net: The power network to perturb.\n\n    Yields:\n        A perturbed network topology.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"components/topology/#noperturbationgenerator","title":"<code>NoPerturbationGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generator that yields the original network without any perturbations.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class NoPerturbationGenerator(TopologyGenerator):\n    \"\"\"Generator that yields the original network without any perturbations.\"\"\"\n\n    def generate(\n        self,\n        net: pp.pandapowerNet,\n    ) -&gt; Generator[pp.pandapowerNet, None, None]:\n        \"\"\"Yield the original network without any perturbations.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            The original power network.\n        \"\"\"\n        yield net\n</code></pre> <code>generate(net)</code> \u00b6 <p>Yield the original network without any perturbations.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>pandapowerNet</code> <p>The original power network.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: pp.pandapowerNet,\n) -&gt; Generator[pp.pandapowerNet, None, None]:\n    \"\"\"Yield the original network without any perturbations.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        The original power network.\n    \"\"\"\n    yield net\n</code></pre>"},{"location":"components/topology/#nminuskgenerator","title":"<code>NMinusKGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generate perturbed topologies for N-k contingency analysis.</p> <p>Only considers lines and transformers. Generates ALL possible topologies with at most k components set out of service (lines and transformers).</p> <p>Only topologies that are feasible (= no unsupplied buses) are yielded.</p> <p>Attributes:</p> Name Type Description <code>k</code> <p>Maximum number of components to drop.</p> <code>components_to_drop</code> <p>List of tuples containing component indices and types.</p> <code>component_combinations</code> <p>List of all possible combinations of components to drop.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class NMinusKGenerator(TopologyGenerator):\n    \"\"\"Generate perturbed topologies for N-k contingency analysis.\n\n    Only considers lines and transformers. Generates ALL possible topologies with at most k\n    components set out of service (lines and transformers).\n\n    Only topologies that are feasible (= no unsupplied buses) are yielded.\n\n    Attributes:\n        k: Maximum number of components to drop.\n        components_to_drop: List of tuples containing component indices and types.\n        component_combinations: List of all possible combinations of components to drop.\n    \"\"\"\n\n    def __init__(self, k: int, base_net: pp.pandapowerNet) -&gt; None:\n        \"\"\"Initialize the N-k generator.\n\n        Args:\n            k: Maximum number of components to drop.\n            base_net: The base power network.\n\n        Raises:\n            ValueError: If k is 0.\n            Warning: If k &gt; 1, as this may result in slow data generation.\n        \"\"\"\n        super().__init__()\n        if k &gt; 1:\n            warnings.warn(\"k&gt;1. This may result in slow data generation process.\")\n        if k == 0:\n            raise ValueError(\n                'k must be greater than 0. Use \"none\" as argument for the generator_type if you don\\'t want to generate any perturbation',\n            )\n        self.k = k\n\n        # Prepare the list of components to drop\n        self.components_to_drop = [(index, \"line\") for index in base_net.line.index] + [\n            (index, \"trafo\") for index in base_net.trafo.index\n        ]\n\n        # Generate all combinations of at most k components\n        self.component_combinations = []\n        for r in range(self.k + 1):\n            self.component_combinations.extend(combinations(self.components_to_drop, r))\n\n        print(\n            f\"Number of possible topologies with at most {self.k} dropped components: {len(self.component_combinations)}\",\n        )\n\n    def generate(\n        self,\n        net: pp.pandapowerNet,\n    ) -&gt; Generator[pp.pandapowerNet, None, None]:\n        \"\"\"Generate perturbed topologies by dropping components.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            A perturbed network topology with at most k components removed.\n        \"\"\"\n        for selected_components in self.component_combinations:\n            perturbed_topology = copy.deepcopy(net)\n\n            # Separate lines and transformers\n            lines_to_drop = [e[0] for e in selected_components if e[1] == \"line\"]\n            trafos_to_drop = [e[0] for e in selected_components if e[1] == \"trafo\"]\n\n            # Drop selected lines and transformers\n            if lines_to_drop:\n                perturbed_topology.line.loc[lines_to_drop, \"in_service\"] = False\n            if trafos_to_drop:\n                perturbed_topology.trafo.loc[trafos_to_drop, \"in_service\"] = False\n\n            # Check network feasibility and yield the topology\n            if not len(top.unsupplied_buses(perturbed_topology)):\n                yield perturbed_topology\n</code></pre> <code>__init__(k, base_net)</code> \u00b6 <p>Initialize the N-k generator.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>int</code> <p>Maximum number of components to drop.</p> required <code>base_net</code> <code>pandapowerNet</code> <p>The base power network.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If k is 0.</p> <code>Warning</code> <p>If k &gt; 1, as this may result in slow data generation.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(self, k: int, base_net: pp.pandapowerNet) -&gt; None:\n    \"\"\"Initialize the N-k generator.\n\n    Args:\n        k: Maximum number of components to drop.\n        base_net: The base power network.\n\n    Raises:\n        ValueError: If k is 0.\n        Warning: If k &gt; 1, as this may result in slow data generation.\n    \"\"\"\n    super().__init__()\n    if k &gt; 1:\n        warnings.warn(\"k&gt;1. This may result in slow data generation process.\")\n    if k == 0:\n        raise ValueError(\n            'k must be greater than 0. Use \"none\" as argument for the generator_type if you don\\'t want to generate any perturbation',\n        )\n    self.k = k\n\n    # Prepare the list of components to drop\n    self.components_to_drop = [(index, \"line\") for index in base_net.line.index] + [\n        (index, \"trafo\") for index in base_net.trafo.index\n    ]\n\n    # Generate all combinations of at most k components\n    self.component_combinations = []\n    for r in range(self.k + 1):\n        self.component_combinations.extend(combinations(self.components_to_drop, r))\n\n    print(\n        f\"Number of possible topologies with at most {self.k} dropped components: {len(self.component_combinations)}\",\n    )\n</code></pre> <code>generate(net)</code> \u00b6 <p>Generate perturbed topologies by dropping components.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>pandapowerNet</code> <p>A perturbed network topology with at most k components removed.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: pp.pandapowerNet,\n) -&gt; Generator[pp.pandapowerNet, None, None]:\n    \"\"\"Generate perturbed topologies by dropping components.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        A perturbed network topology with at most k components removed.\n    \"\"\"\n    for selected_components in self.component_combinations:\n        perturbed_topology = copy.deepcopy(net)\n\n        # Separate lines and transformers\n        lines_to_drop = [e[0] for e in selected_components if e[1] == \"line\"]\n        trafos_to_drop = [e[0] for e in selected_components if e[1] == \"trafo\"]\n\n        # Drop selected lines and transformers\n        if lines_to_drop:\n            perturbed_topology.line.loc[lines_to_drop, \"in_service\"] = False\n        if trafos_to_drop:\n            perturbed_topology.trafo.loc[trafos_to_drop, \"in_service\"] = False\n\n        # Check network feasibility and yield the topology\n        if not len(top.unsupplied_buses(perturbed_topology)):\n            yield perturbed_topology\n</code></pre>"},{"location":"components/topology/#randomcomponentdropgenerator","title":"<code>RandomComponentDropGenerator</code>","text":"<p>               Bases: <code>TopologyGenerator</code></p> <p>Generate perturbed topologies by randomly setting components out of service.</p> <p>Generates perturbed topologies by randomly setting out of service at most k components among the selected element types. Only topologies that are feasible (= no unsupplied buses) are yielded.</p> <p>Attributes:</p> Name Type Description <code>n_topology_variants</code> <p>Number of topology variants to generate.</p> <code>k</code> <p>Maximum number of components to drop.</p> <code>components_to_drop</code> <p>List of tuples containing component indices and types.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>class RandomComponentDropGenerator(TopologyGenerator):\n    \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n    Generates perturbed topologies by randomly setting out of service at most k components among the selected element types.\n    Only topologies that are feasible (= no unsupplied buses) are yielded.\n\n    Attributes:\n        n_topology_variants: Number of topology variants to generate.\n        k: Maximum number of components to drop.\n        components_to_drop: List of tuples containing component indices and types.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_topology_variants: int,\n        k: int,\n        base_net: pp.pandapowerNet,\n        elements: List[str] = [\"line\", \"trafo\", \"gen\", \"sgen\"],\n    ) -&gt; None:\n        \"\"\"Initialize the random component drop generator.\n\n        Args:\n            n_topology_variants: Number of topology variants to generate.\n            k: Maximum number of components to drop.\n            base_net: The base power network.\n            elements: List of element types to consider for dropping.\n        \"\"\"\n        super().__init__()\n        self.n_topology_variants = n_topology_variants\n        self.k = k\n\n        # Create a list of all components that can be dropped\n        self.components_to_drop = []\n        for element in elements:\n            self.components_to_drop.extend(\n                [(index, element) for index in base_net[element].index],\n            )\n\n    def generate(\n        self,\n        net: pp.pandapowerNet,\n    ) -&gt; Generator[pp.pandapowerNet, None, None]:\n        \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n        Args:\n            net: The power network.\n\n        Yields:\n            A perturbed network topology.\n        \"\"\"\n        n_generated_topologies = 0\n\n        # Stop after we generated n_topology_variants\n        while n_generated_topologies &lt; self.n_topology_variants:\n            perturbed_topology = copy.deepcopy(net)\n\n            # draw the number of components to drop from a uniform distribution\n            r = np.random.randint(\n                1,\n                self.k + 1,\n            )  # TODO: decide if we want to be able to set 0 components out of service\n\n            # Randomly select r&lt;=k components to drop\n            components = tuple(\n                np.random.choice(range(len(self.components_to_drop)), r, replace=False),\n            )\n\n            # Convert indices back to actual components\n            selected_components = tuple(\n                self.components_to_drop[idx] for idx in components\n            )\n\n            # Separate lines, transformers, generators, and static generators\n            lines_to_drop = [e[0] for e in selected_components if e[1] == \"line\"]\n            trafos_to_drop = [e[0] for e in selected_components if e[1] == \"trafo\"]\n            gens_to_turn_off = [e[0] for e in selected_components if e[1] == \"gen\"]\n            sgens_to_turn_off = [e[0] for e in selected_components if e[1] == \"sgen\"]\n\n            # Drop selected lines and transformers, turn off generators and static generators\n            if lines_to_drop:\n                perturbed_topology.line.loc[lines_to_drop, \"in_service\"] = False\n            if trafos_to_drop:\n                perturbed_topology.trafo.loc[trafos_to_drop, \"in_service\"] = False\n            if gens_to_turn_off:\n                perturbed_topology.gen.loc[gens_to_turn_off, \"in_service\"] = False\n            if sgens_to_turn_off:\n                perturbed_topology.sgen.loc[sgens_to_turn_off, \"in_service\"] = False\n\n            # Check network feasibility and yield the topology\n            if not len(top.unsupplied_buses(perturbed_topology)):\n                yield perturbed_topology\n                n_generated_topologies += 1\n</code></pre> <code>__init__(n_topology_variants, k, base_net, elements=['line', 'trafo', 'gen', 'sgen'])</code> \u00b6 <p>Initialize the random component drop generator.</p> <p>Parameters:</p> Name Type Description Default <code>n_topology_variants</code> <code>int</code> <p>Number of topology variants to generate.</p> required <code>k</code> <code>int</code> <p>Maximum number of components to drop.</p> required <code>base_net</code> <code>pandapowerNet</code> <p>The base power network.</p> required <code>elements</code> <code>List[str]</code> <p>List of element types to consider for dropping.</p> <code>['line', 'trafo', 'gen', 'sgen']</code> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def __init__(\n    self,\n    n_topology_variants: int,\n    k: int,\n    base_net: pp.pandapowerNet,\n    elements: List[str] = [\"line\", \"trafo\", \"gen\", \"sgen\"],\n) -&gt; None:\n    \"\"\"Initialize the random component drop generator.\n\n    Args:\n        n_topology_variants: Number of topology variants to generate.\n        k: Maximum number of components to drop.\n        base_net: The base power network.\n        elements: List of element types to consider for dropping.\n    \"\"\"\n    super().__init__()\n    self.n_topology_variants = n_topology_variants\n    self.k = k\n\n    # Create a list of all components that can be dropped\n    self.components_to_drop = []\n    for element in elements:\n        self.components_to_drop.extend(\n            [(index, element) for index in base_net[element].index],\n        )\n</code></pre> <code>generate(net)</code> \u00b6 <p>Generate perturbed topologies by randomly setting components out of service.</p> <p>Parameters:</p> Name Type Description Default <code>net</code> <code>pandapowerNet</code> <p>The power network.</p> required <p>Yields:</p> Type Description <code>pandapowerNet</code> <p>A perturbed network topology.</p> Source code in <code>gridfm_datakit/perturbations/topology_perturbation.py</code> <pre><code>def generate(\n    self,\n    net: pp.pandapowerNet,\n) -&gt; Generator[pp.pandapowerNet, None, None]:\n    \"\"\"Generate perturbed topologies by randomly setting components out of service.\n\n    Args:\n        net: The power network.\n\n    Yields:\n        A perturbed network topology.\n    \"\"\"\n    n_generated_topologies = 0\n\n    # Stop after we generated n_topology_variants\n    while n_generated_topologies &lt; self.n_topology_variants:\n        perturbed_topology = copy.deepcopy(net)\n\n        # draw the number of components to drop from a uniform distribution\n        r = np.random.randint(\n            1,\n            self.k + 1,\n        )  # TODO: decide if we want to be able to set 0 components out of service\n\n        # Randomly select r&lt;=k components to drop\n        components = tuple(\n            np.random.choice(range(len(self.components_to_drop)), r, replace=False),\n        )\n\n        # Convert indices back to actual components\n        selected_components = tuple(\n            self.components_to_drop[idx] for idx in components\n        )\n\n        # Separate lines, transformers, generators, and static generators\n        lines_to_drop = [e[0] for e in selected_components if e[1] == \"line\"]\n        trafos_to_drop = [e[0] for e in selected_components if e[1] == \"trafo\"]\n        gens_to_turn_off = [e[0] for e in selected_components if e[1] == \"gen\"]\n        sgens_to_turn_off = [e[0] for e in selected_components if e[1] == \"sgen\"]\n\n        # Drop selected lines and transformers, turn off generators and static generators\n        if lines_to_drop:\n            perturbed_topology.line.loc[lines_to_drop, \"in_service\"] = False\n        if trafos_to_drop:\n            perturbed_topology.trafo.loc[trafos_to_drop, \"in_service\"] = False\n        if gens_to_turn_off:\n            perturbed_topology.gen.loc[gens_to_turn_off, \"in_service\"] = False\n        if sgens_to_turn_off:\n            perturbed_topology.sgen.loc[sgens_to_turn_off, \"in_service\"] = False\n\n        # Check network feasibility and yield the topology\n        if not len(top.unsupplied_buses(perturbed_topology)):\n            yield perturbed_topology\n            n_generated_topologies += 1\n</code></pre>"},{"location":"components/utils/","title":"Utils","text":"<p>This module provides utility functions for the project.</p>"},{"location":"components/utils/#write_ram_usage_distributed","title":"<code>write_ram_usage_distributed</code>","text":"Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>def write_ram_usage_distributed(tqdm_log):\n    process = psutil.Process(os.getpid())  # Parent process\n    mem_usage = process.memory_info().rss / 1024**2  # Parent memory in MB\n\n    # Sum memory usage of all child processes\n    for child in process.children(recursive=True):\n        mem_usage += child.memory_info().rss / 1024**2\n\n    tqdm_log.write(f\"Total RAM usage (Parent + Children): {mem_usage:.2f} MB\\n\")\n</code></pre>"},{"location":"components/utils/#classes","title":"Classes","text":""},{"location":"components/utils/#tee","title":"<code>Tee</code>","text":"Source code in <code>gridfm_datakit/utils/utils.py</code> <pre><code>class Tee:\n    def __init__(self, *streams):\n        self.streams = streams\n\n    def write(self, data):\n        for s in self.streams:\n            s.write(data)\n            s.flush()\n\n    def flush(self):\n        for s in self.streams:\n            s.flush()\n</code></pre>"},{"location":"manual/admittance_perturbations/","title":"Generation Perturbations","text":""},{"location":"manual/admittance_perturbations/#overview","title":"Overview","text":"<p>Admittance perturbations introduce changes to line admittance values by applpying random scaling factors to the resistance (\\(R\\)) and reactance (\\(X\\)) parameters of grid lines.  Admittance (\\(Y\\)) is related to impedance (\\(Z\\)) through \\(Y=1/Z\\), and the impedance, in turn, is related to resistance and reactance through \\(Z=R+jX\\). This results in more variance and diversity in power flow solutions which is beneficial for training ML models to improve generalisation.  Admittance perturbations are applied to the existing topology and generation perturbations.</p> <p>The module provides two options for admittance perturbation strategies:</p> <ul> <li> <p><code>NoAdmittancePerturbationGenerator</code> yields the original example produced by the generation perturbation generator without any additional changes in line admittances.</p> </li> <li> <p><code>PerturbAdmittanceGenerator</code> applies a scaling factor to all resistance and reactance values of network lines.  The scaling factor is sampled from a uniform distribution with a range given by <code>[max(0, 1-sigma), 1+sigma)</code>, where <code>sigma</code> is a user-defined adjustable parameter.</p> </li> </ul>"},{"location":"manual/generation_perturbations/","title":"Generation Perturbations","text":""},{"location":"manual/generation_perturbations/#overview","title":"Overview","text":"<p>Generation perturbations introduce random changes to the cost functions of generators and static generators (<code>gens</code> and <code>sgens</code>) in the Panda Power <code>poly_cost</code> table.  The effect of this is that the cost of operating generators in the grid changes across examples, which allows them to be utilised differently when executing optimal power flow.  As a result, examples produced will have more diverse generator setpoints which is beneficial for training ML models to improve generalisation.  Generation perturbation is applied to the existing topology perturbations.</p> <p>The module provides three options for generation perturbation strategies:</p> <ul> <li> <p><code>NoGenPerturbationGenerator</code> yields the original example produced by the topology perturbation generator without any additional changes in generation cost.</p> </li> <li> <p><code>PermuteGenCostGenerator</code> randomly permutes the rows of generator cost coefficients in the <code>poly_cost</code> table across and among generator elements.</p> </li> <li> <p><code>PerturbGenCostGenerator</code> applies a scaling factor to all generator cost coefficients in the <code>poly_cost</code> table.  The scaling factor is sampled from a uniform distribution with a range given by <code>[max(0, 1-sigma), 1+sigma)</code>, where <code>sigma</code> is a user-defined adjustable parameter.</p> </li> </ul>"},{"location":"manual/getting_started/","title":"Getting Started","text":""},{"location":"manual/getting_started/#option-1-run-data-gen-using-interactive-interface","title":"Option 1: Run data gen using interactive interface","text":"<p>To use the interactive interface, either open <code>scripts/interactive_interface.ipynb</code> or copy the following into a Jupyter notebook and follow the instructions:</p> <pre><code>from gridfm_datakit.interactive import interactive_interface\ninteractive_interface()\n</code></pre>"},{"location":"manual/getting_started/#option-2-using-the-command-line-interface","title":"Option 2: Using the command line interface","text":"<p>Run the data generation routine from the command line:</p> <pre><code>gridfm_datakit path/to/config.yaml\n</code></pre>"},{"location":"manual/getting_started/#configuration-overview","title":"Configuration Overview","text":"<p>Refer to the sections Network, Load Scenarios, and Topology perturbations for a description of the configuration parameters.</p> <p>Sample configuration files are provided in <code>scripts/config</code>, e.g. <code>default.yaml</code>:</p> <pre><code>network:\n  name: \"case24_ieee_rts\" # Name of the power grid network (without extension)\n  source: \"pglib\" # Data source for the grid; options: pglib, pandapower, file\n  network_dir: \"scripts/grids\" # if using source \"file\", this is the directory containing the network file (relative to the project root)\n\n\nload:\n  generator: \"agg_load_profile\" # Name of the load generator; options: agg_load_profile, powergraph\n  agg_profile: \"default\" # Name of the aggregated load profile\n  scenarios: 200 # Number of different load scenarios to generate\n  # WARNING: the following parameters are only used if generator is \"agg_load_profile\"\n  # if using generator \"powergraph\", these parameters are ignored\n  sigma: 0.05 # max local noise\n  change_reactive_power: true # If true, changes reactive power of loads. If False, keeps the ones from the case file\n  global_range: 0.4 # Range of the global scaling factor. used to set the lower bound of the scaling factor\n  max_scaling_factor: 4.0 # Max upper bound of the global scaling factor\n  step_size: 0.025 # Step size when finding the upper bound of the global scaling factor\n  start_scaling_factor: 0.8 # Initial value of the global scaling factor\n\ntopology_perturbation:\n  type: \"random\" # Type of topology generator; options: n_minus_k, random, none\n  # WARNING: the following parameters are only used if type is not \"none\"\n  k: 1 # Maximum number of components to drop in each perturbation\n  n_topology_variants: 5 # Number of unique perturbed topologies per scenario\n  elements: [\"line\", \"trafo\", \"gen\", \"sgen\"] # elements to perturb options: line, trafo, gen, sgen\n\nsettings:\n  num_processes: 10 # Number of parallel processes to use\n  data_dir: \"./data_out\" # Directory to save generated data relative to the project root\n  large_chunk_size: 50 # Number of load scenarios processed before saving\n  no_stats: false # If true, disables statistical calculations\n  overwrite: true # If true, overwrites existing files, if false, appends to files (note that bus_params.csv, edge_params.csv, scenarios_{load.generator}.csv and scenarios_{load.generator}.html will still be overwritten)\n  mode: \"pf\" # Mode of the script; options: contingency, pf\n</code></pre> <p></p>"},{"location":"manual/getting_started/#output-files","title":"Output Files","text":"<p>The data generation process produces several output files in the specified data directory:</p> <ul> <li>tqdm.log: Progress bar log.</li> <li>error.log: Log of the errors raised during data generation.</li> <li>args.log: Copy of the config file used.</li> <li>pf_node.csv: Data related to the nodes (buses) in the network, such as voltage levels and power injections.</li> <li>pf_edge.csv: Branch admittance matrix for each pf case.</li> <li>branch_idx_removed.csv: List of the indices of the branches (lines and transformers) that got removed when perturbing the topologies.</li> <li>edge_params.csv: Branch admittance matrix and branch rate limits for the unperturbed topology.</li> <li>bus_params.csv: Parameters for the buses (voltage limits and the base voltage).</li> <li>scenario_{args.load.generator}.csv: Load element-level load profile obtained after using the load scenario generator.</li> <li>scenario_{args.load.generator}.html: Plots of the element-level load profile.</li> <li>scenario_{args.load.generator}.log: If generator is \"agg_load_profile\", stores the upper and lower bounds for the global scaling factor.</li> <li>stats.csv: Stats about the generated data.</li> <li>stats_plot.html: Plots of the stats about the generated data.</li> </ul>"},{"location":"manual/load_scenarios/","title":"Load Scenarios","text":"<p>Load perturbations generate multiple load scenarios from an initial case file scenario. Each scenario consists of active and reactive power values for all loads in the network.</p> <p>The module provides two main perturbation strategies:</p>"},{"location":"manual/load_scenarios/#comparison-of-perturbation-strategies","title":"Comparison of Perturbation Strategies","text":"Feature <code>LoadScenariosFromAggProfile</code> <code>Powergraph</code> Global scaling \u2705 Yes \u2705 Yes Local (per-load) scaling \u2705 Yes (via noise) \u274c No Reactive power perturbed \u2705 Optional \u274c No Interpolation \u2705 Yes \u2705 Yes Use of real profile data \u2705 Yes \u2705 Yes"},{"location":"manual/load_scenarios/#mathematical-models","title":"Mathematical Models","text":"<p>Let:</p> <ul> <li> <p>\\(n\\): Number of loads (\\(i \\in \\{1, \\dots, n\\}\\))</p> </li> <li> <p>\\(K\\): Number of scenarios (\\(k \\in \\{1, \\dots, K\\}\\))</p> </li> <li> <p>\\((p, q) \\in (\\mathbb{R}_{\\geq 0}^n)^2\\): Nominal active/reactive loads</p> </li> <li> <p>\\(\\text{agg}^k\\): Aggregated load profile value at time step \\(k\\)</p> </li> <li> <p>\\(u\\): Maximum feasible global scaling factor (from OPF)</p> </li> <li> <p>\\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\): Minimum global scaling factor</p> </li> <li> <p>\\(\\text{ref}^k = \\text{MinMaxScale}(\\text{agg}^k, [l, u])\\): Scaled aggregate profile</p> </li> <li> <p>\\(\\varepsilon_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Active power noise</p> </li> <li> <p>\\(\\eta_i^k \\sim \\mathcal{U}(1 - \\sigma, 1 + \\sigma)\\): Reactive power noise (if enabled)</p> </li> </ul>"},{"location":"manual/load_scenarios/#loadscenariosfromaggprofile","title":"<code>LoadScenariosFromAggProfile</code>","text":"<p>Generates load scenarios by scaling all loads of the grid using a global scaling factor derived from an aggregated load profile, while also applying local (load-level) noise to introduce heterogeneity across buses. Both active and reactive power can be perturbed.</p> <p>The process includes:</p> <ol> <li>Determining an upper bound \\(u\\) for load scaling such that the network still     supports a feasible optimal power flow (OPF) solution.</li> <li>Setting the lower bound \\(l = (1 - \\text{global\\textunderscore range}) \\cdot u\\).</li> <li>Min-max scaling the aggregate profile to the interval \\([l, u]\\).</li> <li>Applying this global scaling factor to each load's nominal value with additive uniform noise.</li> </ol> <p>For each load \\(i\\) and scenario \\(k\\): $$ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\cdot \\varepsilon_i^k $$</p> \\[ \\tilde{q}_i^k = \\begin{cases} q_i \\cdot \\text{ref}^k \\cdot \\eta_i^k &amp; \\text{if } \\texttt{change\\textunderscore reactive\\textunderscore power} = \\texttt{True} \\\\ q_i &amp; \\text{otherwise} \\end{cases} \\] <p>Notes</p> <ul> <li> <p>The upper bound <code>u</code> is automatically determined by gradually increasing the base load (doing steps of size <code>step_size</code> and solving the OPF until it fails or reaches <code>max_scaling_factor</code>).</p> </li> <li> <p>The lower bound <code>l</code> is computed as a relative percentage (1-<code>global_range</code>) of <code>u</code>.</p> </li> <li> <p>Noise helps simulate local variability across loads within a global trend.</p> </li> </ul> <p>Sample config parameters:</p> <pre><code>load:\n  generator: \"agg_load_profile\" # Name of the load generator; options: agg_load_profile, powergraph\n  agg_profile: \"default\" # Name of the aggregated load profile\n  scenarios: 200 # Number of different load scenarios to generate\n  sigma: 0.05 # max local noise\n  change_reactive_power: true # If true, changes reactive power of loads. If False, keeps the ones from the case file\n  global_range: 0.4 # Range of the global scaling factor. used to set the lower bound of the scaling factor\n  max_scaling_factor: 4.0 # Max upper bound of the global scaling factor\n  step_size: 0.025 # Step size when finding the upper bound of the global scaling factor\n  start_scaling_factor: 0.8 # Initial value of the global scaling factor\n</code></pre>"},{"location":"manual/load_scenarios/#powergraph","title":"<code>Powergraph</code>","text":"<p>Generates load scenarios by scaling all loads of the grid with a normalized global scaling factor, derived from an aggregated load profile. Only the active power is perturbed; reactive power remains fixed across all scenarios. This follows the implementation of PowerGraph: A power grid benchmark dataset for graph neural networks</p> <p>The reference profile is computed by normalizing an aggregated profile:</p> \\[ \\text{ref}^k = \\frac{\\text{agg}^k}{\\max_k \\text{agg}^k} \\] <p>Then, for each bus \\(i\\) and scenario \\(k\\):</p> \\[ \\tilde{p}_i^k = p_i \\cdot \\text{ref}^k \\] <p>and reactive power is kept constant:</p> \\[ \\tilde{q}_i^k = q_i \\] <p>Sample config parameters:</p> <pre><code>load:\n  generator: \"powergraph\"\n  agg_profile: \"default\"           # Aggregated load profile name\n  scenarios: 200                   # Number of load scenarios to generate\n</code></pre>"},{"location":"manual/load_scenarios/#aggregated-load-profiles","title":"Aggregated load profiles","text":"<p>The following load profiles are available in the <code>gridfm-datakit/load_profiles</code> directory:</p> <ul> <li> <p><code>default.csv</code>: Default load profile.</p> </li> <li> <p>ERCOT load profiles:</p> <ul> <li><code>ercot_load_act_hr_2024_west.csv</code>: ERCOT load profile for the West region.</li> <li><code>ercot_load_act_hr_2024_south_central.csv</code>: ERCOT load profile for the South Central region.</li> <li><code>ercot_load_act_hr_2024_southern.csv</code>: ERCOT load profile for the Southern region.</li> <li><code>ercot_load_act_hr_2024_total.csv</code>: Total ERCOT load profile.</li> <li><code>ercot_load_act_hr_2024_far_west.csv</code>: ERCOT load profile for the Far West region.</li> <li><code>ercot_load_act_hr_2024_north.csv</code>: ERCOT load profile for the North region.</li> <li><code>ercot_load_act_hr_2024_north_central.csv</code>: ERCOT load profile for the North Central region.</li> <li><code>ercot_load_act_hr_2024_coast.csv</code>: ERCOT load profile for the Coast region.</li> <li><code>ercot_load_act_hr_2024_east.csv</code>: ERCOT load profile for the East region.</li> </ul> </li> </ul>"},{"location":"manual/network/","title":"Network","text":"<p>The network parameters are the following:</p> <pre><code>network:\n  name: \"case24_ieee_rts\" # Name of the power grid network (without extension)\n  source: \"pglib\" # Data source for the grid; options: pglib, pandapower, file\n  network_dir: \"scripts/grids\" # if using source \"file\", this is the directory containing the network file (relative to the project root)\n\n</code></pre> <p>Networks can be loaded from three different sources, specified in `source:</p>"},{"location":"manual/network/#pglib-repository-recommended","title":"PGLib repository (recommended)","text":"<p>e.g.</p> <pre><code>network:\n  source: \"pglib\"\n  name: \"case24_ieee_rts\"   # Name of the power grid network **without the pglib prefix**\n</code></pre>"},{"location":"manual/network/#pandapower-library","title":"Pandapower library","text":"<p>e.g.</p> <pre><code>network:\n  source: \"pandapower\"\n  name: \"case_ieee30\"\n</code></pre>"},{"location":"manual/network/#local-matpower-files","title":"Local matpower files","text":"<p>e.g.</p> <pre><code>network:\n  source: \"Texas2k_case1_2016summerpeak\"\n  name: \"case24_ieee_rts\"          # Name of the power grid network **without .m extension**\n  network_dir: \"scripts/grids\"    # Directory containing the network files\n</code></pre>"},{"location":"manual/outputs/","title":"Outputs","text":"<p>This page provides a detailed description of the output files generated by the data generation process. All files are saved in the specified data directory.</p>"},{"location":"manual/outputs/#output-files","title":"Output Files","text":""},{"location":"manual/outputs/#log-files","title":"Log Files","text":""},{"location":"manual/outputs/#tqdmlog","title":"<code>tqdm.log</code>","text":"<p>Progress bar log showing the execution progress of the data generation process.</p>"},{"location":"manual/outputs/#errorlog","title":"<code>error.log</code>","text":"<p>Log of any errors raised during data generation.</p>"},{"location":"manual/outputs/#argslog","title":"<code>args.log</code>","text":"<p>Copy of the configuration file used for the data generation run.</p>"},{"location":"manual/outputs/#network-data-files","title":"Network Data Files","text":""},{"location":"manual/outputs/#pf_nodecsv","title":"<code>pf_node.csv</code>","text":"<p>Contains data related to the nodes (buses) in the network:</p> <ul> <li>scenario: Index of the scenario (This is not the load scenario index, but a unique identifier of the pf case. There can be many scenarios per load scenario in case of topology perturbation)</li> <li>bus: Index of the bus</li> <li>Pd: Active power demand at the bus</li> <li>Qd: Reactive power demand at the bus</li> <li>Pg: Active power generation at the bus</li> <li>Qg: Reactive power generation at the bus</li> <li>Vm: Voltage magnitude at the bus</li> <li>Va: Voltage angle at the bus</li> <li>PQ: Indicates if the bus is a PQ bus</li> <li>PV: Indicates if the bus is a PV bus</li> <li>REF: Indicates if the bus is a reference bus</li> </ul>"},{"location":"manual/outputs/#pf_edgecsv","title":"<code>pf_edge.csv</code>","text":"<p>Branch admittance matrix for each power flow case (accounting for perturbations, i.e. a dropped branch won't appear in the adjacency list).</p>"},{"location":"manual/outputs/#branch_idx_removedcsv","title":"<code>branch_idx_removed.csv</code>","text":"<p>List of the indices of the branches (lines and transformers) that got removed when perturbing the topologies.</p>"},{"location":"manual/outputs/#network-parameters","title":"Network Parameters","text":""},{"location":"manual/outputs/#edge_paramscsv","title":"<code>edge_params.csv</code>","text":"<p>Branch admittance matrix and branch rate limits for the unperturbed topology. Contains the following columns:</p> <ul> <li>from_bus: Index of the source bus</li> <li>to_bus: Index of the destination bus</li> <li>Yff_r: Real part of the self-admittance at the source bus</li> <li>Yff_i: Imaginary part of the self-admittance at the source bus</li> <li>Yft_r: Real part of the mutual admittance from source to destination bus</li> <li>Yft_i: Imaginary part of the mutual admittance from source to destination bus</li> <li>Ytf_r: Real part of the mutual admittance from destination to source bus</li> <li>Ytf_i: Imaginary part of the mutual admittance from destination to source bus</li> <li>Ytt_r: Real part of the self-admittance at the destination bus</li> <li>Ytt_i: Imaginary part of the self-admittance at the destination bus</li> <li>rate_a: Rate limit of the branch</li> </ul>"},{"location":"manual/outputs/#bus_paramscsv","title":"<code>bus_params.csv</code>","text":"<p>Parameters for the buses, such as voltage limits and the base voltage. Contains the following columns:</p> <ul> <li>bus: Index of the bus</li> <li>type: Type of the bus (e.g., PQ, PV, REF)</li> <li>vmin: Minimum voltage limit at the bus</li> <li>vmax: Maximum voltage limit at the bus</li> <li>baseKV: Base voltage level at the bus</li> </ul>"},{"location":"manual/outputs/#load-scenario-files","title":"Load Scenario Files","text":""},{"location":"manual/outputs/#scenario_argsloadgeneratorcsv","title":"<code>scenario_{args.load.generator}.csv</code>","text":"<p>Load element-level load profile obtained after using the load scenario generator. The file name depends on the generator type specified in the config (e.g., <code>scenarios_agg_load_profile.csv</code> or <code>scenarios_powergraph.csv</code>).</p>"},{"location":"manual/outputs/#scenario_argsloadgeneratorhtml","title":"<code>scenario_{args.load.generator}.html</code>","text":"<p>Plots of the element-level load profile. The file name depends on the generator type specified in the config (e.g., <code>scenarios_agg_load_profile.html</code> or <code>scenarios_powergraph.html</code>).</p>"},{"location":"manual/outputs/#scenario_argsloadgeneratorlog","title":"<code>scenario_{args.load.generator}.log</code>","text":"<p>If generator is \"agg_load_profile\", this file stores the upper and lower bounds for the global scaling factor. The file name depends on the generator type specified in the config (e.g., <code>scenarios_agg_load_profile.log</code>).</p>"},{"location":"manual/outputs/#statistics-files","title":"Statistics Files","text":""},{"location":"manual/outputs/#statscsv","title":"<code>stats.csv</code>","text":"<p>Statistics about the generated data, including metrics such as:</p> <ul> <li>Number of generators</li> <li>Number of lines and transformers</li> <li>Number of overloads</li> <li>Maximum loading values</li> <li>Other network performance metrics</li> </ul>"},{"location":"manual/outputs/#stats_plothtml","title":"<code>stats_plot.html</code>","text":"<p>Plots visualizing the statistics about the generated data.</p>"},{"location":"manual/topology_perturbations/","title":"Topology Perturbations","text":""},{"location":"manual/topology_perturbations/#overview","title":"Overview","text":"<p>Topology perturbations generate variations of the original network by altering its structure. These variations simulate contingencies and component failures, and are useful for robustness testing, contingency analysis, and training ML models on diverse grid conditions.</p> <p>The module provides three topology perturbation strategies:</p> <ul> <li> <p><code>NoPerturbationGenerator</code> yields the original topology without changes. It is useful for baseline comparisons and debugging.</p> </li> <li> <p><code>NMinusKGenerator</code> generates all possible combinations of up to k components (lines and transformers) being out of service. Only feasible topologies with no unsupplied buses are returned.</p> </li> <li> <p><code>RandomComponentDropGenerator</code> randomly generates a specified number of feasible topologies by disabling up to k randomly selected components, including lines, transformers, generators, and static generators.</p> </li> </ul>"},{"location":"manual/topology_perturbations/#comparison-of-perturbation-strategies","title":"Comparison of Perturbation Strategies","text":"Feature <code>NoPerturbationGenerator</code> <code>NMinusKGenerator</code> <code>RandomComponentDropGenerator</code> Number of topologies 1 (original) All feasible (up to k elements lost) User-defined Component types supported \u2013 Lines, Transformers Lines, Transformers, Gens, Sgens Randomized generation \u274c No \u274c No \u2705 Yes"}]}