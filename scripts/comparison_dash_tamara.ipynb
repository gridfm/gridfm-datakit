{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea41b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import OPFDataset\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8fca432",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "num_buses = 118\n",
    "num_loads = 99\n",
    "num_gens = 54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfea505",
   "metadata": {},
   "source": [
    "# PF delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0add9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pfdelta data\n",
    "path_to_data = \"/Users/albanpuech/benchmark_data/pfdelta/30000opfv2dataset_case118_ieee.mat\"\n",
    "pfdelta_data = scipy.io.loadmat(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f9f66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 30000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfdelta_data['bus_type'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1972afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "## Load pfdelta data\n",
    "path_to_data = \"/Users/albanpuech/benchmark_data/pfdelta/30000opfv2dataset_case118_ieee.mat\"\n",
    "pfdelta_data = scipy.io.loadmat(path_to_data)\n",
    "baseMVA = pfdelta_data[\"baseMVA\"]\n",
    "print(baseMVA.dtype)\n",
    "pd_ = pfdelta_data[\"bus\"][:, 2]\n",
    "qd_ = pfdelta_data[\"bus\"][:, 3]\n",
    "load_bus_mask = (pd_ > 0) | (qd_ > 0)\n",
    "gen_bus = (\n",
    "    torch.tensor(pfdelta_data[\"gen\"][:, 0], dtype=torch.long) - 1\n",
    ")  # change index of bus back to\n",
    "gen_bus_expanded = gen_bus.expand(num_samples, -1)\n",
    "spv_bus_mask = torch.tensor(pfdelta_data[\"bus\"][:, 1] != 1, dtype=torch.bool)\n",
    "\n",
    "# Get variables (only first 10000 samples)\n",
    "pd = np.real(pfdelta_data[\"Dem\"][load_bus_mask, :10000].T) / 100\n",
    "qd = np.imag(pfdelta_data[\"Dem\"][load_bus_mask, :10000].T) / 100\n",
    "pg = torch.tensor(np.real(pfdelta_data[\"Gen\"][:10000, :].T) / 100)\n",
    "qg = torch.tensor(np.imag(pfdelta_data[\"Gen\"][:10000, :].T) / 100)\n",
    "vm = np.abs(pfdelta_data[\"Vol\"][:10000, :].T)\n",
    "\n",
    "pg_full = torch.zeros((num_samples, num_buses), dtype=pg.dtype)\n",
    "qg_full = torch.zeros((num_samples, num_buses), dtype=qg.dtype)\n",
    "pg_full.scatter_add_(1, gen_bus_expanded, pg)\n",
    "qg_full.scatter_add_(1, gen_bus_expanded, qg)\n",
    "pg = pg_full[:, spv_bus_mask]\n",
    "qg = qg_full[:, spv_bus_mask]\n",
    "\n",
    "perturbpf = {\"pd\": pd, \"qd\": qd, \"pg\": pg, \"qg\": qg, \"vm\": vm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41be9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OPFData\n",
    "root = \".//Users/albanpuech/benchmark_data/opfdata\"\n",
    "dataset = OPFDataset(\n",
    "    root=root,\n",
    "    split=\"train\",\n",
    "    case_name=\"pglib_opf_case118_ieee\",\n",
    "    num_groups=1,\n",
    "    topological_perturbations=True,\n",
    "    force_reload=False,\n",
    ")\n",
    "\n",
    "pg_full = torch.zeros((num_samples, num_buses))\n",
    "qg_full = torch.zeros((num_samples, num_buses))\n",
    "pd = torch.zeros((num_samples, num_loads))\n",
    "qd = torch.zeros((num_samples, num_loads))\n",
    "vm = torch.zeros((num_samples, num_buses))\n",
    "\n",
    "for i in range(10000):\n",
    "    pg = dataset[i][\"generator\"][\"y\"][:, 0]\n",
    "    qg = dataset[i][\"generator\"][\"y\"][:, 1]\n",
    "    gen_bus = dataset[i][\"generator\", \"generator_link\", \"bus\"][\"edge_index\"][1, :]\n",
    "    pg_full[i, :].scatter_add_(0, gen_bus, pg)\n",
    "    qg_full[i, :].scatter_add_(0, gen_bus, qg)\n",
    "    pd[i, :] = dataset[i][\"load\"][\"x\"][:, 0]\n",
    "    qd[i, :] = dataset[i][\"load\"][\"x\"][:, 1]\n",
    "    vm[i, :] = dataset[i][\"bus\"][\"y\"][:, 1]\n",
    "\n",
    "pg = pg_full[:, spv_bus_mask]\n",
    "qg = qg_full[:, spv_bus_mask]\n",
    "\n",
    "opfdata = {\"pd\": pd, \"qd\": qd, \"pg\": pg, \"qg\": qg, \"vm\": vm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2584b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/19f7b26x5s9771w9ggsv_vxh0000gn/T/ipykernel_80455/1021886785.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  vm_complex = vm_df.applymap(safe_complex).to_numpy()\n"
     ]
    }
   ],
   "source": [
    "# Load OPFLearn Data\n",
    "opflearn_data_path = \"/Users/albanpuech/benchmark_data/opflearn/pglib_opf_case118_ieee.csv\"\n",
    "df = pandas.read_csv(opflearn_data_path)\n",
    "pd = df.filter(regex=r\"^load\\d+:pl$\", axis=1).to_numpy()\n",
    "qd = df.filter(regex=r\"^load\\d+:ql$\", axis=1).to_numpy()\n",
    "pg = torch.tensor(df.filter(regex=r\"^gen\\d+:pg$\", axis=1).to_numpy())\n",
    "qg = torch.tensor(df.filter(regex=r\"^gen\\d+:qg$\", axis=1).to_numpy())\n",
    "vm_df = df.filter(regex=r\"^bus\\d+:v_bus$\", axis=1)\n",
    "\n",
    "\n",
    "def safe_complex(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.replace(\" + \", \"+\").replace(\" - \", \"-\")  # fix spacing for conversion\n",
    "        return complex(val)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "# Apply transformation\n",
    "vm_complex = vm_df.applymap(safe_complex).to_numpy()\n",
    "vm = np.abs(vm_complex)\n",
    "\n",
    "# expand pg and qg\n",
    "pg_full = torch.zeros((10000, 118), dtype=pg.dtype)\n",
    "qg_full = torch.zeros((10000, 118), dtype=pg.dtype)\n",
    "pg_full.scatter_add_(1, gen_bus_expanded, pg)\n",
    "qg_full.scatter_add_(1, gen_bus_expanded, qg)\n",
    "pg = pg_full[:, spv_bus_mask]\n",
    "qg = qg_full[:, spv_bus_mask]\n",
    "\n",
    "opflearn = {\"pd\": pd, \"qd\": qd, \"pg\": pg, \"qg\": qg, \"vm\": vm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e46ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datakit data\n",
    "# No generator cost permutation - random topology perturbation\n",
    "datakit_data_path = \"/Users/albanpuech/datakit-data/case118/pf_random_topology_no_gencost/pf_node.csv\"\n",
    "df_dk_no_gc = pandas.read_csv(datakit_data_path)\n",
    "df_dk_no_gc = df_dk_no_gc[(df_dk_no_gc[\"scenario\"] < 10000)]  # only 10000 samples\n",
    "for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n",
    "    df_dk_no_gc[col] = df_dk_no_gc[col] / 100\n",
    "df_dk_no_gc = df_dk_no_gc.rename(\n",
    "    columns={\"Pd\": \"pd\", \"Qd\": \"qd\", \"Pg\": \"pg\", \"Qg\": \"qg\", \"Vm\": \"vm\", \"Va\": \"va\"}\n",
    ")  # rename to match other data\n",
    "\n",
    "# Need to group by generator bus and load bus indices first then select bus indices to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9dc163",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/tamaragovindasamy/Desktop/gridfm-datakit/data_out/data_comparison/case118_ieee_gc_no_topology/raw/pf_node.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generator cost permutation - no topology perturbation\u001b[39;00m\n\u001b[32m      2\u001b[39m datakit_gc_no_topology_path = \u001b[33m\"\u001b[39m\u001b[33m/Users/tamaragovindasamy/Desktop/gridfm-datakit/data_out/data_comparison/case118_ieee_gc_no_topology/raw/pf_node.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m datakit_gc_no_topology = \u001b[43mpandas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatakit_gc_no_topology_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m datakit_gc_no_topology = datakit_gc_no_topology[\n\u001b[32m      5\u001b[39m     (datakit_gc_no_topology[\u001b[33m\"\u001b[39m\u001b[33mscenario\u001b[39m\u001b[33m\"\u001b[39m] < \u001b[32m10000\u001b[39m)\n\u001b[32m      6\u001b[39m ]  \u001b[38;5;66;03m# only 10000 samples\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mPd\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mQd\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mQg\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gridfm-datakit/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gridfm-datakit/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gridfm-datakit/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gridfm-datakit/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gridfm-datakit/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/tamaragovindasamy/Desktop/gridfm-datakit/data_out/data_comparison/case118_ieee_gc_no_topology/raw/pf_node.csv'"
     ]
    }
   ],
   "source": [
    "# Generator cost permutation - no topology perturbation\n",
    "datakit_gc_no_topology_path = \"/Users/tamaragovindasamy/Desktop/gridfm-datakit/data_out/data_comparison/case118_ieee_gc_no_topology/raw/pf_node.csv\"\n",
    "datakit_gc_no_topology = pandas.read_csv(datakit_gc_no_topology_path)\n",
    "datakit_gc_no_topology = datakit_gc_no_topology[\n",
    "    (datakit_gc_no_topology[\"scenario\"] < 10000)\n",
    "]  # only 10000 samples\n",
    "for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n",
    "    datakit_gc_no_topology[col] = datakit_gc_no_topology[col] / 100\n",
    "datakit_gc_no_topology = datakit_gc_no_topology.rename(\n",
    "    columns={\"Pd\": \"pd\", \"Qd\": \"qd\", \"Pg\": \"pg\", \"Qg\": \"qg\", \"Vm\": \"vm\", \"Va\": \"va\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da951305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator cost permutation - random topology perturbation\n",
    "datakit_gc_random_topology_path = \"/Users/albanpuech/datakit-data/case118/pf_topology_random_gc_permute_agg_load/pf_node.csv\"\n",
    "datakit_gc_random_topology = pandas.read_csv(datakit_gc_random_topology_path)\n",
    "datakit_gc_random_topology = datakit_gc_random_topology[\n",
    "    (datakit_gc_random_topology[\"scenario\"] < 10000)\n",
    "]  # only 10000 samples\n",
    "for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n",
    "    datakit_gc_random_topology[col] = datakit_gc_random_topology[col] / 100\n",
    "datakit_gc_random_topology = datakit_gc_random_topology.rename(\n",
    "    columns={\"Pd\": \"pd\", \"Qd\": \"qd\", \"Pg\": \"pg\", \"Qg\": \"qg\", \"Vm\": \"vm\", \"Va\": \"va\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9b206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency - Generator cost permutation - random topology perturbation\n",
    "datakit_gc_random_topology_contingency_path = \"/Users/albanpuech/datakit-data/case118/contingency_topology_random_gc_permuted/pf_node.csv\"\n",
    "datakit_gc_random_topology_contingency = pandas.read_csv(\n",
    "    datakit_gc_random_topology_contingency_path\n",
    ")\n",
    "datakit_gc_random_topology_contingency = datakit_gc_random_topology_contingency[\n",
    "    (datakit_gc_random_topology_contingency[\"scenario\"] < 10000)\n",
    "]  # only 10000 samples\n",
    "for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n",
    "    datakit_gc_random_topology_contingency[col] = (\n",
    "        datakit_gc_random_topology_contingency[col] / 100\n",
    "    )\n",
    "datakit_gc_random_topology_contingency = datakit_gc_random_topology_contingency.rename(\n",
    "    columns={\"Pd\": \"pd\", \"Qd\": \"qd\", \"Pg\": \"pg\", \"Qg\": \"qg\", \"Vm\": \"vm\", \"Va\": \"va\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aaf4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PgLearn data\n",
    "pglearn_data_path = (\n",
    "    \"/Users/albanpuech/benchmark_data/pglearn/pglearn.csv\"\n",
    ")\n",
    "df_pg = pandas.read_csv(pglearn_data_path)\n",
    "\n",
    "df_pg = df_pg[(df_pg[\"scenario\"] < 10000)]  # only 10000 samples\n",
    "for col in [\"Pd\", \"Qd\", \"Pg\", \"Qg\"]:\n",
    "    df_pg[col] = df_pg[col] / 100\n",
    "df_pg = df_pg.rename(\n",
    "    columns={\"Pd\": \"pd\", \"Qd\": \"qd\", \"Pg\": \"pg\", \"Qg\": \"qg\", \"Vm\": \"vm\", \"Va\": \"va\"}\n",
    ")  # rename to match other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c4eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_function(\n",
    "    feature, sample_buses, perturbpf, opfdata, opflearn, df_pg, df_dk\n",
    "):\n",
    "    # Group data by bus\n",
    "    bus_groups_df_dk = df_dk.groupby(\"bus\")\n",
    "\n",
    "    bus_groups_df_pg = df_pg.groupby(\"bus\")\n",
    "\n",
    "    bus_data_pfdelta = []  # pfdelta\n",
    "    bus_data_opfdata = []  # opfdata\n",
    "    bus_data_opflearn = []  # opflearn\n",
    "\n",
    "    for i in sample_buses:  # Iterate over each bus\n",
    "        bus_data_pfdelta.append(perturbpf[feature][:, i])\n",
    "        bus_data_opfdata.append(opfdata[feature][:, i])\n",
    "        bus_data_opflearn.append(opflearn[feature][:, i])\n",
    "\n",
    "    bus_data_dk = [\n",
    "        bus_groups_df_dk.get_group(bus)[feature].values for bus in sample_buses\n",
    "    ]\n",
    "    bus_data_pg = [\n",
    "        bus_groups_df_pg.get_group(bus)[feature].values for bus in sample_buses\n",
    "    ]\n",
    "\n",
    "    datasets = [\n",
    "        bus_data_dk,\n",
    "        bus_data_opfdata,\n",
    "        bus_data_pfdelta,\n",
    "        bus_data_opflearn,\n",
    "        bus_data_pg,\n",
    "    ]\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "    x_pos = np.array(\n",
    "        [np.arange(len(sample_buses)) + i * 0.2 for i in range(5)]\n",
    "    ).T.flatten()\n",
    "\n",
    "    # Plot\n",
    "    colors = [\"lightgreen\", \"pink\", \"thistle\", \"lightblue\", \"lightyellow\"]\n",
    "\n",
    "    for i, data in enumerate(datasets):\n",
    "        bp = ax.boxplot(\n",
    "            data,\n",
    "            sym=\"\",\n",
    "            whis=[0, 100],\n",
    "            widths=0.15,\n",
    "            showfliers=False,\n",
    "            showcaps=True,\n",
    "            patch_artist=True,\n",
    "            medianprops=dict(color=\"black\", linewidth=1.5),\n",
    "            tick_labels=list(datasets[0]),\n",
    "            positions=[x_pos[i] + j * 1 for j in range(len(data))],\n",
    "        )\n",
    "\n",
    "        for pc in bp[\"boxes\"]:\n",
    "            pc.set_facecolor(colors[i % 5])  # Cycles through colors\n",
    "            pc.set_alpha(0.6)  # Transparency\n",
    "\n",
    "    # Titles\n",
    "    ax.set(\n",
    "        title=f\"{feature} distribution across buses\", ylabel=feature, xlabel=\"Bus Index\"\n",
    "    )\n",
    "    # Remove the major x-axis tickmarks\n",
    "    ax.tick_params(axis=\"x\", bottom=False)\n",
    "    xtick_positions = np.arange(len(sample_buses)) + 0.2\n",
    "    ax.set_xticks(xtick_positions)\n",
    "\n",
    "    # Positions of the x-axis labels\n",
    "    ax.set_xlabel(\"Bus Index\")\n",
    "    ax.set_ylabel(feature)\n",
    "\n",
    "    # Positions of the minor x-axis tickmarks\n",
    "    ax.set_xticklabels(\n",
    "        [f\"Bus {bus}\" for bus in sample_buses],\n",
    "        # rotation=45,\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    # Add legend\n",
    "    group_labels = [\"GFM-Datakit\", \"OPF: n-1\", \"Pfdelta\", \"OPF Learn\", \"PgLearn\"]\n",
    "    legend_patches = [\n",
    "        mpatches.Patch(color=colors[i], label=group_labels[i]) for i in range(5)\n",
    "    ]\n",
    "    ax.legend(handles=legend_patches, loc=\"best\")\n",
    "    fig.canvas.header_visible = False\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "582e68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add widgets\n",
    "toggle_button = widgets.ToggleButtons(\n",
    "    options=[\"vm\", \"pd\", \"qd\", \"pg\", \"qg\"],\n",
    "    description=\"Feature\",\n",
    "    disabled=False,\n",
    "    button_style=\"\",  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltips=[\"vm\", \"pd\", \"qd\", \"pg\", \"qg\"],\n",
    "    # layout=Layout(width=\"50%\", height='30px', padding='10px')\n",
    ")\n",
    "# Number of buses\n",
    "text_input = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=0,\n",
    "    max=54,\n",
    "    step=1,\n",
    "    description=\"# buses to display:\",\n",
    "    orientation=\"horizontal\",\n",
    "    disabled=False,\n",
    ")\n",
    "# display(text_input)\n",
    "\n",
    "# Create a Dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        \"pf_no_gc\",\n",
    "        \"pf_gc_no_topology\",\n",
    "        \"pf_gc_random_topology\",\n",
    "        \"contingency_gc_random_topology\",\n",
    "    ],\n",
    "    value=\"pf_no_gc\",  # Initial selected value\n",
    "    description=\"Select data:\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "022d030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(dropdown_value, input_buses, toggle_val):\n",
    "    plt.clf()\n",
    "    if toggle_val == \"pd\" or toggle_val == \"qd\":\n",
    "        sample_buses = np.sort(random.sample(range(99), input_buses))\n",
    "    elif toggle_val == \"vm\":\n",
    "        sample_buses = np.sort(random.sample(range(118), input_buses))\n",
    "    elif toggle_val == \"pg\" or toggle_val == \"qg\":\n",
    "        sample_buses = np.sort(random.sample(range(54), input_buses))\n",
    "\n",
    "    if dropdown_value == \"pf_no_gc\":\n",
    "        plotting_function(\n",
    "            toggle_val, sample_buses, perturbpf, opfdata, opflearn, df_pg, df_dk_no_gc\n",
    "        )\n",
    "    elif dropdown_value == \"pf_gc_no_topology\":\n",
    "        plotting_function(\n",
    "            toggle_val,\n",
    "            sample_buses,\n",
    "            perturbpf,\n",
    "            opfdata,\n",
    "            opflearn,\n",
    "            df_pg,\n",
    "            datakit_gc_no_topology,\n",
    "        )\n",
    "    elif dropdown_value == \"pf_gc_random_topology\":\n",
    "        plotting_function(\n",
    "            toggle_val,\n",
    "            sample_buses,\n",
    "            perturbpf,\n",
    "            opfdata,\n",
    "            opflearn,\n",
    "            df_pg,\n",
    "            datakit_gc_random_topology,\n",
    "        )\n",
    "    elif dropdown_value == \"contingency_gc_random_topology\":\n",
    "        plotting_function(\n",
    "            toggle_val,\n",
    "            sample_buses,\n",
    "            perturbpf,\n",
    "            opfdata,\n",
    "            opflearn,\n",
    "            df_pg,\n",
    "            datakit_gc_random_topology_contingency,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3b00f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b001f26328a4687a3ca888c1ec55854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select data:', options=('pf_no_gc', 'pf_gc_no_topology', 'pf_gc_raâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = widgets.interactive(\n",
    "    f, dropdown_value=dropdown, input_buses=text_input, toggle_val=toggle_button\n",
    ")\n",
    "dropdown\n",
    "text_input\n",
    "toggle_button\n",
    "nwidget_vbox = widgets.VBox([toggle_button])\n",
    "\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406936b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
