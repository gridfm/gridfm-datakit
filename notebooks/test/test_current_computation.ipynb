{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding upper limit u ."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albanpuech/grid_data_synthetic/venv/lib/python3.9/site-packages/pandapower/create.py:5049: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "OPF did not converge for u=1.200. Using u=1.100 for upper limit\n",
      "min, max of ref_curve: 0.66, 1.1\n",
      "l, u: 0.66, 1.1\n",
      "cutting the load profile (original length: 8760, requested length: 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albanpuech/grid_data_synthetic/venv/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:133: ComplexWarning:\n",
      "\n",
      "Casting complex values to real discards the imaginary part\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data generation complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from GridDataGen.utils.io import *\n",
    "from GridDataGen.utils.process_network import *\n",
    "from GridDataGen.utils.config import *\n",
    "from GridDataGen.utils.stats import *\n",
    "from GridDataGen.utils.param_handler import *\n",
    "from GridDataGen.utils.load import *\n",
    "from pandapower.auxiliary import pandapowerNet\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from GridDataGen.utils.topology_perturbation import initialize_generator\n",
    "import psutil\n",
    "import shutil\n",
    "import yaml\n",
    "from GridDataGen.utils.process_network import process_scenario_contingency\n",
    "\n",
    "\n",
    "\n",
    "# Load the base config\n",
    "with open(\"test_current_computation.yaml\", \"r\") as f:\n",
    "    base_config = yaml.safe_load(f)\n",
    "\n",
    "args = NestedNamespace(**base_config)\n",
    "\n",
    "base_path = os.path.join(args.settings.data_dir, args.network.name, \"raw\")\n",
    "if os.path.exists(base_path) and args.settings.overwrite:\n",
    "    shutil.rmtree(base_path)\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "tqdm_log = open(os.path.join(base_path, \"tqdm.log\"), \"a\")\n",
    "error_log_path = os.path.join(base_path, \"error.log\")\n",
    "args_log_path = os.path.join(base_path, \"args.log\")\n",
    "node_path = os.path.join(base_path, \"pf_node.csv\")\n",
    "edge_path = os.path.join(base_path, \"pf_edge.csv\")\n",
    "branch_idx_removed_path = os.path.join(base_path, \"branch_idx_removed.csv\")\n",
    "edge_params_path = os.path.join(base_path, \"edge_params.csv\")\n",
    "bus_params_path = os.path.join(base_path, \"bus_params.csv\")\n",
    "scenarios_csv_path = os.path.join(\n",
    "    base_path, \"scenarios_\" + args.load.generator + \".csv\"\n",
    ")\n",
    "scenarios_plot_path = os.path.join(\n",
    "    base_path, \"scenarios_\" + args.load.generator + \".html\"\n",
    ")\n",
    "scenarios_log = os.path.join(base_path, \"scenarios_\" + args.load.generator + \".log\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tqdm_log.write(f\"\\nNew generation started at {timestamp}\\n\")\n",
    "with open(error_log_path, \"a\") as f:\n",
    "    f.write(f\"\\nNew generation started at {timestamp}\\n\")\n",
    "with open(scenarios_log, \"a\") as f:\n",
    "    f.write(f\"\\nNew generation started at {timestamp}\\n\")\n",
    "with open(args_log_path, \"a\") as f:\n",
    "    f.write(f\"\\nNew generation started at {timestamp}\\n\")\n",
    "    yaml.dump(base_config, f)\n",
    "\n",
    "# Load network and scenario data\n",
    "if args.network.source == \"pandapower\":\n",
    "    net = load_net_from_pp(args.network.name)\n",
    "elif args.network.source == \"pglib\":\n",
    "    net = load_net_from_pglib(args.network.name)\n",
    "elif args.network.source == \"file\":\n",
    "    net = load_net_from_file(args.network.name)\n",
    "else:\n",
    "    raise ValueError(\"Invalid grid source!\")\n",
    "\n",
    "network_preprocessing(net)\n",
    "assert (net.sgen[\"scaling\"] == 1).all(), \"Scaling factor >1 not supported yet!\"\n",
    "\n",
    "load_scenario_generator = get_load_scenario_generator(args)\n",
    "scenarios = load_scenario_generator(net, args.load.scenarios, scenarios_log)\n",
    "scenarios_df = load_scenarios_to_df(scenarios)\n",
    "scenarios_df.to_csv(scenarios_csv_path, index=False)\n",
    "plot_load_scenarios_combined(scenarios_df, scenarios_plot_path)\n",
    "save_edge_params(net, edge_params_path)\n",
    "save_bus_params(net, bus_params_path)\n",
    "\n",
    "# Initialize the topology generator\n",
    "generator = initialize_generator(\n",
    "    args.topology_perturbation.type,\n",
    "    args.topology_perturbation.n_topology_variants,\n",
    "    args.topology_perturbation.k,\n",
    "    args.topology_perturbation.elements,\n",
    "    net,\n",
    ")\n",
    "\n",
    "# Initialize data structures\n",
    "csv_data = []\n",
    "adjacency_lists = []\n",
    "branch_idx_removed = []\n",
    "global_stats = Stats() if not args.settings.no_stats else None\n",
    "\n",
    "scenario_index = 1\n",
    "\n",
    "# Process the scenario\n",
    "net = copy.deepcopy(net)\n",
    "net.load.p_mw = scenarios[:, scenario_index, 0]\n",
    "net.load.q_mvar = scenarios[:, scenario_index, 1]\n",
    "run_opf(net)\n",
    "\n",
    "\n",
    "net_pf = copy.deepcopy(net)\n",
    "net_pf = pf_preprocessing(net_pf)\n",
    "\n",
    "# Generate perturbed topologies\n",
    "perturbed_topologies = generator.generate(net_pf)\n",
    "\n",
    "# to simulate contingency, we apply the topology perturbation after OPF\n",
    "for perturbed_topology in perturbed_topologies:\n",
    "    try:\n",
    "        run_pf(perturbed_topology)\n",
    "    except Exception as e:\n",
    "        with open(error_log_path, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"Caught an exception at scenario {scenario_index} in run_pf function: {e}\\n\"\n",
    "            )\n",
    "\n",
    "            continue\n",
    "\n",
    "            # TODO 1: What to do when the network does not converge for AC-PF? -> we dont have targets for regression!!\n",
    "\n",
    "    # Append processed power flow data\n",
    "    csv_data.extend(pf_post_processing(perturbed_topology))\n",
    "    adjacency_lists.append(get_adjacency_list(perturbed_topology))\n",
    "    branch_idx_removed.append(\n",
    "        get_branch_idx_removed(perturbed_topology._ppc[\"branch\"])\n",
    "    )\n",
    "    if not args.settings.no_stats:\n",
    "        global_stats.update(perturbed_topology)\n",
    "\n",
    "\n",
    "# Save final data\n",
    "save_node_edge_data(net, node_path, edge_path, csv_data, adjacency_lists)\n",
    "# save branch_idx_removed to numpy array\n",
    "save_branch_idx_removed(branch_idx_removed, branch_idx_removed_path)\n",
    "if not args.settings.no_stats:\n",
    "    global_stats.save(base_path)\n",
    "    plot_stats(base_path)\n",
    "\n",
    "print(\"Data generation complete.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_edge = pd.read_csv(\"../test_data/case24_ieee_rts/raw/pf_edge.csv\")\n",
    "pf_node = pd.read_csv(\"../test_data/case24_ieee_rts/raw/pf_node.csv\")\n",
    "branch_idx_removed = pd.read_csv(\"../test_data/case24_ieee_rts/raw/branch_idx_removed.csv\")\n",
    "edge_params = pd.read_csv(\"../test_data/case24_ieee_rts/raw/edge_params.csv\")\n",
    "bus_params = pd.read_csv(\"../test_data/case24_ieee_rts/raw/bus_params.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario  0   1\n",
       "0         0  2  15"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_idx_removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kv = bus_params[\"baseKV\"].values\n",
    "sn_mva = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges removed [ 2 15]\n"
     ]
    }
   ],
   "source": [
    "idx_removed =  branch_idx_removed.loc[:, ['0', '1']].values[0]\n",
    "print(\"edges removed\", idx_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_params.drop(idx_removed, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from-bus and to-bus indices for each branch\n",
    "\n",
    "f = edge_params[\"from_bus\"].values.astype(np.int32)\n",
    "t = edge_params[\"to_bus\"].values.astype(np.int32)\n",
    "\n",
    "# Extract branch admittance coefficients\n",
    "Yff = edge_params[\"Yff_r\"].values + 1j * edge_params[\"Yff_i\"].values\n",
    "Yft = edge_params[\"Yft_r\"].values + 1j * edge_params[\"Yft_i\"].values\n",
    "Ytf = edge_params[\"Ytf_r\"].values + 1j * edge_params[\"Ytf_i\"].values\n",
    "Ytt = edge_params[\"Ytt_r\"].values + 1j * edge_params[\"Ytt_i\"].values\n",
    "\n",
    "# Get base voltages for the from and to buses (for kA conversion)\n",
    "Vf_base_kV = base_kv[f]\n",
    "Vt_base_kV = base_kv[t]\n",
    "\n",
    "nl = edge_params.shape[0]\n",
    "nb = bus_params.shape[0]\n",
    "\n",
    "# i = [0, 1, ..., nl-1, 0, 1, ..., nl-1], used for constructing Yf and Yt\n",
    "i = np.hstack([np.arange(nl), np.arange(nl)])\n",
    "\n",
    "# Construct from-end admittance matrix Yf using the linear combination:\n",
    "# Yf[b, :] = y_ff_b * e_f + y_ft_b * e_t\n",
    "Yf = csr_matrix((np.hstack([Yff, Yft]), (i, np.hstack([f, t]))), shape=(nl, nb))\n",
    "Yt = csr_matrix((np.hstack([Ytf, Ytt]), (i, np.hstack([f, t]))), shape=(nl, nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_branch_currents_kA(Yf, Yt, V, Vf_base_kV, Vt_base_kV, sn_mva):\n",
    "\n",
    "    \n",
    "    If_pu = Yf @ V  # From-end currents in per-unit (I_f = Y_f V)\n",
    "    If_kA = np.abs(If_pu) * sn_mva / (np.sqrt(3) * Vf_base_kV)  # Conversion to kA\n",
    "\n",
    "    # Construct to-end admittance matrix Yt:\n",
    "    # Yt[b, :] = y_tf_b * e_f + y_tt_b * e_t\n",
    "    It_pu = Yt @ V  # To-end currents in per-unit (I_t = Y_t V)\n",
    "    It_kA = np.abs(It_pu) * sn_mva / (np.sqrt(3) * Vt_base_kV)  # Conversion to kA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return If_kA, It_kA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.17546403, 0.25518052, 0.09886943, 0.07348013, 0.23954488,\n",
       "        0.24327099, 0.23442614, 0.6032624 , 0.22396224, 0.38218623,\n",
       "        0.28779473, 0.20571786, 0.70133643, 0.54024475, 0.71703685,\n",
       "        1.04284532, 0.26532923, 0.57841542, 0.57841542, 0.61935974,\n",
       "        0.88226173, 0.1803906 , 0.54833144, 0.33557769, 0.08544352,\n",
       "        0.08544352, 0.08675645, 0.08675645, 0.20120267, 0.20120267,\n",
       "        0.37650682, 0.62511666, 0.375087  , 0.19368163, 0.53213818,\n",
       "        0.35084715]),\n",
       " array([0.17515675, 0.26626711, 0.11247232, 0.07275817, 0.23635455,\n",
       "        0.24597761, 0.23251819, 0.60400414, 0.23011729, 0.38625903,\n",
       "        0.28605241, 0.20811571, 0.69733627, 0.54029101, 0.71684839,\n",
       "        1.04479711, 0.26389178, 0.57942865, 0.57942865, 0.62511662,\n",
       "        0.88319778, 0.1853832 , 0.54825806, 0.34128208, 0.08725273,\n",
       "        0.08725273, 0.09041433, 0.09041433, 0.20150013, 0.20150013,\n",
       "        0.38128567, 1.07311693, 0.64389934, 0.33248679, 0.90463486,\n",
       "        0.59644006]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = pf_node[\"Vm\"].values * np.exp(1j * pf_node[\"Va\"].values * np.pi / 180)\n",
    "If_kA, It_kA = compute_branch_currents_kA(Yf, Yt, V, Vf_base_kV, Vt_base_kV, sn_mva)\n",
    "\n",
    "If_kA, It_kA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_topology.res_line['from_bus'] = perturbed_topology.line['from_bus']\n",
    "perturbed_topology.res_line['to_bus'] = perturbed_topology.line['to_bus']\n",
    "perturbed_topology.res_line['in_service'] = perturbed_topology.line['in_service']\n",
    "perturbed_topology.res_trafo['hv_bus'] = perturbed_topology.trafo['hv_bus']\n",
    "perturbed_topology.res_trafo['lv_bus'] = perturbed_topology.trafo['lv_bus']\n",
    "perturbed_topology.res_trafo['in_service'] = perturbed_topology.trafo['in_service']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_branch_currents(net, f, t,If_kA, It_kA,  idx_removed, decimals=6):\n",
    "    \"\"\"\n",
    "    Compares calculated branch currents and loading with pandapower results.\n",
    "\n",
    "    Parameters:\n",
    "    - net: pandapower network\n",
    "    - f: np.ndarray of shape (n_edges, 2), from and to bus indices\n",
    "    - t: np.ndarray of shape (n_edges, 2), from and to bus indices\n",
    "    - If_kA: np.ndarray of calculated from-end branch currents\n",
    "    - It_kA: np.ndarray of calculated to-end branch currents\n",
    "    - decimals: int, number of decimal places to round to\n",
    "    \"\"\"\n",
    "    \n",
    "    # create sets of all (from_bus, to_bus, I_from_kA, I_to_kA) for lines\n",
    "    set_of_lines = set((line.from_bus, line.to_bus, np.round(line.i_from_ka, decimals), np.round(line.i_to_ka, decimals)) for line in net.res_line.itertuples() if line.in_service)\n",
    "    # add trafos to the set\n",
    "    set_of_lines.update((trafo.hv_bus, trafo.lv_bus, np.round(trafo.i_hv_ka, decimals), np.round(trafo.i_lv_ka, decimals)) for trafo in net.res_trafo.itertuples() if trafo.in_service)\n",
    "    set_of_lines_computed = set((f[line_index], t[line_index], np.round(If_kA[line_index], decimals), np.round(It_kA[line_index], decimals)) for line_index in range(f.shape[0]))\n",
    "    if not set_of_lines == set_of_lines_computed:\n",
    "        print(set_of_lines - set_of_lines_computed)\n",
    "        print(set_of_lines_computed - set_of_lines)\n",
    "    assert set_of_lines == set_of_lines_computed, \"Lines do not match\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_branch_currents(perturbed_topology, f, t, If_kA, It_kA, idx_removed, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loading(If_kA, It_kA, Vf_base_kV, Vt_base_kV, rate_a):\n",
    "    \"\"\"\n",
    "    Compute per-branch loading using current magnitudes and branch ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - edge_index: np.ndarray of shape (n_edges, 2), each row is [from_bus, to_bus]\n",
    "    - If_kA: np.ndarray of from-side current magnitudes in kA\n",
    "    - It_kA: np.ndarray of to-side current magnitudes in kA\n",
    "    - base_kv: np.ndarray of shape (n_buses,), base voltage in kV per bus\n",
    "    - edge_attr: np.ndarray of shape (n_edges, >=5), edge features, column 4 = RATE_A\n",
    "\n",
    "    Returns:\n",
    "    - loading: np.ndarray of shape (n_edges,), max of from and to side loading\n",
    "    \"\"\"\n",
    "\n",
    "    limitf = rate_a / (Vf_base_kV * np.sqrt(3))\n",
    "    limitt = rate_a / (Vt_base_kV * np.sqrt(3))\n",
    "\n",
    "    loadingf = If_kA / limitf\n",
    "    loadingt = It_kA / limitt\n",
    "\n",
    "    return np.maximum(loadingf, loadingt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_a = edge_params[\"rate_a\"].values\n",
    "loading = compute_loading(If_kA, It_kA, Vf_base_kV, Vt_base_kV, rate_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_loading(net, f,t, loading, decimals=6):\n",
    "    \"\"\"\n",
    "    Compare computed loading against values in net.res_line and net.res_trafo.\n",
    "\n",
    "    Parameters:\n",
    "    - net: pandapower network\n",
    "    - edge_index: np.ndarray of shape (n_edges, 2), mapping lines/transformers to buses\n",
    "    - loading: np.ndarray of computed loading (shape = number of branches)\n",
    "    \"\"\"\n",
    "    \n",
    "    # create sets of all (from_bus, to_bus, loading) for lines\n",
    "    set_of_lines = set((line.from_bus, line.to_bus, np.round(line.loading_percent / 100, decimals)) for line in net.res_line.itertuples() if line.in_service)\n",
    "    # add trafos to the set\n",
    "    set_of_lines.update((trafo.hv_bus, trafo.lv_bus, np.round(trafo.loading_percent / 100, decimals)) for trafo in net.res_trafo.itertuples() if trafo.in_service) \n",
    "    set_of_lines_computed = set((f[line_index], t[line_index], np.round(loading[line_index], decimals)) for line_index in range(f.shape[0]))\n",
    "    # assert that the two sets are equal\n",
    "    assert set_of_lines == set_of_lines_computed, \"Lines do not match\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_loading(perturbed_topology, f, t, loading, decimals=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
